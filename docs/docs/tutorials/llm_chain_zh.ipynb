{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab129d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.16\n",
      "cryptography                      44.0.2\n",
      "duckduckgo_search                 6.3.7\n",
      "langchain                         0.3.19\n",
      "langchain-community               0.3.18\n",
      "langchain-core                    0.3.49\n",
      "langchain-deepseek                0.1.3\n",
      "langchain-openai                  0.3.11\n",
      "langchain-text-splitters          0.3.6\n",
      "langgraph                         0.3.21\n",
      "langgraph-checkpoint              2.0.23\n",
      "langgraph-prebuilt                0.1.7\n",
      "langgraph-sdk                     0.1.60\n",
      "langserve                         0.3.1\n",
      "langsmith                         0.3.8\n",
      "numpy                             1.26.4\n",
      "openai                            1.69.0\n",
      "scipy                             1.15.2\n",
      "tiktoken                          0.9.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from env_key_manager import APIKeyManager\n",
    "\n",
    "# 创建实例\n",
    "key_manager = APIKeyManager()\n",
    "\n",
    "# 设置环境变量\n",
    "key_manager.setup_api_key([\"DEEPSEEK_API_KEY\", \"LANGSMITH_TRACING\", \"LANGSMITH_PROJECT\", ])\n",
    "\n",
    "# 查看Python版本\n",
    "!python -V\n",
    "# 查看安装的库\n",
    "if 'win' in sys.platform.lower():\n",
    "    !pip list | findstr \"lang openai llm tiktoken chromadb cryptography duck unstructured numpy scipy\"\n",
    "else:\n",
    "    !pip list | grep -E 'lang|openai|llm|tiktoken|chromadb|cryptography|duck|unstructured|numpy|scipy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9316da0d",
   "metadata": {},
   "source": [
    "# 使用聊天模型和提示模板构建一个简单的LLM应用\n",
    "\n",
    "在本快速入门指南中，我们将向您展示如何使用LangChain构建一个简单的LLM应用程序。该应用程序能够将文本从英语翻译成其他语言。这是一个相对简单的LLM应用——仅需一次LLM调用加上适当的提示即可完成。尽管如此，这仍是入门LangChain的绝佳方式——仅通过提示设计和LLM调用就能实现许多功能！\n",
    "\n",
    "阅读本教程后，您将对以下内容有高层次的理解：\n",
    "\n",
    "- 使用[语言模型](/docs/concepts/chat_models)\n",
    "\n",
    "- 使用[提示模板](/docs/concepts/prompt_templates)\n",
    "\n",
    "- 使用 [LangSmith](https://docs.smith.langchain.com/) 调试和追踪您的应用程序\n",
    "\n",
    "让我们开始吧！\n",
    "\n",
    "## 安装设置\n",
    "\n",
    "### Jupyter Notebook\n",
    "\n",
    "本教程及其他教程或许在 [Jupyter notebooks](https://jupyter.org/) 中运行最为便捷。在交互式环境中学习教程是深入理解内容的绝佳方式。安装方法请参阅 [此处](https://jupyter.org/install)。\n",
    "\n",
    "### 安装\n",
    "\n",
    "要安装LangChain，请运行：\n",
    "\n",
    "<!-- HIDE_IN_NB\n",
    "import Tabs from '@theme/Tabs';\n",
    "import TabItem from '@theme/TabItem';\n",
    "import CodeBlock from \"@theme/CodeBlock\";\n",
    "\n",
    "<Tabs>\n",
    "  <TabItem value=\"pip\" label=\"Pip\" default>\n",
    "<CodeBlock language=\"bash\">pip install langchain</CodeBlock>\n",
    "  </TabItem>\n",
    "  <TabItem value=\"conda\" label=\"Conda\">\n",
    "<CodeBlock language=\"bash\">conda install langchain -c conda-forge</CodeBlock>\n",
    "  </TabItem>\n",
    "</Tabs>\n",
    "HIDE_IN_NB -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86874822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "\n",
    "# %pip install langchain\n",
    "# OR\n",
    "# %conda install langchain -c conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a546a5bc",
   "metadata": {},
   "source": [
    "更多详情，请参阅我们的[安装指南](/docs/how_to/installation)。\n",
    "\n",
    "### LangSmith\n",
    "\n",
    "使用LangChain构建的许多应用程序将包含多个步骤，涉及多次LLM调用。\n",
    "随着这些应用变得越来越复杂，能够检查链或代理内部的具体运行情况变得至关重要。\n",
    "最佳方式是使用 [LangSmith](https://smith.langchain.com)。\n",
    "\n",
    "在以上链接完成注册后，请确保设置环境变量以开始记录追踪数据：\n",
    "\n",
    "```shell\n",
    "export LANGSMITH_TRACING=\"true\"\n",
    "export LANGSMITH_API_KEY=\"...\"\n",
    "export LANGSMITH_PROJECT=\"default\" # 或其他任意项目名称\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "599bb688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import getpass\n",
    "# import os\n",
    "\n",
    "# try:\n",
    "#     # load environment variables from .env file (requires `python-dotenv`)\n",
    "#     from dotenv import load_dotenv\n",
    "\n",
    "#     load_dotenv()\n",
    "# except ImportError:\n",
    "#     pass\n",
    "\n",
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "# if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "#     os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\n",
    "#         prompt=\"Enter your LangSmith API key (optional): \"\n",
    "#     )\n",
    "# if \"LANGSMITH_PROJECT\" not in os.environ:\n",
    "#     os.environ[\"LANGSMITH_PROJECT\"] = getpass.getpass(\n",
    "#         prompt='Enter your LangSmith Project Name (default = \"default\"): '\n",
    "#     )\n",
    "#     if not os.environ.get(\"LANGSMITH_PROJECT\"):\n",
    "#         os.environ[\"LANGSMITH_PROJECT\"] = \"default\"\n",
    "# if \"OPENAI_API_KEY\" not in os.environ:\n",
    "#     os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\n",
    "#         prompt=\"Enter your OpenAI API key (required if using OpenAI): \"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5558ca9",
   "metadata": {},
   "source": [
    "## 使用语言模型\n",
    "\n",
    "首先，我们来学习如何单独使用语言模型。LangChain支持多种可互换使用的语言模型。有关特定模型的入门指南，请参阅[支持的集成](/docs/integrations/chat/)。\n",
    "\n",
    "<!-- HIDE_IN_NB>\n",
    "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
    "\n",
    "<ChatModelTabs overrideParams={{openai: {model: \"gpt-4o-mini\"}}} />\n",
    "HIDE_IN_NB -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b41234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "model = ChatDeepSeek(model=\"deepseek-chat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5642ff",
   "metadata": {},
   "source": [
    "让我们首先直接使用这个模型。[聊天模型](/docs/concepts/chat_models)是LangChain中[可运行对象](/docs/concepts/runnables/)的实例，这意味着它们提供了与之交互的标准接口。要简单地调用模型，我们可以向`.invoke`方法传入一个[消息](/docs/concepts/messages/)列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b2481f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao! 😊', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 12, 'total_tokens': 17, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 12}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3d5141a69a_prod0225', 'id': '369d6d54-9756-4d16-b783-79f0798789db', 'finish_reason': 'stop', 'logprobs': None}, id='run-058a3cd1-887f-4e47-938e-f3eba48d7499-0', usage_metadata={'input_tokens': 12, 'output_tokens': 5, 'total_tokens': 17, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83373db",
   "metadata": {},
   "source": [
    ":::提示\n",
    "\n",
    "如果已启用LangSmith，我们可以看到此次运行已记录到LangSmith中，并能查看[LangSmith追踪记录](https://smith.langchain.com/public/88baa0b2-7c1a-4d09-ba30-a47985dde2ea/r)。该追踪记录会报告[令牌](/docs/concepts/tokens/)使用情况、延迟时间、[标准模型参数](/docs/concepts/chat_models/#standard-parameters)（如temperature）以及其他信息。\n",
    "\n",
    ":::\n",
    "\n",
    "请注意，ChatModels 接收[消息](/docs/concepts/messages/)对象作为输入，并生成消息对象作为输出。除了文本内容外，消息对象还传递对话[角色](/docs/concepts/messages/#role)，并包含重要数据，例如[工具调用](/docs/concepts/tool_calling/)和令牌使用计数。\n",
    "\n",
    "LangChain 还支持通过字符串或 [OpenAI 格式](/docs/concepts/messages/#openai-format) 输入聊天模型。以下是等效的：\n",
    "\n",
    "```python\n",
    "model.invoke(\"你好\")\n",
    "\n",
    "model.invoke([{\"role\": \"user\", \"content\": \"你好\"}])\n",
    "\n",
    "model.invoke([HumanMessage(\"你好\")])\n",
    "```\n",
    "### 流式传输\n",
    "\n",
    "由于聊天模型属于[可运行对象](/docs/concepts/runnables/)，它们提供了一套标准接口，包含异步和流式调用模式。这使得我们可以从聊天模型中逐令牌流式获取输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0abb0863-bee7-448d-b013-79d8db01e330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|C|iao|!| 😊||"
     ]
    }
   ],
   "source": [
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5963141-468c-4570-8f2e-5f7cfb6eb3db",
   "metadata": {},
   "source": [
    "您可以在[本指南](/docs/how_to/chat_streaming/)中找到关于流式聊天模型输出的更多详细信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab8da31",
   "metadata": {},
   "source": [
    "## 提示模板\n",
    "\n",
    "目前我们直接将一组消息传递给语言模型。这组消息从何而来？通常，它是由用户输入和应用程序逻辑共同构建而成。应用程序逻辑通常会接收原始用户输入，并将其转换为一组可直接传递给语言模型的消息。常见的转换操作包括添加系统消息，或根据用户输入格式化模板。\n",
    "\n",
    "[提示模板](/docs/concepts/prompt_templates/)是LangChain中设计用于辅助这种转换的概念。它们接收原始用户输入并返回准备传递给语言模型的数据（即提示）。\n",
    "\n",
    "让我们在此创建一个提示模板。该模板将接收两个用户变量：\n",
    "\n",
    "- `language`: 要将文本翻译成的目标语言\n",
    "- `text`: 要翻译的文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e73cc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e876c2a",
   "metadata": {},
   "source": [
    "请注意，`ChatPromptTemplate` 支持在单个模板中使用多种[消息角色](/docs/concepts/messages/#role)。我们将 `language` 参数格式化为系统消息，而用户输入的 `text` 则格式化为用户消息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9711ba6",
   "metadata": {},
   "source": [
    "此提示模板的输入是一个字典。我们可以单独使用这个提示模板，看看它本身能实现什么功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f781b3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49ba9e",
   "metadata": {},
   "source": [
    "我们可以看到它返回了一个由两条消息组成的 `ChatPromptValue`。如果我们想直接访问这些消息，可以这样做："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2159b619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e70ee6-f0e0-4ae0-a290-002799ebf828",
   "metadata": {},
   "source": [
    "最后，我们可以在格式化后的提示上调用聊天模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a509d8c-e122-4641-b9ee-91bc23aa155a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao!\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f0bf25-6efb-4853-9a8f-242f2855c84a",
   "metadata": {},
   "source": [
    ":::提示\n",
    "消息 `content` 可以包含文本和具有附加结构的[内容块](/docs/concepts/messages/#aimessage)。更多信息请参阅[本指南](/docs/how_to/output_parser_string/)。\n",
    ":::\n",
    "\n",
    "如果我们查看 [LangSmith 追踪记录](https://smith.langchain.com/public/3ccc2d5e-2869-467b-95d6-33a577df99a2/r)，就能清晰地看到聊天模型接收的具体提示内容，以及 [token 使用情况](/docs/concepts/tokens/)、延迟时间、[标准模型参数](/docs/concepts/chat_models/#standard-parameters)（如 temperature）等其他信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befdb168",
   "metadata": {},
   "source": [
    "## 结论\n",
    "\n",
    "就是这样！在本教程中，你已经学会了如何创建第一个简单的LLM应用程序。你掌握了如何运用语言模型、如何创建提示模板，以及如何通过LangSmith为你构建的应用程序实现出色的可观测性。\n",
    "\n",
    "这仅仅触及了成为熟练AI工程师所需学习的皮毛。幸运的是——我们还有很多其他资源！\n",
    "\n",
    "要进一步了解LangChain的核心概念，我们提供了详细的[概念指南](/docs/concepts)。\n",
    "\n",
    "如果您对这些概念有更具体的问题，请查阅操作指南的以下部分：\n",
    "\n",
    "- [聊天模型](/docs/how_to/#chat-models)\n",
    "- [提示词模板](/docs/how_to/#prompt-templates)\n",
    "\n",
    "以及LangSmith文档：\n",
    "\n",
    "- [LangSmith](https://docs.smith.langchain.com)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
