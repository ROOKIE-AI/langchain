{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df29b30a-fd27-4e08-8269-870df5631f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGSMITH_ENDPOINT密钥已加密保存\n",
      "LANGSMITH_API_KEY密钥已加密保存\n",
      "LANGSMITH_PROJECT密钥已加密保存\n",
      "Python 3.10.16\n",
      "chromadb                                 0.6.3\n",
      "cryptography                             44.0.2\n",
      "duckduckgo_search                        6.3.7\n",
      "langchain                                0.3.19\n",
      "langchain-chroma                         0.2.2\n",
      "langchain-community                      0.3.18\n",
      "langchain-core                           0.3.49\n",
      "langchain-deepseek                       0.1.3\n",
      "langchain-openai                         0.3.11\n",
      "langchain-text-splitters                 0.3.6\n",
      "langgraph                                0.3.21\n",
      "langgraph-checkpoint                     2.0.23\n",
      "langgraph-prebuilt                       0.1.7\n",
      "langgraph-sdk                            0.1.60\n",
      "langserve                                0.3.1\n",
      "langsmith                                0.3.8\n",
      "numpy                                    1.26.4\n",
      "openai                                   1.69.0\n",
      "scipy                                    1.15.2\n",
      "tiktoken                                 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from IPython.display import Markdown\n",
    "from env_key_manager import APIKeyManager\n",
    "\n",
    "# 创建实例\n",
    "key_manager = APIKeyManager()\n",
    "\n",
    "# 设置环境变量\n",
    "key_manager.setup_api_key([\"DEEPSEEK_API_KEY\", \"LANGSMITH_ENDPOINT\", \"LANGSMITH_API_KEY\", \"LANGSMITH_PROJECT\"])\n",
    "\n",
    "# 查看Python版本\n",
    "!python -V\n",
    "# 查看安装的库\n",
    "if 'win' in sys.platform.lower():\n",
    "    !pip list | findstr \"lang openai llm tiktoken chromadb cryptography duck unstructured numpy scipy\"\n",
    "else:\n",
    "    !pip list | grep -E 'lang|openai|llm|tiktoken|chromadb|cryptography|duck|unstructured|numpy|scipy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28530a6-ddfd-49c0-85dc-b723551f6614",
   "metadata": {},
   "source": [
    "# 构建一个提取链\n",
    "\n",
    "在本教程中，我们将利用[聊天模型](/docs/concepts/chat_models)的[工具调用功能](/docs/concepts/tool_calling)，从非结构化文本中提取结构化信息。同时，我们还将展示如何在此场景下运用[少量样本提示技术](/docs/concepts/few_shot_prompting/)来提升性能。\n",
    "\n",
    ":::重要\n",
    "本教程需要 `langchain-core>=0.3.20` 版本，且仅支持具备**工具调用**功能的模型。\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412def2-38e3-4bd0-bbf0-fb09ff9e5985",
   "metadata": {},
   "source": [
    "## 安装设置\n",
    "\n",
    "### Jupyter Notebook\n",
    "\n",
    "本教程及其他教程或许在 [Jupyter notebooks](https://jupyter.org/) 中运行最为便捷。在交互式环境中学习指南是深入理解它们的绝佳方式。安装方法请参阅 [此处](https://jupyter.org/install)。\n",
    "\n",
    "### 安装\n",
    "\n",
    "要安装LangChain，请运行：\n",
    "\n",
    "import Tabs from '@theme/Tabs';\n",
    "import TabItem from '@theme/TabItem';\n",
    "import CodeBlock from \"@theme/CodeBlock\";\n",
    "\n",
    "<Tabs>\n",
    "  <TabItem value=\"pip\" label=\"Pip\" default>\n",
    "<CodeBlock language=\"bash\">pip install --upgrade langchain-core</CodeBlock>\n",
    "  </TabItem>\n",
    "  <TabItem value=\"conda\" label=\"Conda\">\n",
    "<CodeBlock language=\"bash\">conda install langchain-core -c conda-forge</CodeBlock>\n",
    "  </TabItem>\n",
    "</Tabs>\n",
    "\n",
    "\n",
    "\n",
    "更多详情，请参阅我们的[安装指南](/docs/how_to/installation)。\n",
    "\n",
    "### LangSmith\n",
    "\n",
    "使用LangChain构建的许多应用程序将包含多个步骤，涉及多次LLM调用。\n",
    "随着这些应用变得越来越复杂，能够检查链或代理内部的具体运行情况变得至关重要。\n",
    "最佳实践是使用 [LangSmith](https://smith.langchain.com)。\n",
    "\n",
    "在以上链接完成注册后，请确保设置环境变量以开始记录追踪数据：\n",
    "\n",
    "```shell\n",
    "export LANGSMITH_TRACING=\"true\"\n",
    "export LANGSMITH_API_KEY=\"...\"\n",
    "```\n",
    "```python\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e48ac14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['LANGSMITH_TRACING'] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d6b970-2ea3-4192-951e-21237212b359",
   "metadata": {},
   "source": [
    "## 架构\n",
    "\n",
    "首先，我们需要描述要从文本中提取哪些信息。\n",
    "\n",
    "我们将使用 Pydantic 来定义一个示例模式以提取个人信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c141084c-fb94-4093-8d6a-81175d688e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"关于一个人的信息。\"\"\"\n",
    "\n",
    "    # ^ 人物Person的实体的文档字符串。\n",
    "    # 此文档字符串将作为模式Person的描述发送到LLM，\n",
    "    # 并且可以帮助改善提取结果。\n",
    "\n",
    "    # 请注意：\n",
    "    # 1. 每个字段都是`optional` -- 这允许模型拒绝提取它！\n",
    "    # 2. 每个字段都有一个`description` -- 此描述由LLM使用。\n",
    "    # 有一个好的描述可以帮助改善提取结果。\n",
    "    name: Optional[str] = Field(default=None, description=\"人的名字\")\n",
    "    hair_color: Optional[str] = Field(\n",
    "        default=None, description=\"如果已知，人的头发颜色\"\n",
    "    )\n",
    "    height_in_meters: Optional[str] = Field(\n",
    "        default=None, description=\"以米为单位的身高\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f248dd54-e36d-435a-b154-394ab4ed6792",
   "metadata": {},
   "source": [
    "定义模式时的两个最佳实践：\n",
    "\n",
    "1. 记录**属性**及**模式**本身：这些信息会被发送至大语言模型（LLM），用于提升信息提取的质量。\n",
    "2. 不要强迫大语言模型编造信息！如上所述，我们对属性使用了`Optional`，允许大语言模型在不知道答案时输出`None`。\n",
    "\n",
    ":::重要\n",
    "为了获得最佳性能，请详细记录模式，并确保在没有需要提取的信息时，模型不会被强制返回结果。\n",
    ":::\n",
    "\n",
    "## 提取器\n",
    "\n",
    "让我们使用上面定义的架构来创建一个信息提取器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5e490f6-35ad-455e-8ae4-2bae021583ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 定义一个自定义的提示，以提供指令和任何额外的上下文。\n",
    "# 1) 您可以将示例添加到提示模板中，以提高提取质量\n",
    "# 2) 引入额外的参数，以考虑上下文（例如，包括文本被提取的文档的元数据）。\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"您是一个专门的提取算法。 \"\n",
    "            \"只从文本中提取相关信息。 \"\n",
    "            \"如果您不知道要提取的属性的值， \"\n",
    "            \"则返回该属性值为null。\",\n",
    "        ),\n",
    "        # 请参阅关于使用参考示例提高性能的方法。\n",
    "        # MessagesPlaceholder('examples'),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832bf6a1-8e0c-4b6a-aa37-12fe9c42a6d9",
   "metadata": {},
   "source": [
    "我们需要使用一个支持函数/工具调用的模型。\n",
    "\n",
    "请查阅[相关文档](/docs/concepts/tool_calling)了解所有可与此API搭配使用的模型。\n",
    "\n",
    "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
    "\n",
    "<ChatModelTabs customVarName=\"llm\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77c1311c-5252-41d6-83e6-fdb40b172e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "llm = ChatDeepSeek(model='deepseek-chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04d846a6-d5cb-4009-ac19-61e3aac0177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = llm.with_structured_output(schema=Person)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23582c0b-00ed-403f-a10e-3aeabf921f12",
   "metadata": {},
   "source": [
    "让我们来测试一下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd42a935-022f-4860-b9e0-84268f55b22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Alan Smith', hair_color='金发', height_in_meters=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Alan Smith 身高6英尺，头发是金发的。\"\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "structured_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1c493d-f9dc-4236-8da9-50f6919f5710",
   "metadata": {},
   "source": [
    ":::重要\n",
    "\n",
    "提取即生成 🤯\n",
    "\n",
    "大型语言模型（LLMs）是生成式模型，因此它们能完成一些相当酷的任务，例如准确提取以米为单位的人体身高数据。\n",
    "尽管它是以英尺为单位提供的！\n",
    ":::\n",
    "\n",
    "我们可以在此处查看LangSmith追踪记录[链接](https://smith.langchain.com/public/44b69a63-3b3b-47b8-8a6d-61b46533f015/r)。需要注意的是，[追踪记录中的聊天模型部分](https://smith.langchain.com/public/44b69a63-3b3b-47b8-8a6d-61b46533f015/r/dd1f6305-f1e9-4919-bd8f-339d03a12d01)显示了发送给模型的消息确切序列、调用的工具以及其他元数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c5ef0c-b8d1-4e12-bd0e-e2528de87fcc",
   "metadata": {},
   "source": [
    "## 多重实体\n",
    "\n",
    "在**大多数情况下**，你应该提取一个实体列表而非单个实体。\n",
    "\n",
    "通过使用pydantic将模型相互嵌套，可以轻松实现这一点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "591a0c16-7a17-4883-91ee-0d6d2fdb265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"关于一个人的信息。\"\"\"\n",
    "\n",
    "    # ^ 对实体Person的文档字符串。\n",
    "    # 这个文档字符串作为Person模式的描述被发送给LLM，\n",
    "    # 它可以帮助提高提取结果。\n",
    "\n",
    "    # 注意：\n",
    "    # 1. 每个字段都是`可选的` -- 这允许模型拒绝提取它！\n",
    "    # 2. 每个字段都有一个`描述` -- 这个描述被LLM使用。\n",
    "    # 拥有一个好的描述可以帮助提高提取结果。\n",
    "    name: Optional[str] = Field(default=None, description=\"人的姓名\")\n",
    "    hair_color: Optional[str] = Field(\n",
    "        default=None, description=\"如果已知，人的头发颜色\"\n",
    "    )\n",
    "    height_in_meters: Optional[str] = Field(\n",
    "        default=None, description=\"以米为单位测量的身高\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"关于人们的提取数据。\"\"\"\n",
    "\n",
    "    # 创建一个模型，以便我们可以提取多个实体。\n",
    "    people: List[Person]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5cda33-fd7b-481e-956a-703f45e40e1d",
   "metadata": {},
   "source": [
    ":::重要\n",
    "提取结果在此可能并不完美。继续阅读以了解如何使用**参考示例**来提高提取质量，并查看我们的提取[操作指南](/docs/how_to/#extraction)以获取更多详细信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83ecf0db-757b-4ae3-a9d2-eb1c9f6b2631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[Person(name='杰夫', hair_color='黑色', height_in_meters='1.8288'), Person(name='安娜', hair_color='黑色', height_in_meters=None)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm = llm.with_structured_output(schema=Data)\n",
    "text = \"我的名字是杰夫，我的头发是黑色的，我6英尺高。安娜的头发颜色和我一样。\"\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "structured_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff49dfb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[Person(name='Rookie', hair_color='黑色', height_in_meters=None), Person(name='Jack', hair_color=None, height_in_meters='250')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"我是Rookie, 我的头发是黑色的。我正在和250cm高的Jack学习LangChain\"\n",
    "chain =  prompt_template | structured_llm\n",
    "chain.invoke({\"text\": text})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1d770-bf4d-4de4-9e4f-7384872ef0dc",
   "metadata": {},
   "source": [
    ":::提示\n",
    "当模式支持提取**多个实体**时，若不存在相关信息，该模式也允许模型**不提取任何实体**。\n",
    "在文本中通过提供一个空列表来表示。\n",
    "\n",
    "这通常是一件**好**事！它允许在实体上指定**必需**的属性，而不必强制模型检测该实体。\n",
    ":::\n",
    "\n",
    "我们可以在[这里](https://smith.langchain.com/public/7173764d-5e76-45fe-8496-84460bd9cdef/r)查看LangSmith的追踪记录。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c590f366-050a-43d4-8c78-acf84ccfbf9b",
   "metadata": {},
   "source": [
    "## 参考示例\n",
    "\n",
    "可以通过[少量样本提示](/docs/concepts/few_shot_prompting/)来引导LLM应用的行为。对于[聊天模型](/docs/concepts/chat_models/)而言，这可以表现为一系列输入与响应消息的配对组合，用以展示期望的行为模式。\n",
    "\n",
    "例如，我们可以通过交替使用 `user` 和 `assistant` 的[消息](/docs/concepts/messages/#role)来传达符号的含义："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bb138d7-116e-4542-aa5f-bebf0c301ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  \n",
      "\n",
      "The parrot (🦜) seems to be acting as a plus sign (+) here!  \n",
      "\n",
      "So:  \n",
      "- 2 🦜 2 = 2 + 2 = **4**  \n",
      "- 2 🦜 3 = 2 + 3 = **5**  \n",
      "- 3 🦜 4 = 3 + 4 = **7**  \n",
      "\n",
      "Fun pattern! 😊\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"2 🦜 2\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"4\"},  \n",
    "    {\"role\": \"user\", \"content\": \"2 🦜 3\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"5\"},\n",
    "    {\"role\": \"user\", \"content\": \"3 🦜 4\"},\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5691d07-e2b8-4ab3-a943-9b0b503e2549",
   "metadata": {},
   "source": [
    "[结构化输出](/docs/concepts/structured_outputs/)通常底层使用了[工具调用](/docs/concepts/tool_calling/)功能。这一过程通常涉及生成包含工具调用的[AI消息](/docs/concepts/messages/#aimessage)，以及包含工具调用结果的[工具消息](/docs/concepts/messages/#toolmessage)。在这种情况下，消息序列应该是怎样的？\n",
    "\n",
    "不同的[聊天模型提供商](/docs/integrations/chat/)对有效消息序列有着不同的要求。有些会接受如下形式的（可重复）消息序列：\n",
    "\n",
    "- 用户消息\n",
    "- 带工具调用的AI消息\n",
    "- 附带结果的工具消息\n",
    "\n",
    "其他情况下则需要一条包含某种回应的最终AI消息。\n",
    "\n",
    "LangChain 包含一个实用函数 [tool_example_to_messages](https://python.langchain.com/api_reference/core/utils/langchain_core.utils.function_calling.tool_example_to_messages.html)，该函数可为大多数模型提供商生成有效的消息序列。它通过仅需对应工具调用的 Pydantic 表示形式，简化了结构化小样本示例的生成过程。\n",
    "\n",
    "让我们来试试这个方法。我们可以将输入字符串与期望的Pydantic对象配对，转换成可提供给聊天模型的消息序列。在底层实现中，LangChain会将工具调用格式化为每个供应商所需的格式。\n",
    "\n",
    "注意：此版本的 `tool_example_to_messages` 需要 `langchain-core>=0.3.20`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c604e476-a2be-4eda-b128-71399e280732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19145\\AppData\\Local\\Temp\\ipykernel_6424\\2093107491.py:23: LangChainBetaWarning: The function `tool_example_to_messages` is in beta. It is actively being worked on, so the API may change.\n",
      "  messages.extend(tool_example_to_messages(txt, [tool_call], ai_response=ai_response))\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.utils.function_calling import tool_example_to_messages\n",
    "\n",
    "examples = [\n",
    "    (\n",
    "        \"海洋是广阔而蓝的。它超过20,000英尺深。\",\n",
    "        Data(people=[]),\n",
    "    ),\n",
    "    (\n",
    "        \"菲奥娜从法国远行到西班牙。\",\n",
    "        Data(people=[Person(name=\"菲奥娜\", height_in_meters=None, hair_color=None)]),\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "messages = []\n",
    "\n",
    "for txt, tool_call in examples:\n",
    "    if tool_call.people:\n",
    "        # 这条最终消息对于一些提供商来说是可选的\n",
    "        ai_response = \"检测到人。\"\n",
    "    else:\n",
    "        ai_response = \"未检测到人。\"\n",
    "    messages.extend(tool_example_to_messages(txt, [tool_call], ai_response=ai_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beecc7a6-e423-4ca1-82b7-c2a751362fd6",
   "metadata": {},
   "source": [
    "检查结果时，我们发现这两个示例对生成了八条消息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "628f67dd-aee0-4200-ac38-24a9fb16f1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "海洋是广阔而蓝的。它超过20,000英尺深。\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Data (a32db15f-180b-4bf9-a519-3b75d5a521b0)\n",
      " Call ID: a32db15f-180b-4bf9-a519-3b75d5a521b0\n",
      "  Args:\n",
      "    people: []\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "You have correctly called this tool.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "未检测到人。\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "菲奥娜从法国远行到西班牙。\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Data (7d78a15f-45d2-4289-83a1-9775ba3d1e15)\n",
      " Call ID: 7d78a15f-45d2-4289-83a1-9775ba3d1e15\n",
      "  Args:\n",
      "    people: [{'name': '菲奥娜', 'hair_color': None, 'height_in_meters': None}]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "You have correctly called this tool.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "检测到人。\n"
     ]
    }
   ],
   "source": [
    "for message in messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8846f0-8bd1-48e1-bc4d-a62fbfa6a9f4",
   "metadata": {},
   "source": [
    "让我们对比一下有这些消息和没有这些消息时的性能表现。例如，我们传递一条本意不提取任何人名的消息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b73d4e2-d18d-4d47-89ec-99b5eb6b234f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[Person(name='Earth', hair_color=None, height_in_meters=None)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_no_extraction = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"太阳系很大，但地球只有1个月亮。\",\n",
    "}\n",
    "\n",
    "structured_llm = llm.with_structured_output(schema=Data)\n",
    "structured_llm.invoke([message_no_extraction])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350e1298-14f1-48e4-b11c-534af643e3a6",
   "metadata": {},
   "source": [
    "在此示例中，模型容易错误地生成人物记录。\n",
    "\n",
    "由于我们的少量示例中包含“负面”案例，我们鼓励模型在这种情况下做出正确反应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb1b3a99-4750-45bc-ad28-5d12751ed9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm.invoke(messages + [message_no_extraction])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1ae320-14bc-45ee-aeeb-8a986f3e6808",
   "metadata": {},
   "source": [
    ":::提示\n",
    "\n",
    "[LangSmith](https://smith.langchain.com/public/b3433f57-7905-4430-923c-fed214525bf1/r) 运行轨迹揭示了发送至聊天模型的具体消息序列、生成的工具调用、延迟时间、令牌计数以及其他元数据。\n",
    "\n",
    ":::\n",
    "\n",
    "请参阅[本指南](/docs/how_to/extraction_examples/)了解包含参考示例的提取工作流程详情，其中涵盖如何整合提示模板及自定义示例消息的生成方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07a7455-7de6-4a6f-9772-0477ef65e3dc",
   "metadata": {},
   "source": [
    "## 后续步骤\n",
    "\n",
    "既然你已经掌握了使用LangChain进行信息提取的基础知识，接下来可以继续学习其余的操作指南：\n",
    "\n",
    "- [添加示例](/docs/how_to/extraction_examples): 关于使用**参考示例**提升性能的更多细节。\n",
    "- [处理长文本](/docs/how_to/extraction_long_text)：如果文本超出大语言模型的上下文窗口限制，该如何应对？\n",
    "- [采用解析方法](/docs/how_to/extraction_parse)：对于不支持**工具/函数调用**的模型，使用基于提示词的方法进行信息提取。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
