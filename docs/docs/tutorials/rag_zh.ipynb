{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "204e86c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.16\n",
      "chromadb                                 0.6.3\n",
      "cryptography                             44.0.2\n",
      "duckduckgo_search                        6.3.7\n",
      "langchain                                0.3.21\n",
      "langchain-chroma                         0.2.2\n",
      "langchain-community                      0.3.20\n",
      "langchain-core                           0.3.49\n",
      "langchain-deepseek                       0.1.3\n",
      "langchain-openai                         0.3.11\n",
      "langchain-text-splitters                 0.3.7\n",
      "langgraph                                0.3.21\n",
      "langgraph-checkpoint                     2.0.23\n",
      "langgraph-prebuilt                       0.1.7\n",
      "langgraph-sdk                            0.1.60\n",
      "langserve                                0.3.1\n",
      "langsmith                                0.3.8\n",
      "numpy                                    1.26.4\n",
      "openai                                   1.69.0\n",
      "scipy                                    1.15.2\n",
      "tiktoken                                 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from IPython.display import Markdown\n",
    "from env_key_manager import APIKeyManager\n",
    "\n",
    "# 创建实例\n",
    "key_manager = APIKeyManager()\n",
    "\n",
    "# 设置环境变量\n",
    "key_manager.setup_api_key([\"OPENAI_API_KEY\", \"OPENAI_BASE_URL\", \"LANGSMITH_ENDPOINT\", \"LANGSMITH_API_KEY\", \"LANGSMITH_PROJECT\"])\n",
    "\n",
    "os.environ['LANGSMITH_TRACING'] = \"true\"\n",
    "\n",
    "# 查看Python版本\n",
    "!python -V\n",
    "# 查看安装的库\n",
    "if 'win' in sys.platform.lower():\n",
    "    !pip list | findstr \"lang openai llm tiktoken chromadb cryptography duck unstructured numpy scipy\"\n",
    "else:\n",
    "    !pip list | grep -E \"lang|openai|llm|tiktoken|chromadb|cryptography|duck|unstructured|numpy|scipy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5630b0ca",
   "metadata": {},
   "source": [
    "# 构建检索增强生成（RAG）应用：第一部分\n",
    "\n",
    "大型语言模型（LLMs）最强大的应用之一是复杂的问答（Q&A）聊天机器人。这类应用能够回答关于特定源信息的问题。它们采用了一种称为检索增强生成（Retrieval Augmented Generation，简称[RAG](/docs/concepts/rag/)）的技术。\n",
    "\n",
    "这是一个多部分教程：\n",
    "\n",
    "- [第一部分](/docs/tutorials/rag)（本指南）介绍RAG并逐步演示一个最小化实现方案。\n",
    "- [第二部分](/docs/tutorials/qa_chat_history) 扩展了实现功能，以支持对话式交互和多步骤检索流程。\n",
    "\n",
    "本教程将展示如何构建一个简单的问答应用程序\n",
    "在处理文本数据源的过程中，我们将逐步讲解一个典型的问答流程。\n",
    "架构并重点介绍更多高级问答技术的额外资源。我们还将看到\n",
    "LangSmith 如何帮助我们追踪和理解应用程序。\n",
    "随着我们应用程序的不断发展，LangSmith将变得越来越有用\n",
    "复杂性。\n",
    "\n",
    "如果您已经熟悉基础检索，您可能还会对以下内容感兴趣：\n",
    "这篇[不同检索技术的高级概述](/docs/concepts/retrieval)\n",
    "\n",
    "**注意**：这里我们主要关注非结构化数据的问答。如果您对基于结构化数据的检索增强生成（RAG）感兴趣，请参阅我们关于[SQL数据问答](/docs/tutorials/sql_qa)的教程。\n",
    "\n",
    "## 概述\n",
    "一个典型的RAG应用包含两个主要组件：\n",
    "\n",
    "**索引**：一个用于从数据源摄取数据并建立索引的流水线。*这一过程通常是离线进行的。*\n",
    "\n",
    "**检索与生成**：实际的RAG链式流程，在运行时接收用户查询并从索引中检索相关数据，随后将其传递给模型。\n",
    "\n",
    "注意：本教程的索引部分将主要遵循[语义搜索教程](/docs/tutorials/retrievers)的内容。\n",
    "\n",
    "从原始数据到答案最常见的完整流程如下：\n",
    "\n",
    "### 索引\n",
    "1. **加载**：首先我们需要加载数据。这可以通过[文档加载器](/docs/concepts/document_loaders)来完成。\n",
    "2. **分割**：[文本分割器](/docs/concepts/text_splitters)将大型`文档`拆分为更小的片段。这对数据索引和模型输入都非常有用，因为大片段更难检索，且无法适配模型的有限上下文窗口。\n",
    "3. **存储**：我们需要一个地方来存储和索引分割后的内容，以便后续进行搜索。这通常通过[向量数据库](/docs/concepts/vectorstores)和[嵌入模型](/docs/concepts/embedding_models)来实现。\n",
    "\n",
    "![索引示意图](../../static/img/rag_indexing.png)\n",
    "\n",
    "### 检索与生成\n",
    "4. **检索**：根据用户输入，使用[检索器](/docs/concepts/retrievers)从存储中获取相关的拆分内容。\n",
    "5. **生成**：一个[聊天模型](/docs/concepts/chat_models) / [大语言模型](/docs/concepts/text_llms)通过包含问题及检索数据的提示词来生成答案\n",
    "\n",
    "![检索示意图](../../static/img/rag_retrieval_generation.png)\n",
    "\n",
    "索引完数据后，我们将使用 [LangGraph](https://langchain-ai.github.io/langgraph/) 作为编排框架来实现检索和生成步骤。\n",
    "\n",
    "## 安装\n",
    "\n",
    "### Jupyter Notebook\n",
    "\n",
    "本教程及其他教程或许在 [Jupyter notebooks](https://jupyter.org/) 中运行最为便捷。在交互式环境中学习指南是深入理解它们的绝佳方式。安装方法请参阅 [此处](https://jupyter.org/install)。\n",
    "\n",
    "### 安装\n",
    "\n",
    "本教程需要以下langchain依赖项：\n",
    "\n",
    "import Tabs from '@theme/Tabs';\n",
    "import TabItem from '@theme/TabItem';\n",
    "import CodeBlock from \"@theme/CodeBlock\";\n",
    "\n",
    "<Tabs>\n",
    "  <TabItem value=\"pip\" label=\"Pip\" default>\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1918ba2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1007)'))': /simple/langchain-text-splitters/\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff1b425",
   "metadata": {},
   "source": [
    "  </TabItem>\n",
    "  <TabItem value=\"conda\" label=\"Conda\">\n",
    "<CodeBlock language=\"bash\">conda install langchain-text-splitters langchain-community langgraph -c conda-forge</CodeBlock>\n",
    "  </TabItem>\n",
    "</Tabs>\n",
    "\n",
    "\n",
    "更多详情，请参阅我们的[安装指南](/docs/how_to/installation)。\n",
    "\n",
    "### LangSmith\n",
    "\n",
    "使用LangChain构建的许多应用程序将包含多个步骤，涉及多次LLM调用。\n",
    "随着这些应用变得越来越复杂，能够检查链或代理内部的具体运行情况变得至关重要。\n",
    "最佳实践是使用 [LangSmith](https://smith.langchain.com)。\n",
    "\n",
    "在以上链接完成注册后，请确保设置环境变量以开始记录追踪数据：\n",
    "\n",
    "```shell\n",
    "export LANGSMITH_TRACING=\"true\"\n",
    "export LANGSMITH_API_KEY=\"...\"\n",
    "```\n",
    "\n",
    "```python\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\n",
    "```\n",
    "\n",
    "## 组件\n",
    "\n",
    "我们需要从LangChain的集成套件中选择三个组件。\n",
    "\n",
    "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
    "\n",
    "<ChatModelTabs customVarName=\"llm\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ef9d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b78672-f21e-4827-843e-59514d18ca20",
   "metadata": {},
   "source": [
    "import EmbeddingTabs from \"@theme/EmbeddingTabs\";\n",
    "\n",
    "<EmbeddingTabs/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a199c764-5dfd-45cf-a4d4-731f2c3d474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859ffca8-055e-4f5a-95fe-55906ed1d63f",
   "metadata": {},
   "source": [
    "import VectorStoreTabs from \"@theme/VectorStoreTabs\";\n",
    "\n",
    "<VectorStoreTabs/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4db6b46-ea3f-4994-9d54-d7c84beb50cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "from langchain_core.vectorstores import InMemoryVectorStore # InMemoryVectorStore: 用于存储向量的内存存储器\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b2d316-922c-4318-b72d-486fd6813b94",
   "metadata": {},
   "source": [
    "## 预览\n",
    "\n",
    "在本指南中，我们将构建一个能够回答有关网站内容问题的应用程序。我们将使用的具体网站是[LLM驱动的自主\n",
    "[智能体](https://lilianweng.github.io/posts/2023-06-23-agent/) 博客文章\n",
    "作者 Lilian Weng 的研究成果使我们能够针对内容提出问题\n",
    "帖子。\n",
    "\n",
    "我们可以创建一个简单的索引管道和RAG链来实现这一点，代码量约50行\n",
    "代码行数。\n",
    "\n",
    "```python\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# 加载并分块处理博客内容\n",
    "loader = WebBaseLoader(\n",
    "web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "bs_kwargs=字典(\n",
    "parse_only=bs4.SoupStrainer(\n",
    "class_=(\"文章内容\", \"文章标题\", \"文章头部\")\n",
    ")\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 索引块\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# 定义问答提示\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# 定义应用程序状态\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "# 定义应用步骤\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# 编译应用程序和测试\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "response = graph.invoke({\"question\": \"什么是任务分解？\"})\n",
    "print(response[\"answer\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff8204b-dabc-4790-80ea-50d4cf4fceb0",
   "metadata": {},
   "source": [
    "查看 [LangSmith 文档](https://docs.smith.langchain.com/) 了解更多信息。\n",
    "[追踪](https://smith.langchain.com/public/65030797-7efa-4356-a7bd-b54b3dc70e17/r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa9ea6a-f914-4f50-8e35-52e6c34b8001",
   "metadata": {},
   "source": [
    "## 详细步骤说明\n",
    "\n",
    "让我们逐步解析上述代码，以真正理解其\n",
    "正在进行中。\n",
    "\n",
    "## 1. 索引 {#indexing}\n",
    "\n",
    ":::note\n",
    "\n",
    "本节是[语义搜索教程](/docs/tutorials/retrievers)中内容的精简版本。\n",
    "如果您熟悉[文档加载器](/docs/concepts/document_loaders)、[嵌入模型](/docs/concepts/embedding_models)和[向量数据库](/docs/concepts/vectorstores)的使用，\n",
    "请随时跳转到下一节：[检索与生成](/docs/tutorials/rag/#orchestration)。\n",
    "\n",
    ":::\n",
    "\n",
    "### 加载文档\n",
    "\n",
    "我们需要先加载博客文章内容。可以使用\n",
    "[文档加载器](/docs/concepts/document_loaders)\n",
    "为此，这些对象从数据源加载数据并返回一个\n",
    "列表\n",
    "[文档](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html)\n",
    "对象。\n",
    "\n",
    "在这种情况下，我们将使用\n",
    "[WebBaseLoader](/docs/integrations/document_loaders/web_base),\n",
    "它使用 `urllib` 从网页 URL 加载 HTML，并使用 `BeautifulSoup` 来\n",
    "解析为文本。我们可以通过传递参数来自定义 HTML 到文本的解析方式\n",
    "通过 `bs_kwargs` 将参数传入 `BeautifulSoup` 解析器（参见\n",
    "[BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/)\n",
    "文档](https://beautiful-soup-4.readthedocs.io/en/latest/#beautifulsoup)。\n",
    "在这种情况下，仅包含类名为“post-content”、“post-title”或\n",
    "“post-header”是相关的，因此我们将移除所有其他内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b0971b5-8579-4a89-bd2e-9029dda4c4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总字符数: 43130\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# 只保留全HTML中的文章标题、头部和内容。\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"总字符数: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a560025-fb86-4b7e-9586-da263bbad481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f11795-e19f-4697-bc6e-6d477355a1cd",
   "metadata": {},
   "source": [
    "#### 深入探索\n",
    "\n",
    "`DocumentLoader`：一种对象，用于从数据源加载内容并将其转换为`Documents`列表。\n",
    "\n",
    "- [文档](/docs/how_to#document-loaders):\n",
    "关于如何使用 `DocumentLoaders` 的详细文档\n",
    "- [集成](/docs/integrations/document_loaders/)：160+\n",
    "可供选择的集成方案。\n",
    "- [接口](https://python.langchain.com/api_reference/core/document_loaders/langchain_core.document_loaders.base.BaseLoader.html):\n",
    "基础接口的API参考。\n",
    "\n",
    "### 文档分割\n",
    "\n",
    "我们的加载文档已超过42,000个字符，内容过长无法完整显示\n",
    "许多模型的上下文窗口内。即便是对于那些能够\n",
    "在上下文中完整适配整篇帖子时，模型可能难以准确捕捉\n",
    "超长输入中的信息。\n",
    "\n",
    "为了解决这个问题，我们将把 `Document` 分割成多个块进行嵌入处理，\n",
    "向量存储。这应有助于我们仅检索最相关的部分\n",
    "在博客文章运行时。\n",
    "\n",
    "与[语义搜索教程](/docs/tutorials/retrievers)中一样，我们使用了\n",
    "[递归字符文本分割器](/docs/how_to/recursive_text_splitter)\n",
    "这将递归地使用常见分隔符来分割文档\n",
    "在确保每个数据块大小合适之前持续添加新行。这是\n",
    "适用于通用文本场景的推荐文本分割器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "753e1484-e21b-4f62-9866-b3a5971f88a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "将博客文章拆分为66个子文档。\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # 块大小（字符）\n",
    "    chunk_overlap=200,  # 块重叠（字符）\n",
    "    add_start_index=True,  # 在原始文档中跟踪索引\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"将博客文章拆分为{len(all_splits)}个子文档。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5193e01-6cf1-45b9-9ba5-38caf75162a6",
   "metadata": {},
   "source": [
    "#### 深入探索\n",
    "\n",
    "`TextSplitter`：用于将`Document`列表拆分为更小部分的对象\n",
    "块。`DocumentTransformer` 的子类。\n",
    "\n",
    "- 通过阅读[操作指南文档](/docs/how_to#text-splitters)，了解更多关于使用不同方法拆分文本的信息\n",
    "- [代码（Python 或 JavaScript）](/docs/integrations/document_loaders/source_code)\n",
    "- [科学论文](/docs/integrations/document_loaders/grobid)\n",
    "- [接口](https://python.langchain.com/api_reference/text_splitters/base/langchain_text_splitters.base.TextSplitter.html): 基础接口的API参考文档。\n",
    "\n",
    "`DocumentTransformer`：对列表执行转换操作的对象\n",
    "由 `Document` 对象组成的集合。\n",
    "\n",
    "- [文档](/docs/how_to#text-splitters): 关于如何使用 `DocumentTransformers` 的详细文档\n",
    "- [集成](/docs/integrations/document_transformers/)\n",
    "- [接口](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.transformers.BaseDocumentTransformer.html): 基础接口的API参考文档。\n",
    "\n",
    "### 存储文档\n",
    "\n",
    "现在我们需要为66个文本块建立索引，以便能够对它们进行搜索\n",
    "在运行时。按照[语义搜索教程](/docs/tutorials/retrievers)进行操作，\n",
    "我们的方法是将每个文档分割的内容[嵌入](/docs/concepts/embedding_models/)，并插入这些嵌入向量\n",
    "存入[向量存储](/docs/concepts/vectorstores/)。给定输入查询后，我们便可利用\n",
    "向量搜索以检索相关文档。\n",
    "\n",
    "我们可以通过一条命令嵌入并存储所有文档分割内容\n",
    "使用在[教程开始](/docs/tutorials/rag/#components)时选择的向量存储和嵌入模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00d455e1-c681-4665-9470-58dbeca050d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4941b579-5bfb-4575-a95d-f9d6f12508dd', 'ce3b4b58-c034-4f91-a96c-6a07eef26b0a', 'dbd8b9a2-ebd9-4726-9ed6-59873c40c3d5']\n"
     ]
    }
   ],
   "source": [
    "# 将所有拆分的文档添加到向量存储器中\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57666234-a5b3-4abc-b079-755241bb2b98",
   "metadata": {},
   "source": [
    "#### 深入探索\n",
    "\n",
    "`Embeddings`: 围绕文本嵌入模型的封装器，用于转换\n",
    "文本到嵌入向量。\n",
    "\n",
    "- [文档](/docs/how_to/embed_text): 关于如何使用嵌入的详细文档。\n",
    "- [集成](/docs/integrations/text_embedding/)：提供30多种集成方案供选择。\n",
    "- [接口](https://python.langchain.com/api_reference/core/embeddings/langchain_core.embeddings.Embeddings.html): 基础接口的API参考文档。\n",
    "\n",
    "`VectorStore`：向量数据库的封装器，用于存储和\n",
    "查询嵌入向量。\n",
    "\n",
    "- [文档](/docs/how_to/vectorstores): 关于如何使用向量存储的详细文档。\n",
    "- [集成](/docs/integrations/vectorstores/)：提供40多种集成方案供选择。\n",
    "- [接口](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.base.VectorStore.html): 基础接口的API参考文档。\n",
    "\n",
    "至此，流水线的**索引构建**部分已完成。此时\n",
    "我们拥有一个可查询的向量存储库，其中包含经过分块处理的内容\n",
    "博客文章。针对用户提出的问题，我们理想情况下应当能够返回\n",
    "博客文章中回答该问题的片段。\n",
    "\n",
    "## 2. 检索与生成 {#orchestration}\n",
    "\n",
    "现在让我们来编写实际的应用程序逻辑。我们想要创建一个简单的\n",
    "一款接收用户问题、搜索相关文档的应用程序\n",
    "对于该问题，将检索到的文档和初始问题传递给\n",
    "一个模型，并返回一个答案。\n",
    "\n",
    "在生成阶段，我们将使用[教程开头](/docs/tutorials/rag/#components)选定的聊天模型。\n",
    "\n",
    "我们将使用一个已提交至LangChain提示中心的RAG提示模板\n",
    "([此处](https://smith.langchain.com/hub/rlm/rag-prompt))。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46f378c5-858c-488f-8aef-8b59a6280791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: （问题在这里） \n",
      "Context: （上下文在这里） \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"（上下文在这里）\", \"question\": \"（问题在这里）\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dfe84d-cc19-4227-bee4-56b69508ab11",
   "metadata": {},
   "source": [
    "我们将使用 [LangGraph](https://langchain-ai.github.io/langgraph/) 将检索和生成步骤整合到一个应用程序中。这将带来诸多优势：\n",
    "\n",
    "- 我们可以一次性定义应用逻辑，并自动支持多种调用模式，包括流式调用、异步调用和批量调用。\n",
    "- 我们通过 [LangGraph 平台](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/) 实现了简化的部署流程。\n",
    "- LangSmith 会自动追踪我们应用程序的各个步骤。\n",
    "- 我们可以轻松地为应用程序添加关键功能，包括[持久化](https://langchain-ai.github.io/langgraph/concepts/persistence/)和[人工介入审批](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/)，只需进行最少的代码改动。\n",
    "\n",
    "要使用LangGraph，我们需要定义以下三件事：\n",
    "\n",
    "1. 我们应用程序的状态；\n",
    "2. 我们应用程序的节点（即应用步骤）；\n",
    "3. 应用程序的“控制流”（例如各步骤的执行顺序）。\n",
    "\n",
    "#### 状态:\n",
    "\n",
    "我们应用程序的[状态](https://langchain-ai.github.io/langgraph/concepts/low_level/#state)控制着哪些数据被输入到应用程序、在步骤之间传递以及由应用程序输出。它通常是一个`TypedDict`，但也可以是一个[Pydantic BaseModel](https://langchain-ai.github.io/langgraph/how-tos/state-model/)。\n",
    "\n",
    "对于一个简单的RAG应用，我们只需记录输入问题、检索到的上下文和生成的答案："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bdc7c33-67f4-40c3-a0f5-9b846bc6e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77868d9a-892f-4b2c-b706-850f96b4464f",
   "metadata": {},
   "source": [
    "#### 节点（应用步骤）\n",
    "\n",
    "让我们从一个简单的两步序列开始：检索与生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdabbf44-cbee-46a4-98e4-794fdfc8bb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    \"\"\"检索相关文档\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    \"\"\"生成答案\"\"\"\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ac9dc3-d73d-48c3-be05-4b60e0b8bc17",
   "metadata": {},
   "source": [
    "我们的检索步骤仅使用输入问题进行相似性搜索，而生成步骤则将检索到的上下文和原始问题格式化为聊天模型的提示。\n",
    "\n",
    "#### 控制流程\n",
    "\n",
    "最后，我们将应用程序编译为一个单一的 `graph` 对象。在本例中，我们只是将检索和生成步骤连接成一个单一的序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "418ddefb-9a1d-42bf-9d23-e525268312a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\") # 添加边\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b127f4-8411-4214-8cdd-a281771ab708",
   "metadata": {},
   "source": [
    "LangGraph 还内置了可视化应用程序控制流程的实用工具："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feabc04f-b509-4452-8e2b-d7c7b7585a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f7dc4d-cac8-4be9-b44c-df097dc28c81",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>我需要使用LangGraph吗？</summary>\n",
    "\n",
    "构建RAG应用并不一定需要LangGraph。实际上，我们可以通过单独调用各个组件来实现相同的应用逻辑。\n",
    "\n",
    "```python\n",
    "question = \"...\"\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search(question)\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "prompt = prompt.invoke({\"question\": question, \"context\": docs_content})\n",
    "answer = llm.invoke(prompt)\n",
    "```\n",
    "LangGraph 的优势包括：\n",
    "\n",
    "- 支持多种调用模式：若需实现输出令牌流式传输或分步结果流式传输，当前逻辑需重新编写；\n",
    "- 通过 [LangSmith](https://docs.smith.langchain.com/) 自动支持追踪功能，并通过 [LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/) 实现部署；\n",
    "- 支持持久化、人在回路（human-in-the-loop）及其他特性。\n",
    "\n",
    "许多应用场景需要在对话体验中实现检索增强生成（RAG），以便用户通过有状态的对话获取基于上下文的回答。正如我们将在教程[第二部分](/docs/tutorials/qa_chat_history)中看到的，LangGraph对状态的管理和持久化功能极大地简化了这类应用的开发。\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee9c057-5a08-46a3-8c7d-6a314d1e777d",
   "metadata": {},
   "source": [
    "#### 使用方法\n",
    "\n",
    "让我们来测试我们的应用程序！LangGraph 支持多种调用模式，包括同步、异步和流式处理。\n",
    "\n",
    "调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "663b93ba-f0a7-44c4-a894-fe895bd5b009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [Document(id='dbd8b9a2-ebd9-4726-9ed6-59873c40c3d5', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='e23b43d5-acc2-4eaf-94d5-7516c7961cfa', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='4d2d0a25-9391-4aa6-bc3e-fe1c300c827c', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17803}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.'), Document(id='141b45e4-55f5-49cd-956c-2b76701e2e62', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17413}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:')]\n",
      "\n",
      "\n",
      "Answer: 任务分解是将复杂任务分解为多个更简单的子任务的过程。通过逐步思考，模型可以更有效地处理这些任务，并提高其执行性能。它可以通过简单的提示、任务特定的指令或人类输入来实现。\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\"question\": \"什么是任务分解？\"})\n",
    "\n",
    "print(f'Context: {result[\"context\"]}\\n\\n')\n",
    "print(f'Answer: {result[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef88f30-40ca-476b-808d-794cb72d401f",
   "metadata": {},
   "source": [
    "流程步骤："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6314a96-aab8-4ecc-bbf9-094fa2aa0e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieve': {'context': [Document(id='dbd8b9a2-ebd9-4726-9ed6-59873c40c3d5', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='e23b43d5-acc2-4eaf-94d5-7516c7961cfa', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='4d2d0a25-9391-4aa6-bc3e-fe1c300c827c', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17803}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.'), Document(id='141b45e4-55f5-49cd-956c-2b76701e2e62', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17413}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': '任务分解是将复杂任务分解为更小、更简单的步骤的过程，以便更好地进行规划和执行。使用诸如“逐步思考”的提示技术，模型可以有效地识别任务的各个部分，并在每一步进行推理和评估。这个过程可以通过简单的提示、任务特定指令或人工输入来实现。'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"什么是任务分解？\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f860142d-d50b-4526-a03f-a59a763117fe",
   "metadata": {},
   "source": [
    "流式传输 [令牌](/docs/concepts/tokens/)："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28625cc3-0f77-4143-af51-ce0fd6682120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Task| decomposition| is| the| process| of| breaking| down| complex| tasks| into| smaller|,| more| manageable| steps|.| It| can| be| achieved| through| techniques| like| Chain| of| Thought| (|Co|T|)| prompting|,| which| encourages| the| model| to| think| step| by| step|,| or| through| more| structured| methods| like| the| Tree| of| Thoughts|.| This| approach| not| only| simplifies| task| execution| but| also| provides| insights| into| the| model|'s| reasoning| process|.||"
     ]
    }
   ],
   "source": [
    "for message, metadata in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"messages\"\n",
    "):\n",
    "    print(message.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe09894-0cc5-4427-9a24-aef60d20705f",
   "metadata": {},
   "source": [
    ":::提示\n",
    "\n",
    "对于异步调用，请使用：\n",
    "\n",
    "```python\n",
    "result = await graph.ainvoke(...)\n",
    "async for step in graph.astream(...):\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406534d4-66a3-4c27-b277-2bd2f5930cf5",
   "metadata": {},
   "source": [
    "#### 返回来源\n",
    "\n",
    "请注意，通过将检索到的上下文存储在图表的状态中，我们可以在状态的 `\"context\"` 字段中获取模型生成答案的来源。有关返回来源的更多详细信息，请参阅[本指南](/docs/how_to/qa_sources/)。\n",
    "\n",
    "#### 深入探索\n",
    "\n",
    "[聊天模型](/docs/concepts/chat_models)接收一系列消息并返回一条消息。\n",
    "\n",
    "- [文档](/docs/how_to#chat-models)\n",
    "- [集成](/docs/integrations/chat/)：提供25种以上集成方案供选择。\n",
    "- [接口](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.BaseChatModel.html): 基础接口的API参考文档。\n",
    "\n",
    "**自定义提示词**\n",
    "\n",
    "如上所示，我们可以加载提示（例如，[这个RAG\n",
    "[提示](https://smith.langchain.com/hub/rlm/rag-prompt) 来自提示\n",
    "中心。提示词也可以轻松定制。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "956e7e78-c26c-4d2d-bf2e-4fc41ff40d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"使用以下上下文来回答最终的问题。\n",
    "如果你不知道答案，就说你不知道，不要尝试编造答案。\n",
    "最多使用三句话，并尽量使答案简洁。\n",
    "总是以\"谢谢你问！\"结尾。\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217cf819-da76-4595-8f75-33f931f1f92a",
   "metadata": {},
   "source": [
    "## 查询分析\n",
    "\n",
    "截至目前，我们一直使用原始输入查询执行检索。然而，允许模型为检索目的生成查询具有一些优势，例如：\n",
    "\n",
    "- 除了语义搜索，我们还可以构建结构化过滤器（例如，“查找2020年以来的文档”）。\n",
    "- 该模型能够将用户可能包含多方面内容或无关语言的查询，重写为更有效的搜索查询。\n",
    "\n",
    "[查询分析](/docs/concepts/retrieval/#query-analysis)通过模型将原始用户输入转换或构建为优化的搜索查询。我们可以轻松地在应用程序中加入查询分析步骤。出于演示目的，让我们为向量存储中的文档添加一些元数据。我们将为文档添加一些（人为设计的）可筛选段落。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df00956a-6565-4c05-b201-32854dd2a889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       " 'start_index': 8,\n",
       " 'section': 'beginning'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "\n",
    "all_splits[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114878bd-a334-41ed-8013-ec4ce0a9112b",
   "metadata": {},
   "source": [
    "我们需要更新向量存储中的文档。为此，我们将使用简单的 [InMemoryVectorStore](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.in_memory.InMemoryVectorStore.html)，因为它具备我们所需的特定功能（例如元数据过滤）。请参考向量存储的 [集成文档](/docs/integrations/vectorstores/) 以了解所选向量存储的相关功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebb3cbd7-7c75-4cc0-a198-ff7c54a0c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_documents(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08aaccd-b3df-45e9-8646-d6ea20215e62",
   "metadata": {},
   "source": [
    "接下来，让我们为搜索查询定义一个模式。为此，我们将使用[结构化输出](/docs/concepts/structured_outputs/)。这里我们将查询定义为一个包含字符串查询和文档部分（可以是\"开头\"、\"中间\"或\"结尾\"）的对象，但您可以根据需要自由定义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87f9c8c3-3e99-426d-aa65-fec4b9155c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6399a870-cb06-4219-9b4f-cfa37cb8ab0f",
   "metadata": {},
   "source": [
    "最后，我们在LangGraph应用中增加一个步骤，用于根据用户的原始输入生成查询："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e8fcdcb-a4ff-41c3-97c7-92d81ab29f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    # highlight-next-line\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# highlight-next-line\n",
    "def analyze_query(state: State):\n",
    "    # highlight-next-line\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    # highlight-next-line\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    # highlight-next-line\n",
    "    return {\"query\": query}\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    # highlight-start\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    # highlight-end\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# highlight-start\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "# highlight-end\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a62d34",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>完整代码：</summary>\n",
    "\n",
    "```python\n",
    "from typing import Literal\n",
    "\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "```markdown\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "```\n",
    "from langgraph.graph import START, StateGraph\n",
    "```markdown\n",
    "from typing_extensions import Annotated, List, TypedDict\n",
    "```\n",
    "\n",
    "# 加载并分块处理博客内容\n",
    "```markdown\n",
    "loader = WebBaseLoader(\n",
    "```\n",
    "web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "```markdown\n",
    "bs_kwargs=dict(\n",
    "```\n",
    "```markdown\n",
    "parse_only=bs4.SoupStrainer(\n",
    "```\n",
    "class_=(\"文章内容\", \"文章标题\", \"文章头部\")\n",
    ")\n",
    ")\n",
    "好的,我会按照要求将英文翻译成中文,并保持标准的markdown格式。以下是一个示例翻译:\n",
    "\n",
    "# 欢迎使用翻译助手\n",
    "\n",
    "这是一个**markdown格式**的翻译示例:\n",
    "\n",
    "## 主要功能\n",
    "- 提供准确的翻译服务\n",
    "- 保持原始文档格式\n",
    "- 支持多种语言互译\n",
    "\n",
    "### 使用说明\n",
    "1. 输入需要翻译的文本\n",
    "2. 指定目标语言\n",
    "3. 获取翻译结果\n",
    "\n",
    "> 注意:翻译质量取决于原文的清晰度和专业性\n",
    "\n",
    "如需更多帮助,请访问我们的[官方网站](https://example.com)\n",
    "文档 = 加载器.加载()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# 更新元数据（用于说明用途）\n",
    "total_documents = len(all_splits)\n",
    "三分之一 = 总文档数 // 3\n",
    "\n",
    "for i, document in enumerate(all_splits):\n",
    "如果 i < 第三位：\n",
    "document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "document.metadata[\"section\"] = \"middle\"\n",
    "否则：\n",
    "document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "\n",
    "# 索引块\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_documents(all_splits)\n",
    "\n",
    "\n",
    "# 定义搜索模式\n",
    "```markdown\n",
    "class Search(TypedDict):\n",
    "```\n",
    "\"\"\"搜索查询。\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"要运行的搜索查询。\"]\n",
    "    section: 标注部分\n",
    "`[\"开头\", \"中间\", \"结尾\"]`\n",
    "...，\n",
    "\"待查询的章节。\"\n",
    "    ]\n",
    "\n",
    "# 定义问答提示\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# 定义应用程序状态\n",
    "```markdown\n",
    "class State(TypedDict):\n",
    "```\n",
    "问题: str\n",
    "查询：搜索\n",
    "上下文：文档列表\n",
    "    answer: str\n",
    "\n",
    "\n",
    "```markdown\n",
    "def analyze_query(state: State):\n",
    "```\n",
    "structured_llm = llm.with_structured_output(搜索)\n",
    "query = structured_llm.invoke(state[\"question\"])\n",
    "返回 {\"query\": query}\n",
    "\n",
    "\n",
    "```markdown\n",
    "def retrieve(state: State):\n",
    "```\n",
    "```markdown\n",
    "query = state[\"query\"]\n",
    "```\n",
    "检索到的文档 = 向量存储.相似性搜索(\n",
    "        query[\"query\"],\n",
    "```markdown\n",
    "filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "```\n",
    ")\n",
    "返回 {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "response = llm.invoke(messages)\n",
    "返回 {\"answer\": response.content}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()\n",
    "好的,我会严格按照您的要求进行翻译,确保markdown格式一致。以下是一个示例翻译:\n",
    "\n",
    "# Project Documentation\n",
    "\n",
    "## Introduction\n",
    "This document provides an overview of the XYZ project.\n",
    "\n",
    "### Key Features\n",
    "- Feature 1: Real-time data processing\n",
    "- Feature 2: Cloud-based storage\n",
    "- Feature 3: Cross-platform compatibility\n",
    "\n",
    "## Installation\n",
    "To install the software:\n",
    "1. Download the package from [our website](https://example.com)\n",
    "2. Run `install.sh` in terminal\n",
    "3. Follow the on-screen instructions\n",
    "\n",
    "> Note: Administrator privileges may be required during installation.\n",
    "\n",
    "```python\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "```\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| timeout   | Connection timeout in seconds |\n",
    "| retries   | Number of connection retry attempts |\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a92d539-f85d-434b-b911-51a1cf9b81da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653cf8dc-a201-43ea-9965-02fcfd2fc316",
   "metadata": {},
   "source": [
    "我们可以通过明确要求获取帖子末尾的上下文来测试我们的实现。请注意，模型在其回答中包含了不同的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b420650-2d9e-4f5e-a8d8-ec36ae07423c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': 'end'}}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'retrieve': {'context': [Document(id='d6cef137-e1e8-4ddc-91dc-b62bd33c6020', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39221, 'section': 'end'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.'), Document(id='d1834ae1-eb6a-43d7-a023-08dfa5028799', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39086, 'section': 'end'}, page_content='}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:'), Document(id='ca7f06e4-2c2e-4788-9a81-2418d82213d9', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 32942, 'section': 'end'}, page_content='}\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:'), Document(id='1fcc2736-30f4-4ef6-90f2-c64af92118cb', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 35127, 'section': 'end'}, page_content='\"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'The end of the post highlights that task decomposition faces challenges in long-term planning and adapting to unexpected errors. LLMs struggle with adjusting their plans, making them less robust compared to humans who learn from trial and error. This indicates a limitation in effectively exploring the solution space and handling complex tasks.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What does the end of the post say about Task Decomposition?\"},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5875a48a-c849-4da9-99e0-558b04884fb0",
   "metadata": {},
   "source": [
    "无论是在流式处理的步骤中，还是在[LangSmith追踪记录](https://smith.langchain.com/public/bdbaae61-130c-4338-8b59-9315dfee22a0/r)里，我们现在都能观察到输入到检索步骤的结构化查询。\n",
    "\n",
    "查询分析是一个涉及多种方法的复杂问题。更多示例请参考[操作指南](/docs/how_to/#query-analysis)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e4d779",
   "metadata": {},
   "source": [
    "## 后续步骤\n",
    "\n",
    "我们已经介绍了基于数据构建基础问答应用的步骤：\n",
    "\n",
    "- 使用[文档加载器](/docs/concepts/document_loaders)加载数据\n",
    "- 使用[文本分割器](/docs/concepts/text_splitters)对索引数据进行分块处理，使其更易于模型使用\n",
    "- [嵌入数据](/docs/concepts/embedding_models) 并将数据存储在[向量数据库](/docs/how_to/vectorstores)中\n",
    "- [检索](/docs/concepts/retrievers) 先前存储的文本块以响应传入的问题\n",
    "- 使用检索到的文本块作为上下文生成答案。\n",
    "\n",
    "在[教程第2部分](/docs/tutorials/qa_chat_history)中，我们将扩展当前实现以支持对话式交互和多步骤检索流程。\n",
    "\n",
    "进一步阅读：\n",
    "\n",
    "- [返回来源](/docs/how_to/qa_sources): 了解如何返回源文档\n",
    "- [流式传输](/docs/how_to/streaming): 了解如何流式输出结果及中间步骤\n",
    "- [添加聊天记录](/docs/how_to/message_history): 了解如何为您的应用添加聊天记录功能\n",
    "- [检索概念指南](/docs/concepts/retrieval): 关于特定检索技术的高层次概述"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
