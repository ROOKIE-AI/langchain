{"cells": [{"cell_type": "markdown", "id": "8c5eb99a", "metadata": {}, "source": ["# 如何检查可运行项", "\n", ":::info 前提条件", "\n", "本指南假定您熟悉以下概念：", "- [LangChain 表达式语言 (LCEL)](/docs/concepts/lcel)", "- [链式运行](/docs/how_to/sequence/)", "\n", ":::", "\n", "一旦你使用 [LangChain 表达式语言](/docs/concepts/lcel) 创建了一个可运行对象，通常你会希望检查它以更好地理解其运行机制。本笔记本介绍了一些实现这一目的的方法。", "\n", "本指南展示了几种以编程方式检查链内部步骤的方法。如果您更关注如何调试链中的问题，请参阅[此章节](/docs/how_to/debugging)。", "\n", "首先，让我们创建一个示例链。我们将创建一个用于检索的链："]}, {"cell_type": "code", "execution_count": null, "id": "d816e954", "metadata": {}, "outputs": [], "source": ["%pip install -qU langchain langchain-openai faiss-cpu tiktoken"]}, {"cell_type": "code", "execution_count": 2, "id": "139228c2", "metadata": {}, "outputs": [], "source": ["from langchain_community.vectorstores import FAISS\n", "from langchain_core.output_parsers import StrOutputParser\n", "from langchain_core.prompts import ChatPromptTemplate\n", "from langchain_core.runnables import RunnablePassthrough\n", "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n", "\n", "vectorstore = FAISS.from_texts(\n", "    [\"harrison worked at kensho\"], embedding=OpenAIEmbeddings()\n", ")\n", "retriever = vectorstore.as_retriever()\n", "\n", "template = \"\"\"Answer the question based only on the following context:\n", "{context}\n", "\n", "Question: {question}\n", "\"\"\"\n", "prompt = ChatPromptTemplate.from_template(template)\n", "\n", "model = ChatOpenAI()\n", "\n", "chain = (\n", "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n", "    | prompt\n", "    | model\n", "    | StrOutputParser()\n", ")"]}, {"cell_type": "markdown", "id": "849e3c42", "metadata": {}, "source": ["## 获取图表", "\n", "你可以使用 `get_graph()` 方法来获取可运行对象的图形表示："]}, {"cell_type": "code", "execution_count": null, "id": "2448b6c2", "metadata": {}, "outputs": [], "source": ["chain.get_graph()"]}, {"cell_type": "markdown", "id": "065b02fb", "metadata": {}, "source": ["## 打印图表", "\n", "虽然这不够清晰易读，但你可以使用 `print_ascii()` 方法以更易懂的方式展示该图表："]}, {"cell_type": "code", "execution_count": 5, "id": "d5ab1515", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["           +---------------------------------+         \n", "           | Parallel<context,question>Input |         \n", "           +---------------------------------+         \n", "                    **               **                \n", "                 ***                   ***             \n", "               **                         **           \n", "+----------------------+              +-------------+  \n", "| VectorStoreRetriever |              | Passthrough |  \n", "+----------------------+              +-------------+  \n", "                    **               **                \n", "                      ***         ***                  \n", "                         **     **                     \n", "           +----------------------------------+        \n", "           | Parallel<context,question>Output |        \n", "           +----------------------------------+        \n", "                             *                         \n", "                             *                         \n", "                             *                         \n", "                  +--------------------+               \n", "                  | ChatPromptTemplate |               \n", "                  +--------------------+               \n", "                             *                         \n", "                             *                         \n", "                             *                         \n", "                      +------------+                   \n", "                      | ChatOpenAI |                   \n", "                      +------------+                   \n", "                             *                         \n", "                             *                         \n", "                             *                         \n", "                   +-----------------+                 \n", "                   | StrOutputParser |                 \n", "                   +-----------------+                 \n", "                             *                         \n", "                             *                         \n", "                             *                         \n", "                +-----------------------+              \n", "                | StrOutputParserOutput |              \n", "                +-----------------------+              \n"]}], "source": ["chain.get_graph().print_ascii()"]}, {"cell_type": "markdown", "id": "2babf851", "metadata": {}, "source": ["## 获取提示", "\n", "你可能想通过 `get_prompts()` 方法查看链式调用中使用的提示词："]}, {"cell_type": "code", "execution_count": 6, "id": "34b2118d", "metadata": {}, "outputs": [{"data": {"text/plain": ["[ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n'))])]"]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": ["chain.get_prompts()"]}, {"cell_type": "markdown", "id": "c5a74bd5", "metadata": {}, "source": ["## 后续步骤", "\n", "你现在已经学会了如何内省你组合的LCEL链。", "\n", "接下来，请查阅本节中关于可运行项的其他操作指南，或参考相关的[链式调试操作指南](/docs/how_to/debugging)。"]}, {"cell_type": "code", "execution_count": null, "id": "ed965769", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.1"}}, "nbformat": 4, "nbformat_minor": 5}