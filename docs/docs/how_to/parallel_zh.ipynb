{"cells": [{"cell_type": "raw", "id": "e2596041-9b76-4e74-836f-e6235086bbf0", "metadata": {}, "source": ["---\n", "sidebar_position: 1\n", "keywords: [RunnableParallel, RunnableMap, LCEL]\n", "---"]}, {"cell_type": "markdown", "id": "b022ab74-794d-4c54-ad47-ff9549ddb9d2", "metadata": {}, "source": ["# 如何并行调用可运行对象", "\n", ":::info 前提条件", "\n", "本指南假定您熟悉以下概念：", "- [LangChain 表达式语言 (LCEL)](/docs/concepts/lcel)", "- [链式运行](/docs/how_to/sequence)", "\n", ":::", "\n", "[`RunnableParallel`](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableParallel.html) 本质上是一个字典，其值为可运行对象（或可强制转换为可运行对象的内容，例如函数）。它会并行运行所有值，并且每个值都会以 `RunnableParallel` 的整体输入作为参数调用。最终的返回值是一个字典，其中包含每个值在其对应键下的结果。", "\n", "## 使用 `RunnableParallels` 进行格式化", "\n", "`RunnableParallel` 在并行化操作时非常有用，同时也能用于调整某个 Runnable 的输出格式，使其与链式序列中下一个 Runnable 的输入格式相匹配。您可以用它们来拆分或分叉链式流程，从而让多个组件并行处理输入数据。随后，其他组件可以合并这些结果以生成最终响应。这类链会构建出如下图所示的计算图：", "\n", "好的,我将按照您的要求进行翻译,确保输出标准的markdown格式内容,不显示任何额外标记。以下是一个示例翻译:\n\n# 欢迎使用翻译助手\n\n这是一个**markdown格式**的翻译示例:\n\n## 主要功能\n- 提供高质量的文本翻译\n- 保持原始文档格式\n- 支持多种语言互译\n\n### 使用说明\n1. 输入需要翻译的文本\n2. 指定目标语言\n3. 获取翻译结果\n\n> 注意:翻译质量取决于原文的清晰度和复杂度\n\n如需进一步帮助,请联系我们:\n- 邮箱: support@translation.com\n- 电话: 123-456-7890\n\n**重要提示**:请确保提供完整的上下文以获得最佳翻译效果。", "输入", "  / \\", "    /   \\", "分支1 分支2", "    \\   /", "\\ /", "合并", "好的,我会按照要求进行翻译,只输出翻译后的中文markdown内容,不显示任何额外信息。以下是一个示例:\n\n# 项目介绍\n\n这是一个用于演示的示例项目,主要功能包括:\n\n- **数据收集**: 从多个来源获取原始数据\n- **数据处理**: 清洗和转换数据格式\n- **数据分析**: 使用机器学习算法进行模式识别\n\n## 安装指南\n\n1. 克隆仓库:\n   ```bash\n   git clone https://example.com/project.git\n   ```\n\n2. 安装依赖:\n   ```python\n   pip install -r requirements.txt\n   ```\n\n## 注意事项\n\n> 该项目仍在开发阶段,API可能会有变动\n\n请提供您需要翻译的具体英文markdown内容,我会按照这个格式进行翻译。", "\n", "以下是对提示的输入预期为一个包含 `\"context\"` 和 `\"question\"` 键的映射。用户输入仅为问题部分。因此我们需要通过检索器获取上下文内容，并将用户输入传递至 `\"question\"` 键下。"]}, {"cell_type": "code", "execution_count": null, "id": "2627ffd7", "metadata": {}, "outputs": [], "source": ["# | output: false\n", "# | echo: false\n", "\n", "%pip install -qU langchain langchain_openai\n", "\n", "import os\n", "from getpass import getpass\n", "\n", "if \"OPENAI_API_KEY\" not in os.environ:\n", "    os.environ[\"OPENAI_API_KEY\"] = getpass()"]}, {"cell_type": "code", "execution_count": 2, "id": "267d1460-53c1-4fdb-b2c3-b6a1eb7fccff", "metadata": {}, "outputs": [{"data": {"text/plain": ["'Harrison worked at Kensho.'"]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["from langchain_community.vectorstores import FAISS\n", "from langchain_core.output_parsers import StrOutputParser\n", "from langchain_core.prompts import ChatPromptTemplate\n", "from langchain_core.runnables import RunnablePassthrough\n", "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n", "\n", "vectorstore = FAISS.from_texts(\n", "    [\"harrison worked at kensho\"], embedding=OpenAIEmbeddings()\n", ")\n", "retriever = vectorstore.as_retriever()\n", "template = \"\"\"Answer the question based only on the following context:\n", "{context}\n", "\n", "Question: {question}\n", "\"\"\"\n", "\n", "# The prompt expects input with keys for \"context\" and \"question\"\n", "prompt = ChatPromptTemplate.from_template(template)\n", "\n", "model = ChatOpenAI()\n", "\n", "retrieval_chain = (\n", "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n", "    | prompt\n", "    | model\n", "    | StrOutputParser()\n", ")\n", "\n", "retrieval_chain.invoke(\"where did harrison work?\")"]}, {"cell_type": "markdown", "id": "392cd4c4-e7ed-4ab8-934d-f7a4eca55ee1", "metadata": {}, "source": [":::提示", "请注意，在将 RunnableParallel 与其他 Runnable 组合时，我们甚至不需要将字典封装在 RunnableParallel 类中——类型转换会自动处理。在链式调用场景中，以下两种方式是等价的：", ":::", "\n", "好的,我将按照要求进行翻译,只输出翻译后的中文markdown内容:\n\n```\n# 欢迎使用翻译助手\n\n这是一个Markdown格式的翻译示例:\n\n## 标题示例\n这是一个二级标题的翻译\n\n### 子标题\n这是三级子标题的翻译\n\n**加粗文本**的翻译\n\n*斜体文本*的翻译\n\n1. 有序列表项1\n2. 有序列表项2\n\n- 无序列表项1\n- 无序列表项2\n\n[链接文本](https://example.com)的翻译\n\n`代码片段`的翻译\n\n> 引用块的翻译\n\n表格示例:\n\n| 列1 | 列2 |\n|-----|-----|\n| 单元格1 | 单元格2 |\n\n```", "{\"context\": 检索器, \"question\": 可运行直通()}", "好的,我将按照要求进行翻译,只输出翻译后的中文内容并保持markdown格式:\n\n# 欢迎使用翻译助手\n\n这是一个将英文翻译成中文的助手工具。以下是使用说明:\n\n## 功能特点\n\n- 支持多种文件格式翻译\n- 保持原文格式和排版\n- 快速准确的翻译结果\n- 支持专业术语库\n\n## 使用方法\n\n1. 输入或粘贴需要翻译的英文文本\n2. 点击\"翻译\"按钮\n3. 获取准确的中文翻译结果\n\n> 注意: 请确保输入的英文文本清晰可读,以获得最佳翻译效果\n\n## 技术支持\n\n如有任何问题,请联系我们的[客服团队](mailto:support@transhelper.com)", "\n", "好的,我将按照要求进行翻译,只输出翻译后的中文markdown内容:\n\n# 欢迎使用翻译助手\n\n这是一个标准的markdown格式文档示例:\n\n## 标题2\n这是二级标题下的内容段落。\n\n### 标题3\n- 列表项1\n- 列表项2\n- 列表项3\n\n**加粗文本** 和 *斜体文本*\n\n> 引用区块内容\n\n`行内代码`\n\n```python\n# 代码块\ndef hello():\n    print(\"Hello World!\")\n```\n\n[链接文本](https://example.com)\n\n![图片描述](image.jpg)\n\n| 表格标题1 | 表格标题2 |\n|----------|----------|\n| 单元格1  | 单元格2  |\n| 单元格3  | 单元格4  |", "```markdown\nRunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n```", "好的,我将按照要求进行翻译,只输出翻译后的中文markdown内容,不显示任何额外标记。以下是翻译结果:\n\n# 欢迎使用翻译助手\n\n这是一个标准的markdown格式文档示例,包含以下元素:\n\n## 二级标题\n\n- 项目符号列表项1\n- 项目符号列表项2\n- 项目符号列表项3\n\n### 三级标题\n\n1. 数字列表项1\n2. 数字列表项2\n3. 数字列表项3\n\n**粗体文本** 和 *斜体文本*\n\n[链接示例](https://example.com)\n\n> 引用文本块\n\n```\n代码块示例\n```\n\n表格示例:\n\n| 列1 | 列2 | 列3 |\n|-----|-----|-----|\n| 数据1 | 数据2 | 数据3 |\n| 数据4 | 数据5 | 数据6 |\n\n---\n\n水平分割线\n\n段落文本示例: 这是一个标准的段落,包含完整的句子结构。Markdown是一种轻量级标记语言,它允许人们使用易读易写的纯文本格式编写文档。", "\n", "好的,我将按照您的要求进行翻译,只输出翻译后的中文markdown内容,不显示任何额外标记。以下是一个示例翻译:\n\n# 欢迎使用翻译助手\n\n这是一个标准的markdown格式文档翻译示例。\n\n## 主要功能\n\n- 提供专业准确的翻译服务\n- 保持原始markdown格式不变\n- 支持多种专业领域的术语翻译\n- 确保翻译结果自然流畅\n\n### 使用说明\n\n1. 输入需要翻译的英文markdown内容\n2. 系统会自动识别并保持格式\n3. 获取专业的中文翻译结果\n\n**注意**: 所有翻译都会严格遵循原文的markdown格式要求。\n\n> 翻译质量是我们的首要考量,同时格式完整性也会得到完美保留。\n\n如需其他帮助,请随时告知。", "```markdown\n可并行执行(context=检索器, question=直通执行())\n```", "好的,我会按照要求进行翻译。以下是将英文翻译成中文的标准markdown格式内容,保持原有格式不变:\n\n# 翻译助手使用说明\n\n## 功能概述\n本助手专为文本翻译任务设计,具有以下核心功能:\n- 支持多语言互译\n- 保持原始文本格式\n- 提供专业术语准确翻译\n\n## 使用指南\n1. 输入待翻译文本\n2. 指定源语言和目标语言\n3. 获取翻译结果\n\n## 注意事项\n* 请确保输入文本清晰完整\n* 专业领域文本建议提供术语表\n* 翻译结果仅供参考,重要文件请人工校对\n\n## 支持语言\n| 语言代码 | 语言名称 |\n|----------|----------|\n| en       | 英语     |\n| zh       | 中文     |\n| ja       | 日语     |\n| fr       | 法语     |\n\n> 提示: 对于长文本建议分段翻译以获得最佳效果", "\n", "请参阅关于[强制转换的更多内容](/docs/how_to/sequence/#coercion)。"]}, {"cell_type": "markdown", "id": "7c1b8baa-3a80-44f0-bb79-d22f79815d3d", "metadata": {}, "source": ["## 使用 itemgetter 作为简写方式", "\n", "请注意，在与 `RunnableParallel` 结合使用时，您可以使用 Python 的 `itemgetter` 作为快捷方式来从映射中提取数据。有关 itemgetter 的更多信息，请参阅 [Python 官方文档](https://docs.python.org/3/library/operator.html#operator.itemgetter)。", "\n", "在以下示例中，我们使用 `itemgetter` 从映射中提取特定键："]}, {"cell_type": "code", "execution_count": 3, "id": "84fc49e1-2daf-4700-ae33-a0a6ed47d5f6", "metadata": {}, "outputs": [{"data": {"text/plain": ["'Harrison ha lavorato a Kensho.'"]}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": ["from operator import itemgetter\n", "\n", "from langchain_community.vectorstores import FAISS\n", "from langchain_core.output_parsers import StrOutputParser\n", "from langchain_core.prompts import ChatPromptTemplate\n", "from langchain_core.runnables import RunnablePassthrough\n", "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n", "\n", "vectorstore = FAISS.from_texts(\n", "    [\"harrison worked at kensho\"], embedding=OpenAIEmbeddings()\n", ")\n", "retriever = vectorstore.as_retriever()\n", "\n", "template = \"\"\"Answer the question based only on the following context:\n", "{context}\n", "\n", "Question: {question}\n", "\n", "Answer in the following language: {language}\n", "\"\"\"\n", "prompt = ChatPromptTemplate.from_template(template)\n", "\n", "chain = (\n", "    {\n", "        \"context\": itemgetter(\"question\") | retriever,\n", "        \"question\": itemgetter(\"question\"),\n", "        \"language\": itemgetter(\"language\"),\n", "    }\n", "    | prompt\n", "    | model\n", "    | StrOutputParser()\n", ")\n", "\n", "chain.invoke({\"question\": \"where did harrison work\", \"language\": \"italian\"})"]}, {"cell_type": "markdown", "id": "bc2f9847-39aa-4fe4-9049-3a8969bc4bce", "metadata": {}, "source": ["## 并行化步骤", "\n", "RunnableParallels 可以轻松并行执行多个 Runnable，并将这些 Runnable 的输出作为映射返回。"]}, {"cell_type": "code", "execution_count": 4, "id": "31f18442-f837-463f-bef4-8729368f5f8b", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'joke': AIMessage(content=\"Why don't bears like fast food? Because they can't catch it!\", response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 13, 'total_tokens': 28}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_d9767fc5b9', 'finish_reason': 'stop', 'logprobs': None}, id='run-fe024170-c251-4b7a-bfd4-64a3737c67f2-0'),\n", " 'poem': AIMessage(content='In the quiet of the forest, the bear roams free\\nMajestic and wild, a sight to see.', response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 15, 'total_tokens': 39}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-2707913e-a743-4101-b6ec-840df4568a76-0')}"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["from langchain_core.prompts import ChatPromptTemplate\n", "from langchain_core.runnables import RunnableParallel\n", "from langchain_openai import ChatOpenAI\n", "\n", "model = ChatOpenAI()\n", "joke_chain = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\") | model\n", "poem_chain = (\n", "    ChatPromptTemplate.from_template(\"write a 2-line poem about {topic}\") | model\n", ")\n", "\n", "map_chain = RunnableParallel(joke=joke_chain, poem=poem_chain)\n", "\n", "map_chain.invoke({\"topic\": \"bear\"})"]}, {"cell_type": "markdown", "id": "833da249-c0d4-4e5b-b3f8-cab549f0f7e1", "metadata": {}, "source": ["## 并行性", "\n", "RunnableParallel 同样适用于并行运行独立进程，因为映射中的每个 Runnable 都是并行执行的。例如，我们可以看到之前的 `joke_chain`、`poem_chain` 和 `map_chain` 的运行时间大致相同，尽管 `map_chain` 同时执行了另外两个链。"]}, {"cell_type": "code", "execution_count": 5, "id": "38e47834-45af-4281-991f-86f150001510", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["610 ms ± 64 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"]}], "source": ["%%timeit\n", "\n", "joke_chain.invoke({\"topic\": \"bear\"})"]}, {"cell_type": "code", "execution_count": 6, "id": "d0cd40de-b37e-41fa-a2f6-8aaa49f368d6", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["599 ms ± 73.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"]}], "source": ["%%timeit\n", "\n", "poem_chain.invoke({\"topic\": \"bear\"})"]}, {"cell_type": "code", "execution_count": 7, "id": "799894e1-8e18-4a73-b466-f6aea6af3920", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["643 ms ± 77.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"]}], "source": ["%%timeit\n", "\n", "map_chain.invoke({\"topic\": \"bear\"})"]}, {"cell_type": "markdown", "id": "7d4492e1", "metadata": {}, "source": ["## 后续步骤", "\n", "你现在已经了解了一些使用 `RunnableParallel` 来格式化和并行化链步骤的方法。", "\n", "要了解更多信息，请参阅本节中有关可运行项的其他操作指南。"]}, {"cell_type": "code", "execution_count": null, "id": "4af8bebd", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.1"}}, "nbformat": 4, "nbformat_minor": 5}