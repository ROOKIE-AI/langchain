{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# 如何将工具输出传递给聊天模型", "\n", ":::info 前提条件", "本指南假定您已熟悉以下概念：", "\n", "- [LangChain 工具](/docs/concepts/tools)", "- [函数/工具调用](/docs/concepts/tool_calling)", "- [使用聊天模型调用工具](/docs/how_to/tool_calling)", "- [定义自定义工具](/docs/how_to/custom_tools/)", "\n", ":::", "\n", "部分模型具备[**工具调用**](/docs/concepts/tool_calling)能力——可生成符合用户自定义模式的参数。本指南将演示如何实际调用这些工具生成的函数，并将结果正确传回模型。", "\n", "![工具调用示意图](/img/tool_invocation.png)", "\n", "![工具调用结果示意图](/img/tool_results.png)", "\n", "首先，让我们定义我们的工具和模型："]}, {"cell_type": "markdown", "metadata": {}, "source": ["import ChatModelTabs from \"@theme/ChatModelTabs\";", "\n", "<ChatModelTabs\n", "customVarName=\"llm\"", "```markdown\noverrideParams={{fireworks: {model: \"accounts/fireworks/models/firefunction-v1\", kwargs: \"temperature=0\"}}}\n```", "/>"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["# | output: false\n", "# | echo: false\n", "\n", "import os\n", "from getpass import getpass\n", "\n", "from langchain_openai import ChatOpenAI\n", "\n", "if \"OPENAI_API_KEY\" not in os.environ:\n", "    os.environ[\"OPENAI_API_KEY\"] = getpass()\n", "\n", "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["from langchain_core.tools import tool\n", "\n", "\n", "@tool\n", "def add(a: int, b: int) -> int:\n", "    \"\"\"Adds a and b.\"\"\"\n", "    return a + b\n", "\n", "\n", "@tool\n", "def multiply(a: int, b: int) -> int:\n", "    \"\"\"Multiplies a and b.\"\"\"\n", "    return a * b\n", "\n", "\n", "tools = [add, multiply]\n", "\n", "llm_with_tools = llm.bind_tools(tools)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["现在，让模型调用一个工具。我们会将其添加到消息列表中，作为对话历史记录来处理："]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_GPGPE943GORirhIAYnWv00rK', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_dm8o64ZrY3WFZHAvCh1bEJ6i', 'type': 'tool_call'}]\n"]}], "source": ["from langchain_core.messages import HumanMessage\n", "\n", "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n", "\n", "messages = [HumanMessage(query)]\n", "\n", "ai_msg = llm_with_tools.invoke(messages)\n", "\n", "print(ai_msg.tool_calls)\n", "\n", "messages.append(ai_msg)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["接下来让我们使用模型填充的参数来调用工具函数！", "\n", "方便的是，如果我们使用 `ToolCall` 调用 LangChain 的 `Tool`，系统会自动返回一个可反馈给模型的 `ToolMessage`：", "\n", ":::caution 兼容性", "\n", "此功能已在 `langchain-core == 0.2.19` 版本中添加。请确保您的软件包已更新至最新版本。", "\n", "如果您使用的是早期版本的 `langchain-core`，则需要从工具中提取 `args` 字段并手动构建 `ToolMessage`。", "\n", ":::"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"data": {"text/plain": ["[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?'),\n", " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_loT2pliJwJe3p7nkgXYF48A1', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_bG9tYZCXOeYDZf3W46TceoV4', 'function': {'arguments': '{\"a\": 11, \"b\": 49}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 87, 'total_tokens': 137}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_661538dc1f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e3db3c46-bf9e-478e-abc1-dc9a264f4afe-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_loT2pliJwJe3p7nkgXYF48A1', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_bG9tYZCXOeYDZf3W46TceoV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 87, 'output_tokens': 50, 'total_tokens': 137}),\n", " ToolMessage(content='36', name='multiply', tool_call_id='call_loT2pliJwJe3p7nkgXYF48A1'),\n", " ToolMessage(content='60', name='add', tool_call_id='call_bG9tYZCXOeYDZf3W46TceoV4')]"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["for tool_call in ai_msg.tool_calls:\n", "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n", "    tool_msg = selected_tool.invoke(tool_call)\n", "    messages.append(tool_msg)\n", "\n", "messages"]}, {"cell_type": "markdown", "metadata": {}, "source": ["最后，我们将调用模型并传入工具返回的结果。该模型将利用这些信息，针对最初的查询生成最终答案："]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"data": {"text/plain": ["AIMessage(content='The result of \\\\(3 \\\\times 12\\\\) is 36, and the result of \\\\(11 + 49\\\\) is 60.', response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 153, 'total_tokens': 184}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_661538dc1f', 'finish_reason': 'stop', 'logprobs': None}, id='run-87d1ef0a-1223-4bb3-9310-7b591789323d-0', usage_metadata={'input_tokens': 153, 'output_tokens': 31, 'total_tokens': 184})"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["llm_with_tools.invoke(messages)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["请注意，每个 `ToolMessage` 必须包含一个 `tool_call_id`，该 ID 需与模型生成的原始工具调用中的 `id` 相匹配。这有助于模型将工具响应与工具调用关联起来。", "\n", "工具调用代理（如[LangGraph](https://langchain-ai.github.io/langgraph/tutorials/introduction/)中的示例）通过以下基础流程来应答查询与解决问题。", "\n", "## 相关", "\n", "- [LangGraph 快速入门](https://langchain-ai.github.io/langgraph/tutorials/introduction/)", "- 少量样本提示 [使用工具](/docs/how_to/tools_few_shot/)", "- 流式处理 [工具调用](/docs/how_to/tool_streaming/)", "- 将[运行时值传递给工具](/docs/how_to/tool_runtime)", "- 从模型获取[结构化输出](/docs/how_to/structured_output/)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.5"}}, "nbformat": 4, "nbformat_minor": 4}