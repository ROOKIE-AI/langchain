{"cells": [{"cell_type": "markdown", "id": "90dff237-bc28-4185-a2c0-d5203bbdeacd", "metadata": {}, "source": ["# 如何追踪大语言模型的令牌使用情况", "\n", "跟踪 [token](/docs/concepts/tokens/) 使用情况以计算成本是将应用程序投入生产的重要环节。本指南将介绍如何从 LangChain 模型调用中获取这些信息。", "\n", ":::info 前提条件", "\n", "本指南假定您熟悉以下概念：", "\n", "- [大型语言模型（LLMs）](/docs/concepts/text_llms)", ":::", "\n", "## 使用LangSmith", "\n", "您可以使用 [LangSmith](https://www.langchain.com/langsmith) 来帮助追踪 LLM 应用中的令牌使用情况。详情请参阅 [LangSmith 快速入门指南](https://docs.smith.langchain.com/)。", "\n", "## 使用回调函数", "\n", "有一些特定于API的回调上下文管理器，允许您跨多个调用跟踪令牌使用情况。您需要检查是否针对您使用的特定模型提供了此类集成。", "\n", "如果您的模型没有此类集成，您可以通过适配 [OpenAI 回调管理器](https://python.langchain.com/api_reference/community/callbacks/langchain_community.callbacks.openai_info.OpenAICallbackHandler.html) 的实现来创建自定义回调管理器。", "\n", "### OpenAI", "\n", "让我们首先看一个极其简单的示例：追踪单个聊天模型调用的令牌使用情况。", "\n", ":::危险", "\n", "回调处理器目前不支持传统语言模型（例如 `langchain_openai.OpenAI`）的流式令牌计数功能。如需在流式场景中获取支持，请参考聊天模型的相关指南[此处](/docs/how_to/chat_token_usage_tracking)。", "\n", "好的,我会按照要求将英文翻译成中文,并保持markdown格式一致。以下是一个示例:\n\n# 标题1\n## 标题2\n### 标题3\n\n这是一个段落文本。\n\n- 无序列表项1\n- 无序列表项2\n- 无序列表项3\n\n1. 有序列表项1\n2. 有序列表项2\n3. 有序列表项3\n\n**加粗文本**  \n*斜体文本*  \n~~删除线文本~~\n\n[链接文本](https://example.com)\n\n![图片描述](image.jpg)\n\n> 引用文本\n\n```python\n# 代码块\ndef hello():\n    print(\"Hello World!\")\n```\n\n| 表头1 | 表头2 |\n|-------|-------|\n| 单元格1 | 单元格2 |\n| 单元格3 | 单元格4 |"]}, {"cell_type": "markdown", "id": "f790edd9-823e-4bc5-befa-e9529c7237a0", "metadata": {}, "source": ["### 单次调用"]}, {"cell_type": "code", "execution_count": 1, "id": "2eebbee2-6ca1-4fa8-a3aa-0376888ceefb", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "Why don't scientists trust atoms?\n", "\n", "Because they make up everything.\n", "---\n", "\n", "Total Tokens: 18\n", "Prompt Tokens: 4\n", "Completion Tokens: 14\n", "Total Cost (USD): $3.4e-05\n"]}], "source": ["from langchain_community.callbacks import get_openai_callback\n", "from langchain_openai import OpenAI\n", "\n", "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")\n", "\n", "with get_openai_callback() as cb:\n", "    result = llm.invoke(\"Tell me a joke\")\n", "    print(result)\n", "    print(\"---\")\n", "print()\n", "\n", "print(f\"Total Tokens: {cb.total_tokens}\")\n", "print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n", "print(f\"Completion Tokens: {cb.completion_tokens}\")\n", "print(f\"Total Cost (USD): ${cb.total_cost}\")"]}, {"cell_type": "markdown", "id": "7df3be35-dd97-4e3a-bd51-52434ab2249d", "metadata": {}, "source": ["### 多次调用", "\n", "在上下文管理器内的所有操作都将被追踪。以下是一个示例，展示如何用它来依次追踪对链式调用的多次调用。这种方法同样适用于可能需要多步骤执行的智能体。"]}, {"cell_type": "code", "execution_count": 2, "id": "3ec10419-294c-44bf-af85-86aabf457cb6", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "Why did the chicken go to the seance?\n", "\n", "To talk to the other side of the road!\n", "--\n", "\n", "\n", "Why did the fish need a lawyer?\n", "\n", "Because it got caught in a net!\n", "\n", "---\n", "Total Tokens: 50\n", "Prompt Tokens: 12\n", "Completion Tokens: 38\n", "Total Cost (USD): $9.400000000000001e-05\n"]}], "source": ["from langchain_community.callbacks import get_openai_callback\n", "from langchain_core.prompts import PromptTemplate\n", "from langchain_openai import OpenAI\n", "\n", "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")\n", "\n", "template = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n", "chain = template | llm\n", "\n", "with get_openai_callback() as cb:\n", "    response = chain.invoke({\"topic\": \"birds\"})\n", "    print(response)\n", "    response = chain.invoke({\"topic\": \"fish\"})\n", "    print(\"--\")\n", "    print(response)\n", "\n", "\n", "print()\n", "print(\"---\")\n", "print(f\"Total Tokens: {cb.total_tokens}\")\n", "print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n", "print(f\"Completion Tokens: {cb.completion_tokens}\")\n", "print(f\"Total Cost (USD): ${cb.total_cost}\")"]}, {"cell_type": "markdown", "id": "ad7a3fba-9fac-4222-8f87-d1d276d27d6e", "metadata": {"tags": []}, "source": ["## 流式传输", "\n", ":::危险", "\n", "`get_openai_callback` 目前不支持传统语言模型（例如 `langchain_openai.OpenAI`）的流式令牌计数。若需在流式场景中正确统计令牌数，可通过以下方式实现：", "\n", "- 按照[本指南](/docs/how_to/chat_token_usage_tracking)所述使用聊天模型；", "- 实现一个[自定义回调处理程序](/docs/how_to/custom_callbacks/)，该处理程序使用适当的标记器来统计标记数量；", "- 使用监控平台，例如 [LangSmith](https://www.langchain.com/langsmith)。", ":::", "\n", "请注意，在流式传输环境中使用传统语言模型时，令牌计数不会更新："]}, {"cell_type": "code", "execution_count": 3, "id": "cd61ed79-7858-49bb-afb5-d41291f597ba", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "Why don't scientists trust atoms?\n", "\n", "Because they make up everything!\n", "\n", "Why don't scientists trust atoms?\n", "\n", "Because they make up everything.\n", "---\n", "\n", "Total Tokens: 0\n", "Prompt Tokens: 0\n", "Completion Tokens: 0\n", "Total Cost (USD): $0.0\n"]}], "source": ["from langchain_community.callbacks import get_openai_callback\n", "from langchain_openai import OpenAI\n", "\n", "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")\n", "\n", "with get_openai_callback() as cb:\n", "    for chunk in llm.stream(\"Tell me a joke\"):\n", "        print(chunk, end=\"\", flush=True)\n", "    print(result)\n", "    print(\"---\")\n", "print()\n", "\n", "print(f\"Total Tokens: {cb.total_tokens}\")\n", "print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n", "print(f\"Completion Tokens: {cb.completion_tokens}\")\n", "print(f\"Total Cost (USD): ${cb.total_cost}\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.4"}}, "nbformat": 4, "nbformat_minor": 5}