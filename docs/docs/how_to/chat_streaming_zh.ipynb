{"cells": [{"cell_type": "raw", "id": "e9437c8a-d8b7-4bf6-8ff4-54068a5a266c", "metadata": {}, "source": ["---\n", "sidebar_position: 1.5\n", "---"]}, {"cell_type": "markdown", "id": "d0df7646-b1e1-4014-a841-6dae9b3c50d9", "metadata": {}, "source": ["# 如何流式传输聊天模型响应", "\n", "\n", "所有[聊天模型](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.BaseChatModel.html)都实现了[Runnable接口](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable)，该接口提供了标准可运行方法的**默认**实现（例如`ainvoke`、`batch`、`abatch`、`stream`、`astream`、`astream_events`）。", "\n", "**默认**的流式实现提供了一个`Iterator`（对于异步流式处理则是`AsyncIterator`），它会产生一个单一值：来自底层聊天模型提供商的最终输出。", "\n", ":::提示", "\n", "**默认**实现**不**支持逐令牌流式传输，但它确保模型可以替换为任何其他模型，因为它支持相同的标准接口。", "\n", ":::", "\n", "逐令牌流式输出能力取决于服务提供商是否已实现正确的流式支持。", "\n", "查看[哪些集成支持逐令牌流式传输](/docs/integrations/chat/)。"]}, {"cell_type": "markdown", "id": "7a76660e-7691-48b7-a2b4-2ccdff7875c3", "metadata": {}, "source": ["## 同步流式传输", "\n", "下面我们用 `|` 来帮助可视化标记之间的分隔符。"]}, {"cell_type": "code", "execution_count": 1, "id": "975c4f32-21f6-4a71-9091-f87b56347c33", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Here| is| a| |1| |verse| song| about| gol|dfish| on| the| moon|:|\n", "\n", "Floating| up| in| the| star|ry| night|,|\n", "Fins| a|-|gl|im|mer| in| the| pale| moon|light|.|\n", "Gol|dfish| swimming|,| peaceful| an|d free|,|\n", "Se|ren|ely| |drif|ting| across| the| lunar| sea|.|"]}], "source": ["from langchain_anthropic.chat_models import ChatAnthropic\n", "\n", "chat = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n", "for chunk in chat.stream(\"Write me a 1 verse song about goldfish on the moon\"):\n", "    print(chunk.content, end=\"|\", flush=True)"]}, {"cell_type": "markdown", "id": "5482d3a7-ee4f-40ba-b871-4d3f52603cd5", "metadata": {"tags": []}, "source": ["## 异步流式处理"]}, {"cell_type": "code", "execution_count": 2, "id": "422f480c-df79-42e8-9bee-d0ebed31c557", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Here| is| a| |1| |verse| song| about| gol|dfish| on| the| moon|:|\n", "\n", "Floating| up| above| the| Earth|,|\n", "Gol|dfish| swim| in| alien| m|irth|.|\n", "In| their| bowl| of| lunar| dust|,|\n", "Gl|it|tering| scales| reflect| the| trust|\n", "Of| swimming| free| in| this| new| worl|d,|\n", "Where| their| aqu|atic| dream|'s| unf|ur|le|d.|"]}], "source": ["from langchain_anthropic.chat_models import ChatAnthropic\n", "\n", "chat = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n", "async for chunk in chat.astream(\"Write me a 1 verse song about goldfish on the moon\"):\n", "    print(chunk.content, end=\"|\", flush=True)"]}, {"cell_type": "markdown", "id": "c61e1309-3b6e-42fb-820a-2e4e3e6bc074", "metadata": {}, "source": ["## Astream 活动", "\n", "聊天模型也支持标准的 [astream events](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.astream_events) 方法。", "\n", "此方法适用于从包含多个步骤的大型LLM应用程序（例如由提示词、LLM和解析器组成的LLM链）中流式传输输出的场景。"]}, {"cell_type": "code", "execution_count": 3, "id": "5a03086e-2813-4cb1-b12b-d00e7eeba122", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'event': 'on_chat_model_start', 'data': {'input': 'Write me a 1 verse song about goldfish on the moon'}, 'name': 'ChatAnthropic', 'tags': [], 'run_id': '1d430164-52b1-4d00-8c00-b16460f7737e', 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'parent_ids': []}\n", "{'event': 'on_chat_model_stream', 'run_id': '1d430164-52b1-4d00-8c00-b16460f7737e', 'name': 'ChatAnthropic', 'tags': [], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-1d430164-52b1-4d00-8c00-b16460f7737e', usage_metadata={'input_tokens': 21, 'output_tokens': 2, 'total_tokens': 23, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})}, 'parent_ids': []}\n", "{'event': 'on_chat_model_stream', 'run_id': '1d430164-52b1-4d00-8c00-b16460f7737e', 'name': 'ChatAnthropic', 'tags': [], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content=\"Here's\", additional_kwargs={}, response_metadata={}, id='run-1d430164-52b1-4d00-8c00-b16460f7737e')}, 'parent_ids': []}\n", "{'event': 'on_chat_model_stream', 'run_id': '1d430164-52b1-4d00-8c00-b16460f7737e', 'name': 'ChatAnthropic', 'tags': [], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content=' a short one-verse song', additional_kwargs={}, response_metadata={}, id='run-1d430164-52b1-4d00-8c00-b16460f7737e')}, 'parent_ids': []}\n", "...Truncated\n"]}], "source": ["from langchain_anthropic.chat_models import ChatAnthropic\n", "\n", "chat = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n", "idx = 0\n", "\n", "async for event in chat.astream_events(\n", "    \"Write me a 1 verse song about goldfish on the moon\"\n", "):\n", "    idx += 1\n", "    if idx >= 5:  # Truncate the output\n", "        print(\"...Truncated\")\n", "        break\n", "    print(event)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.4"}}, "nbformat": 4, "nbformat_minor": 5}