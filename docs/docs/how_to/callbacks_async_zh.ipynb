{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# 如何在异步环境中使用回调函数", "\n", ":::info 前提条件", "\n", "本指南假定您熟悉以下概念：", "\n", "- [回调函数](/docs/concepts/callbacks)", "- [自定义回调处理程序](/docs/how_to/custom_callbacks)", ":::", "\n", "如果您计划使用异步API，建议使用并扩展 [`AsyncCallbackHandler`](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.AsyncCallbackHandler.html) 以避免阻塞事件。", "\n", "\n", ":::警告", "如果在使用异步方法运行你的LLM / Chain / Tool / Agent时使用了同步的`CallbackHandler`，它仍然可以工作。然而，在底层，它会被[`run_in_executor`](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.loop.run_in_executor)调用，如果你的`CallbackHandler`不是线程安全的，可能会导致问题。", ":::", "\n", ":::危险", "\n", "如果您使用的是 `python<=3.10`，在从 `RunnableLambda`、`RunnableGenerator` 或 `@tool` 内部调用其他 `runnable` 时，需要记得传递 `config` 或 `callbacks`。如果不这样做，", "回调将不会传播到被调用的子可运行对象中。", "好的,我会按照要求进行翻译,只输出翻译后的中文内容,并保持原有的markdown格式:\n\n:::"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# | output: false\n", "# | echo: false\n", "\n", "%pip install -qU langchain langchain_anthropic\n", "\n", "import getpass\n", "import os\n", "\n", "os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass()"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["zzzz....\n", "Hi! I just woke up. Your llm is starting\n", "Sync handler being called in a `thread_pool_executor`: token: Here\n", "Sync handler being called in a `thread_pool_executor`: token: 's\n", "Sync handler being called in a `thread_pool_executor`: token:  a\n", "Sync handler being called in a `thread_pool_executor`: token:  little\n", "Sync handler being called in a `thread_pool_executor`: token:  joke\n", "Sync handler being called in a `thread_pool_executor`: token:  for\n", "Sync handler being called in a `thread_pool_executor`: token:  you\n", "Sync handler being called in a `thread_pool_executor`: token: :\n", "Sync handler being called in a `thread_pool_executor`: token: \n", "\n", "Why\n", "Sync handler being called in a `thread_pool_executor`: token:  can\n", "Sync handler being called in a `thread_pool_executor`: token: 't\n", "Sync handler being called in a `thread_pool_executor`: token:  a\n", "Sync handler being called in a `thread_pool_executor`: token:  bicycle\n", "Sync handler being called in a `thread_pool_executor`: token:  stan\n", "Sync handler being called in a `thread_pool_executor`: token: d up\n", "Sync handler being called in a `thread_pool_executor`: token:  by\n", "Sync handler being called in a `thread_pool_executor`: token:  itself\n", "Sync handler being called in a `thread_pool_executor`: token: ?\n", "Sync handler being called in a `thread_pool_executor`: token:  Because\n", "Sync handler being called in a `thread_pool_executor`: token:  it\n", "Sync handler being called in a `thread_pool_executor`: token: 's\n", "Sync handler being called in a `thread_pool_executor`: token:  two\n", "Sync handler being called in a `thread_pool_executor`: token: -\n", "Sync handler being called in a `thread_pool_executor`: token: tire\n", "zzzz....\n", "Hi! I just woke up. Your llm is ending\n"]}, {"data": {"text/plain": ["LLMResult(generations=[[ChatGeneration(text=\"Here's a little joke for you:\\n\\nWhy can't a bicycle stand up by itself? Because it's two-tire\", message=AIMessage(content=\"Here's a little joke for you:\\n\\nWhy can't a bicycle stand up by itself? Because it's two-tire\", id='run-8afc89e8-02c0-4522-8480-d96977240bd4-0'))]], llm_output={}, run=[RunInfo(run_id=UUID('8afc89e8-02c0-4522-8480-d96977240bd4'))])"]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["import asyncio\n", "from typing import Any, Dict, List\n", "\n", "from langchain_anthropic import ChatAnthropic\n", "from langchain_core.callbacks import AsyncCallbackHandler, BaseCallbackHandler\n", "from langchain_core.messages import HumanMessage\n", "from langchain_core.outputs import LLMResult\n", "\n", "\n", "class MyCustomSyncHandler(BaseCallbackHandler):\n", "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n", "        print(f\"Sync handler being called in a `thread_pool_executor`: token: {token}\")\n", "\n", "\n", "class MyCustomAsyncHandler(AsyncCallbackHandler):\n", "    \"\"\"Async callback handler that can be used to handle callbacks from langchain.\"\"\"\n", "\n", "    async def on_llm_start(\n", "        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any\n", "    ) -> None:\n", "        \"\"\"Run when chain starts running.\"\"\"\n", "        print(\"zzzz....\")\n", "        await asyncio.sleep(0.3)\n", "        class_name = serialized[\"name\"]\n", "        print(\"Hi! I just woke up. Your llm is starting\")\n", "\n", "    async def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:\n", "        \"\"\"Run when chain ends running.\"\"\"\n", "        print(\"zzzz....\")\n", "        await asyncio.sleep(0.3)\n", "        print(\"Hi! I just woke up. Your llm is ending\")\n", "\n", "\n", "# To enable streaming, we pass in `streaming=True` to the ChatModel constructor\n", "# Additionally, we pass in a list with our custom handler\n", "chat = ChatAnthropic(\n", "    model=\"claude-3-sonnet-20240229\",\n", "    max_tokens=25,\n", "    streaming=True,\n", "    callbacks=[MyCustomSyncHandler(), MyCustomAsyncHandler()],\n", ")\n", "\n", "await chat.agenerate([[HumanMessage(content=\"Tell me a joke\")]])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 后续步骤", "\n", "你现在已经学会了如何创建自己的自定义回调处理程序。", "\n", "接下来，请查阅本节中的其他操作指南，例如[如何向可运行对象附加回调函数](/docs/how_to/callbacks_attach)。"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.6"}}, "nbformat": 4, "nbformat_minor": 4}