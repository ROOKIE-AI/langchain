{"cells": [{"cell_type": "markdown", "id": "70403d4f-50c1-43f8-a7ea-a211167649a5", "metadata": {}, "source": ["# 如何在提取时使用参考示例", "\n", "通过向大语言模型提供参考示例，通常可以提升提取信息的质量。", "\n", "数据提取旨在从文本及其他非结构化或半结构化格式中生成[结构化表示](/docs/concepts/structured_outputs/)。此类场景中常会用到[工具调用](/docs/concepts/tool_calling)的大语言模型功能。本指南演示如何构建工具调用的少样本示例，以引导数据提取类应用的行为模式。", "\n", ":::提示", "本指南重点介绍如何通过工具调用模型来使用示例，但该技术具有普适性，适用于各类场景。", "同时结合JSON或多或少的基于提示的技术。", ":::", "\n", "LangChain 在包含工具调用的LLM消息上实现了[tool-call属性](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html#langchain_core.messages.ai.AIMessage.tool_calls)。更多细节请参阅我们的[工具调用操作指南](/docs/how_to/tool_calling)。为了构建数据提取的参考示例，我们创建了包含以下顺序的聊天记录：", "\n", "- [HumanMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.human.HumanMessage.html) 包含示例输入；", "- [AIMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html) 包含示例工具调用的消息；", "- [工具消息](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolMessage.html) 包含示例工具输出。", "\n", "LangChain采用这一约定，用于在跨LLM模型供应商的对话中结构化工具调用。", "\n", "首先我们构建一个提示模板，其中包含这些消息的占位符："]}, {"cell_type": "code", "execution_count": 1, "id": "89579144-bcb3-490a-8036-86a0a6bcd56b", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:26:41.780410Z", "iopub.status.busy": "2024-09-10T20:26:41.780102Z", "iopub.status.idle": "2024-09-10T20:26:42.147112Z", "shell.execute_reply": "2024-09-10T20:26:42.146838Z"}}, "outputs": [], "source": ["from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n", "\n", "# Define a custom prompt to provide instructions and any additional context.\n", "# 1) You can add examples into the prompt template to improve extraction quality\n", "# 2) Introduce additional parameters to take context into account (e.g., include metadata\n", "#    about the document from which the text was extracted.)\n", "prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\n", "            \"system\",\n", "            \"You are an expert extraction algorithm. \"\n", "            \"Only extract relevant information from the text. \"\n", "            \"If you do not know the value of an attribute asked \"\n", "            \"to extract, return null for the attribute's value.\",\n", "        ),\n", "        # ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓\n", "        MessagesPlaceholder(\"examples\"),  # <-- EXAMPLES!\n", "        # ↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑\n", "        (\"human\", \"{text}\"),\n", "    ]\n", ")"]}, {"cell_type": "markdown", "id": "2484008c-ba1a-42a5-87a1-628a900de7fd", "metadata": {}, "source": ["测试模板："]}, {"cell_type": "code", "execution_count": 2, "id": "610c3025-ea63-4cd7-88bd-c8cbcb4d8a3f", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:26:42.148746Z", "iopub.status.busy": "2024-09-10T20:26:42.148621Z", "iopub.status.idle": "2024-09-10T20:26:42.162044Z", "shell.execute_reply": "2024-09-10T20:26:42.161794Z"}}, "outputs": [{"data": {"text/plain": ["ChatPromptValue(messages=[SystemMessage(content=\"You are an expert extraction algorithm. Only extract relevant information from the text. If you do not know the value of an attribute asked to extract, return null for the attribute's value.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='testing 1 2 3', additional_kwargs={}, response_metadata={}), HumanMessage(content='this is some text', additional_kwargs={}, response_metadata={})])"]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["from langchain_core.messages import (\n", "    HumanMessage,\n", ")\n", "\n", "prompt.invoke(\n", "    {\"text\": \"this is some text\", \"examples\": [HumanMessage(content=\"testing 1 2 3\")]}\n", ")"]}, {"cell_type": "markdown", "id": "368abd80-0cf0-41a7-8224-acf90dd6830d", "metadata": {}, "source": ["## 定义模式", "\n", "让我们复用[提取教程](/docs/tutorials/extraction)中的人员模式。"]}, {"cell_type": "code", "execution_count": 3, "id": "d875a49a-d2cb-4b9e-b5bf-41073bc3905c", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:26:42.163477Z", "iopub.status.busy": "2024-09-10T20:26:42.163391Z", "iopub.status.idle": "2024-09-10T20:26:42.324449Z", "shell.execute_reply": "2024-09-10T20:26:42.324206Z"}}, "outputs": [], "source": ["from typing import List, Optional\n", "\n", "from langchain_openai import ChatOpenAI\n", "from pydantic import BaseModel, Field\n", "\n", "\n", "class Person(BaseModel):\n", "    \"\"\"Information about a person.\"\"\"\n", "\n", "    # ^ Doc-string for the entity Person.\n", "    # This doc-string is sent to the LLM as the description of the schema Person,\n", "    # and it can help to improve extraction results.\n", "\n", "    # Note that:\n", "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n", "    # 2. Each field has a `description` -- this description is used by the LLM.\n", "    # Having a good description can help improve extraction results.\n", "    name: Optional[str] = Field(..., description=\"The name of the person\")\n", "    hair_color: Optional[str] = Field(\n", "        ..., description=\"The color of the person's hair if known\"\n", "    )\n", "    height_in_meters: Optional[str] = Field(..., description=\"Height in METERs\")\n", "\n", "\n", "class Data(BaseModel):\n", "    \"\"\"Extracted data about people.\"\"\"\n", "\n", "    # Creates a model so that we can extract multiple entities.\n", "    people: List[Person]"]}, {"cell_type": "markdown", "id": "96c42162-e4f6-4461-88fd-c76f5aab7e32", "metadata": {}, "source": ["## 定义参考示例", "\n", "示例可以定义为一组输入-输出对的列表。", "\n", "每个示例都包含一个示例 `input` 文本和一个示例 `output`，展示应从文本中提取的内容。", "\n", ":::重要", "这有点过于深入细节了，可以跳过不看。", "\n", "示例的格式需要与所使用的API相匹配（例如工具调用或JSON模式等）。", "\n", "在此，格式化示例将与工具调用API所预期的格式相匹配，因为这是我们正在使用的。", ":::"]}, {"cell_type": "code", "execution_count": 4, "id": "08356810-77ce-4e68-99d9-faa0326f2cee", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:26:42.326100Z", "iopub.status.busy": "2024-09-10T20:26:42.326016Z", "iopub.status.idle": "2024-09-10T20:26:42.329260Z", "shell.execute_reply": "2024-09-10T20:26:42.329014Z"}}, "outputs": [], "source": ["import uuid\n", "from typing import Dict, List, TypedDict\n", "\n", "from langchain_core.messages import (\n", "    AIMessage,\n", "    BaseMessage,\n", "    HumanMessage,\n", "    SystemMessage,\n", "    ToolMessage,\n", ")\n", "from pydantic import BaseModel, Field\n", "\n", "\n", "class Example(TypedDict):\n", "    \"\"\"A representation of an example consisting of text input and expected tool calls.\n", "\n", "    For extraction, the tool calls are represented as instances of pydantic model.\n", "    \"\"\"\n", "\n", "    input: str  # This is the example text\n", "    tool_calls: List[BaseModel]  # Instances of pydantic model that should be extracted\n", "\n", "\n", "def tool_example_to_messages(example: Example) -> List[BaseMessage]:\n", "    \"\"\"Convert an example into a list of messages that can be fed into an LLM.\n", "\n", "    This code is an adapter that converts our example to a list of messages\n", "    that can be fed into a chat model.\n", "\n", "    The list of messages per example corresponds to:\n", "\n", "    1) HumanMessage: contains the content from which content should be extracted.\n", "    2) AIMessage: contains the extracted information from the model\n", "    3) ToolMessage: contains confirmation to the model that the model requested a tool correctly.\n", "\n", "    The ToolMessage is required because some of the chat models are hyper-optimized for agents\n", "    rather than for an extraction use case.\n", "    \"\"\"\n", "    messages: List[BaseMessage] = [HumanMessage(content=example[\"input\"])]\n", "    tool_calls = []\n", "    for tool_call in example[\"tool_calls\"]:\n", "        tool_calls.append(\n", "            {\n", "                \"id\": str(uuid.uuid4()),\n", "                \"args\": tool_call.dict(),\n", "                # The name of the function right now corresponds\n", "                # to the name of the pydantic model\n", "                # This is implicit in the API right now,\n", "                # and will be improved over time.\n", "                \"name\": tool_call.__class__.__name__,\n", "            },\n", "        )\n", "    messages.append(AIMessage(content=\"\", tool_calls=tool_calls))\n", "    tool_outputs = example.get(\"tool_outputs\") or [\n", "        \"You have correctly called this tool.\"\n", "    ] * len(tool_calls)\n", "    for output, tool_call in zip(tool_outputs, tool_calls):\n", "        messages.append(ToolMessage(content=output, tool_call_id=tool_call[\"id\"]))\n", "    return messages"]}, {"cell_type": "markdown", "id": "463aa282-51c4-42bf-9463-6ca3b2c08de6", "metadata": {}, "source": ["接下来让我们定义示例，然后将它们转换为消息格式。"]}, {"cell_type": "code", "execution_count": 5, "id": "7f59a745-5c81-4011-a4c5-a33ec1eca7ef", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:26:42.330580Z", "iopub.status.busy": "2024-09-10T20:26:42.330488Z", "iopub.status.idle": "2024-09-10T20:26:42.332813Z", "shell.execute_reply": "2024-09-10T20:26:42.332598Z"}}, "outputs": [], "source": ["examples = [\n", "    (\n", "        \"The ocean is vast and blue. It's more than 20,000 feet deep. There are many fish in it.\",\n", "        Data(people=[]),\n", "    ),\n", "    (\n", "        \"Fiona traveled far from France to Spain.\",\n", "        Data(people=[Person(name=\"Fiona\", height_in_meters=None, hair_color=None)]),\n", "    ),\n", "]\n", "\n", "\n", "messages = []\n", "\n", "for text, tool_call in examples:\n", "    messages.extend(\n", "        tool_example_to_messages({\"input\": text, \"tool_calls\": [tool_call]})\n", "    )"]}, {"cell_type": "markdown", "id": "6fdbda30-e7e3-46b5-a54a-1769c580af93", "metadata": {}, "source": ["让我们测试一下这个提示"]}, {"cell_type": "code", "execution_count": 6, "id": "976bb7b8-09c4-4a3e-80df-49a483705c08", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:26:42.333955Z", "iopub.status.busy": "2024-09-10T20:26:42.333876Z", "iopub.status.idle": "2024-09-10T20:26:42.336841Z", "shell.execute_reply": "2024-09-10T20:26:42.336635Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["system: content=\"You are an expert extraction algorithm. Only extract relevant information from the text. If you do not know the value of an attribute asked to extract, return null for the attribute's value.\" additional_kwargs={} response_metadata={}\n", "human: content=\"The ocean is vast and blue. It's more than 20,000 feet deep. There are many fish in it.\" additional_kwargs={} response_metadata={}\n", "ai: content='' additional_kwargs={} response_metadata={} tool_calls=[{'name': 'Data', 'args': {'people': []}, 'id': '240159b1-1405-4107-a07c-3c6b91b3d5b7', 'type': 'tool_call'}]\n", "tool: content='You have correctly called this tool.' tool_call_id='240159b1-1405-4107-a07c-3c6b91b3d5b7'\n", "human: content='Fiona traveled far from France to Spain.' additional_kwargs={} response_metadata={}\n", "ai: content='' additional_kwargs={} response_metadata={} tool_calls=[{'name': 'Data', 'args': {'people': [{'name': 'Fiona', 'hair_color': None, 'height_in_meters': None}]}, 'id': '3fc521e4-d1d2-4c20-bf40-e3d72f1068da', 'type': 'tool_call'}]\n", "tool: content='You have correctly called this tool.' tool_call_id='3fc521e4-d1d2-4c20-bf40-e3d72f1068da'\n", "human: content='this is some text' additional_kwargs={} response_metadata={}\n"]}], "source": ["example_prompt = prompt.invoke({\"text\": \"this is some text\", \"examples\": messages})\n", "\n", "for message in example_prompt.messages:\n", "    print(f\"{message.type}: {message}\")"]}, {"cell_type": "markdown", "id": "47b0bbef-bc6b-4535-a8e2-5c84f09d5637", "metadata": {}, "source": ["## 创建提取器", "\n", "让我们选择一个LLM。由于我们正在使用工具调用功能，因此需要一个支持工具调用特性的模型。可用的LLM请参阅[此表格](/docs/integrations/chat)。", "\n", "import ChatModelTabs from \"@theme/ChatModelTabs\";", "\n", "<ChatModelTabs\n", "customVarName=\"llm\"", "overrideParams={{openai: {model: \"gpt-4-0125-preview\", kwargs: \"temperature=0\"}}}", "/>"]}, {"cell_type": "code", "execution_count": 7, "id": "df2e1ee1-69e8-4c4d-b349-95f2e320317b", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:26:42.338001Z", "iopub.status.busy": "2024-09-10T20:26:42.337915Z", "iopub.status.idle": "2024-09-10T20:26:42.349121Z", "shell.execute_reply": "2024-09-10T20:26:42.348908Z"}}, "outputs": [], "source": ["# | output: false\n", "# | echo: false\n", "\n", "from langchain_openai import ChatOpenAI\n", "\n", "llm = ChatOpenAI(model=\"gpt-4-0125-preview\", temperature=0)"]}, {"cell_type": "markdown", "id": "ef21e8cb-c4df-4e12-9be7-37ac9d291d42", "metadata": {}, "source": ["按照[提取教程](/docs/tutorials/extraction)的指引，我们使用`.with_structured_output`方法根据所需模式结构化模型输出："]}, {"cell_type": "code", "execution_count": 8, "id": "dbfea43d-769b-42e9-a76f-ce722f7d6f93", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:26:42.350335Z", "iopub.status.busy": "2024-09-10T20:26:42.350264Z", "iopub.status.idle": "2024-09-10T20:26:42.424894Z", "shell.execute_reply": "2024-09-10T20:26:42.424623Z"}}, "outputs": [], "source": ["runnable = prompt | llm.with_structured_output(\n", "    schema=Data,\n", "    method=\"function_calling\",\n", "    include_raw=False,\n", ")"]}, {"cell_type": "markdown", "id": "58a8139e-f201-4b8e-baf0-16a83e5fa987", "metadata": {}, "source": ["## 没有示例 😿", "\n", "请注意，即便是性能强大的模型也可能在**极其简单**的测试用例上失败！"]}, {"cell_type": "code", "execution_count": 9, "id": "66545cab-af2a-40a4-9dc9-b4110458b7d3", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:26:42.426258Z", "iopub.status.busy": "2024-09-10T20:26:42.426187Z", "iopub.status.idle": "2024-09-10T20:26:46.151633Z", "shell.execute_reply": "2024-09-10T20:26:46.150690Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["people=[Person(name='earth', hair_color='null', height_in_meters='null')]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["people=[Person(name='earth', hair_color='null', height_in_meters='null')]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["people=[]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["people=[Person(name='earth', hair_color='null', height_in_meters='null')]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["people=[]\n"]}], "source": ["for _ in range(5):\n", "    text = \"The solar system is large, but earth has only 1 moon.\"\n", "    print(runnable.invoke({\"text\": text, \"examples\": []}))"]}, {"cell_type": "markdown", "id": "09840f17-ab26-4ea2-8a39-c747103804ec", "metadata": {}, "source": ["## 通过示例说明 😻", "\n", "参考示例有助于修复故障！"]}, {"cell_type": "code", "execution_count": 10, "id": "1c09d805-ec16-4123-aef9-6a5b59499b5c", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:26:46.155346Z", "iopub.status.busy": "2024-09-10T20:26:46.155110Z", "iopub.status.idle": "2024-09-10T20:26:51.810359Z", "shell.execute_reply": "2024-09-10T20:26:51.809636Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["people=[]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["people=[]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["people=[]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["people=[]\n"]}, {"name": "stdout", "output_type": "stream", "text": ["people=[]\n"]}], "source": ["for _ in range(5):\n", "    text = \"The solar system is large, but earth has only 1 moon.\"\n", "    print(runnable.invoke({\"text\": text, \"examples\": messages}))"]}, {"cell_type": "markdown", "id": "3855cad5-dfee-4b42-ad35-b28d4d98902e", "metadata": {}, "source": ["请注意，我们可以在 [Langsmith 追踪记录](https://smith.langchain.com/public/4c436bc2-a1ce-440b-82f5-093947542e40/r) 中将少量示例视为工具调用。", "\n", "而我们在一组阳性样本上保持了性能表现："]}, {"cell_type": "code", "execution_count": 11, "id": "a9b7a762-1b75-4f9f-b9d9-6732dd05802c", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:26:51.813309Z", "iopub.status.busy": "2024-09-10T20:26:51.813150Z", "iopub.status.idle": "2024-09-10T20:26:53.474153Z", "shell.execute_reply": "2024-09-10T20:26:53.473522Z"}}, "outputs": [{"data": {"text/plain": ["Data(people=[Person(name='Harrison', hair_color='black', height_in_meters=None)])"]}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": ["runnable.invoke(\n", "    {\n", "        \"text\": \"My name is Harrison. My hair is black.\",\n", "        \"examples\": messages,\n", "    }\n", ")"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.9"}}, "nbformat": 4, "nbformat_minor": 5}