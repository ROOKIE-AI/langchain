{"cells": [{"cell_type": "raw", "id": "adc7ee09", "metadata": {"vscode": {"languageId": "raw"}}, "source": ["---\n", "keywords: [create_react_agent, create_react_agent()]\n", "---"]}, {"cell_type": "markdown", "id": "457cdc67-1893-4653-8b0c-b185a5947e74", "metadata": {}, "source": ["# 如何从传统LangChain智能体迁移至LangGraph", "\n", ":::info 前提条件", "\n", "本指南假设您熟悉以下概念：", "- [智能体](/docs/concepts/agents)", "- [LangGraph](https://langchain-ai.github.io/langgraph/)", "- [工具调用](/docs/how_to/tool_calling/)", "\n", ":::", "\n", "在此，我们重点探讨如何从传统的LangChain智能体过渡到更为灵活的[LangGraph](https://langchain-ai.github.io/langgraph/)智能体。", "LangChain 代理（特别是 [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor)）拥有多个配置参数。", "在本笔记本中，我们将展示如何通过[create_react_agent](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent)预构建辅助方法，将这些参数映射到LangGraph的反应式代理执行器。", "\n", "\n", ":::note", "在LangGraph中，图结构取代了LangChain的代理执行器。它负责管理代理的循环周期，并将草稿内容作为消息记录在其状态中。而LangChain中的\"代理\"则对应为您所提供的提示词和大型语言模型(LLM)。", ":::", "\n", "\n", "#### 前提条件", "\n", "本操作指南使用 OpenAI 作为大语言模型（LLM）。请安装以下依赖项以运行。"]}, {"cell_type": "code", "execution_count": 1, "id": "662fac50", "metadata": {}, "outputs": [], "source": ["%%capture --no-stderr\n", "%pip install -U langgraph langchain langchain-openai"]}, {"cell_type": "markdown", "id": "6f8ec38f", "metadata": {}, "source": ["然后，设置你的OpenAI API密钥。"]}, {"cell_type": "code", "execution_count": 2, "id": "5fca87ef", "metadata": {}, "outputs": [], "source": ["import getpass\n", "import os\n", "\n", "if \"OPENAI_API_KEY\" not in os.environ:\n", "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API key:\\n\")"]}, {"cell_type": "markdown", "id": "8e50635c-1671-46e6-be65-ce95f8167c2f", "metadata": {}, "source": ["## 基本用法", "\n", "对于基础的工具调用式ReAct风格智能体的创建和使用，其功能是相同的。首先，我们需要定义一个模型和工具，然后利用它们来创建一个智能体。"]}, {"cell_type": "code", "execution_count": 1, "id": "1e425fea-2796-4b99-bee6-9a6ffe73f756", "metadata": {}, "outputs": [], "source": ["from langchain_core.tools import tool\n", "from langchain_openai import ChatOpenAI\n", "\n", "model = ChatOpenAI(model=\"gpt-4o\")\n", "\n", "\n", "@tool\n", "def magic_function(input: int) -> int:\n", "    \"\"\"Applies a magic function to an input.\"\"\"\n", "    return input + 2\n", "\n", "\n", "tools = [magic_function]\n", "\n", "\n", "query = \"what is the value of magic_function(3)?\""]}, {"cell_type": "markdown", "id": "af002033-fe51-4d14-b47c-3e9b483c8395", "metadata": {}, "source": ["对于LangChain的[AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor)，我们定义了一个包含代理临时工作区占位符的提示模板。该代理可通过以下方式调用："]}, {"cell_type": "code", "execution_count": 2, "id": "03ea357c-9c36-4464-b2cc-27bd150e1554", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'input': 'what is the value of magic_function(3)?',\n", " 'output': 'The value of `magic_function(3)` is 5.'}"]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["from langchain.agents import AgentExecutor, create_tool_calling_agent\n", "from langchain_core.prompts import ChatPromptTemplate\n", "\n", "prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\"system\", \"You are a helpful assistant\"),\n", "        (\"human\", \"{input}\"),\n", "        # Placeholders fill up a **list** of messages\n", "        (\"placeholder\", \"{agent_scratchpad}\"),\n", "    ]\n", ")\n", "\n", "\n", "agent = create_tool_calling_agent(model, tools, prompt)\n", "agent_executor = AgentExecutor(agent=agent, tools=tools)\n", "\n", "agent_executor.invoke({\"input\": query})"]}, {"cell_type": "markdown", "id": "94205f3b-fd2b-4fd7-af69-0a3fc313dc88", "metadata": {}, "source": ["LangGraph的[react代理执行器](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent)管理着一个由消息列表定义的状态。它会持续处理该列表，直到代理输出中不再出现工具调用为止。启动时，我们需要输入一个消息列表。输出将包含图的完整状态——在本例中即为完整的对话历史记录。", "\n"]}, {"cell_type": "code", "execution_count": 3, "id": "53a3737a-d167-4255-89bf-20ac37f89a3e", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'input': 'what is the value of magic_function(3)?',\n", " 'output': 'The value of `magic_function(3)` is 5.'}"]}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": ["from langgraph.prebuilt import create_react_agent\n", "\n", "langgraph_agent_executor = create_react_agent(model, tools)\n", "\n", "\n", "messages = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n", "{\n", "    \"input\": query,\n", "    \"output\": messages[\"messages\"][-1].content,\n", "}"]}, {"cell_type": "code", "execution_count": 4, "id": "74ecebe3-512e-409c-a661-bdd5b0a2b782", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'input': 'Pardon?',\n", " 'output': 'The result of applying `magic_function` to the input value 3 is 5.'}"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["message_history = messages[\"messages\"]\n", "\n", "new_query = \"Pardon?\"\n", "\n", "messages = langgraph_agent_executor.invoke(\n", "    {\"messages\": message_history + [(\"human\", new_query)]}\n", ")\n", "{\n", "    \"input\": new_query,\n", "    \"output\": messages[\"messages\"][-1].content,\n", "}"]}, {"cell_type": "markdown", "id": "f4466a4d-e55e-4ece-bee8-2269a0b5677b", "metadata": {}, "source": ["## 提示模板", "\n", "使用传统的LangChain代理时，您需要传入一个提示模板。您可以通过这种方式来控制代理的行为。", "\n", "借助LangGraph的[react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent)，默认情况下是没有提示的。您可以通过以下几种方式实现对代理的类似控制：", "\n", "1. 传入一条系统消息作为输入", "2. 使用系统消息初始化代理", "3. 初始化代理时配置消息转换函数，用于在将图谱状态中的消息传递给模型前进行转换处理。", "4. 使用 [Runnable](/docs/concepts/lcel) 初始化代理，以便在将消息传递给模型之前转换图状态中的消息。这包括传递提示模板。", "\n", "让我们来看看以下所有内容。我们将传入自定义指令，让代理以西班牙语进行回应。", "\n", "首先，使用 `AgentExecutor`："]}, {"cell_type": "code", "execution_count": 5, "id": "a9a11ccd-75e2-4c11-844d-a34870b0ff91", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'input': 'what is the value of magic_function(3)?',\n", " 'output': 'El valor de magic_function(3) es 5.'}"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\"system\", \"You are a helpful assistant. Respond only in Spanish.\"),\n", "        (\"human\", \"{input}\"),\n", "        # Placeholders fill up a **list** of messages\n", "        (\"placeholder\", \"{agent_scratchpad}\"),\n", "    ]\n", ")\n", "\n", "\n", "agent = create_tool_calling_agent(model, tools, prompt)\n", "agent_executor = AgentExecutor(agent=agent, tools=tools)\n", "\n", "agent_executor.invoke({\"input\": query})"]}, {"cell_type": "markdown", "id": "bd5f5500-5ae4-4000-a9fd-8c5a2cc6404d", "metadata": {}, "source": ["现在，让我们将一个自定义系统消息传递给[反应代理执行器](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent)。", "\n", "LangGraph 预构建的 `create_react_agent` 并不直接接收提示模板作为参数，而是接受一个 [`prompt`](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent) 参数。该参数会在调用大语言模型（LLM）之前修改图状态，其取值可为以下四种类型之一：", "\n", "- 一条`系统消息`，会被添加到消息列表的开头。", "- 一个 `string`（字符串），它会被转换为 `SystemMessage` 并添加到消息列表的开头。", "- 一个`Callable`（可调用对象），它应当接收完整的图状态作为输入。其输出随后会被传递给语言模型。", "- 或者是一个 [`Runnable`](/docs/concepts/lcel)，它应该接收完整的图状态。输出随后会传递给语言模型。", "\n", "以下是实际效果展示："]}, {"cell_type": "code", "execution_count": 6, "id": "a9486805-676a-4d19-a5c4-08b41b172989", "metadata": {}, "outputs": [], "source": ["from langchain_core.messages import SystemMessage\n", "from langgraph.prebuilt import create_react_agent\n", "\n", "system_message = \"You are a helpful assistant. Respond only in Spanish.\"\n", "# This could also be a SystemMessage object\n", "# system_message = SystemMessage(content=\"You are a helpful assistant. Respond only in Spanish.\")\n", "\n", "langgraph_agent_executor = create_react_agent(model, tools, prompt=system_message)\n", "\n", "\n", "messages = langgraph_agent_executor.invoke({\"messages\": [(\"user\", query)]})"]}, {"cell_type": "markdown", "id": "fc6059fd-0df7-4b6f-a84c-b5874e983638", "metadata": {}, "source": ["我们也可以传入一个任意函数或可运行对象。该函数/可运行对象应接收图状态作为输入，并输出消息列表。", "我们可以在这里对消息进行各种任意格式化。在这种情况下，让我们在消息列表的开头添加一条系统消息，并在末尾追加另一条用户消息。"]}, {"cell_type": "code", "execution_count": 7, "id": "d369ab45-0c82-45f4-9d3e-8efb8dd47e2c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'input': 'what is the value of magic_function(3)?', 'output': 'El valor de magic_function(3) es 5. ¡Pandamonium!'}\n"]}], "source": ["from langchain_core.messages import HumanMessage, SystemMessage\n", "from langgraph.prebuilt import create_react_agent\n", "from langgraph.prebuilt.chat_agent_executor import AgentState\n", "\n", "prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\"system\", \"You are a helpful assistant. Respond only in Spanish.\"),\n", "        (\"placeholder\", \"{messages}\"),\n", "        (\"user\", \"Also say 'Pandamonium!' after the answer.\"),\n", "    ]\n", ")\n", "\n", "# alternatively, this can be passed as a function, e.g.\n", "# def prompt(state: AgentState):\n", "#     return (\n", "#         [SystemMessage(content=\"You are a helpful assistant. Respond only in Spanish.\")] +\n", "#         state[\"messages\"] +\n", "#         [HumanMessage(content=\"Also say 'Pandamonium!' after the answer.\")]\n", "#     )\n", "\n", "\n", "langgraph_agent_executor = create_react_agent(model, tools, prompt=prompt)\n", "\n", "\n", "messages = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n", "print(\n", "    {\n", "        \"input\": query,\n", "        \"output\": messages[\"messages\"][-1].content,\n", "    }\n", ")"]}, {"cell_type": "markdown", "id": "68df3a09", "metadata": {}, "source": ["## 记忆"]}, {"cell_type": "markdown", "id": "96e7ffc8", "metadata": {}, "source": ["### 在LangChain中", "\n", "借助 LangChain 的 [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter)，您可以添加聊天 [Memory](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.memory) 功能，从而实现多轮对话交互。"]}, {"cell_type": "code", "execution_count": 8, "id": "b97beba5-8f74-430c-9399-91b77c8fa15c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The output of the magic function when the input is 3 is 5.\n", "---\n", "Yes, you mentioned your name is Polly.\n", "---\n", "The output of the magic function when the input is 3 is 5.\n"]}], "source": ["from langchain.agents import AgentExecutor, create_tool_calling_agent\n", "from langchain_core.chat_history import InMemoryChatMessageHistory\n", "from langchain_core.prompts import ChatPromptTemplate\n", "from langchain_core.runnables.history import RunnableWithMessageHistory\n", "from langchain_core.tools import tool\n", "from langchain_openai import ChatOpenAI\n", "\n", "model = ChatOpenAI(model=\"gpt-4o\")\n", "memory = InMemoryChatMessageHistory(session_id=\"test-session\")\n", "prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\"system\", \"You are a helpful assistant.\"),\n", "        # First put the history\n", "        (\"placeholder\", \"{chat_history}\"),\n", "        # Then the new input\n", "        (\"human\", \"{input}\"),\n", "        # Finally the scratchpad\n", "        (\"placeholder\", \"{agent_scratchpad}\"),\n", "    ]\n", ")\n", "\n", "\n", "@tool\n", "def magic_function(input: int) -> int:\n", "    \"\"\"Applies a magic function to an input.\"\"\"\n", "    return input + 2\n", "\n", "\n", "tools = [magic_function]\n", "\n", "\n", "agent = create_tool_calling_agent(model, tools, prompt)\n", "agent_executor = AgentExecutor(agent=agent, tools=tools)\n", "\n", "agent_with_chat_history = RunnableWithMessageHistory(\n", "    agent_executor,\n", "    # This is needed because in most real world scenarios, a session id is needed\n", "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n", "    lambda session_id: memory,\n", "    input_messages_key=\"input\",\n", "    history_messages_key=\"chat_history\",\n", ")\n", "\n", "config = {\"configurable\": {\"session_id\": \"test-session\"}}\n", "print(\n", "    agent_with_chat_history.invoke(\n", "        {\"input\": \"Hi, I'm polly! What's the output of magic_function of 3?\"}, config\n", "    )[\"output\"]\n", ")\n", "print(\"---\")\n", "print(agent_with_chat_history.invoke({\"input\": \"Remember my name?\"}, config)[\"output\"])\n", "print(\"---\")\n", "print(\n", "    agent_with_chat_history.invoke({\"input\": \"what was that output again?\"}, config)[\n", "        \"output\"\n", "    ]\n", ")"]}, {"cell_type": "markdown", "id": "c2a5a32f", "metadata": {}, "source": ["### 在LangGraph中", "\n", "记忆即[持久化](https://langchain-ai.github.io/langgraph/how-tos/persistence/)，亦称[检查点](https://langchain-ai.github.io/langgraph/reference/checkpoints/)。", "\n", "为智能体添加一个 `checkpointer`，即可免费获得聊天记忆功能。"]}, {"cell_type": "code", "execution_count": 9, "id": "baca3dc6-678b-4509-9275-2fd653102898", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["The output of the magic function for the input 3 is 5.\n", "---\n", "Yes, you mentioned that your name is Polly.\n", "---\n", "The output of the magic function for the input 3 was 5.\n"]}], "source": ["from langgraph.checkpoint.memory import MemorySaver  # an in-memory checkpointer\n", "from langgraph.prebuilt import create_react_agent\n", "\n", "system_message = \"You are a helpful assistant.\"\n", "# This could also be a SystemMessage object\n", "# system_message = SystemMessage(content=\"You are a helpful assistant. Respond only in Spanish.\")\n", "\n", "memory = MemorySaver()\n", "langgraph_agent_executor = create_react_agent(\n", "    model, tools, prompt=system_message, checkpointer=memory\n", ")\n", "\n", "config = {\"configurable\": {\"thread_id\": \"test-thread\"}}\n", "print(\n", "    langgraph_agent_executor.invoke(\n", "        {\n", "            \"messages\": [\n", "                (\"user\", \"Hi, I'm polly! What's the output of magic_function of 3?\")\n", "            ]\n", "        },\n", "        config,\n", "    )[\"messages\"][-1].content\n", ")\n", "print(\"---\")\n", "print(\n", "    langgraph_agent_executor.invoke(\n", "        {\"messages\": [(\"user\", \"Remember my name?\")]}, config\n", "    )[\"messages\"][-1].content\n", ")\n", "print(\"---\")\n", "print(\n", "    langgraph_agent_executor.invoke(\n", "        {\"messages\": [(\"user\", \"what was that output again?\")]}, config\n", "    )[\"messages\"][-1].content\n", ")"]}, {"cell_type": "markdown", "id": "d7cf24a8", "metadata": {}, "source": ["## 逐步迭代", "\n", "### 在LangChain中", "\n", "通过 LangChain 的 [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter)，您可以使用 [stream](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream)（或异步的 `astream`）方法或 [iter](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter) 方法来迭代执行步骤。LangGraph 则支持通过 [stream](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream) 实现逐步迭代。"]}, {"cell_type": "code", "execution_count": 10, "id": "e62843c4-1107-41f0-a50b-aea256e28053", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'actions': [ToolAgentAction(tool='magic_function', tool_input={'input': 3}, log=\"\\nInvoking: `magic_function` with `{'input': 3}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7'}, id='run-7a3a5ada-52ec-4df0-bf7d-81e5051b01b4', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'magic_function', 'args': '{\"input\":3}', 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_yyetzabaDBRX9Ml2KyqfKzZM')], 'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7'}, id='run-7a3a5ada-52ec-4df0-bf7d-81e5051b01b4', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'magic_function', 'args': '{\"input\":3}', 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'index': 0, 'type': 'tool_call_chunk'}])]}\n", "{'steps': [AgentStep(action=ToolAgentAction(tool='magic_function', tool_input={'input': 3}, log=\"\\nInvoking: `magic_function` with `{'input': 3}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7'}, id='run-7a3a5ada-52ec-4df0-bf7d-81e5051b01b4', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'magic_function', 'args': '{\"input\":3}', 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_yyetzabaDBRX9Ml2KyqfKzZM'), observation=5)], 'messages': [FunctionMessage(content='5', additional_kwargs={}, response_metadata={}, name='magic_function')]}\n", "{'output': 'The value of `magic_function(3)` is 5.', 'messages': [AIMessage(content='The value of `magic_function(3)` is 5.', additional_kwargs={}, response_metadata={})]}\n"]}], "source": ["from langchain.agents import AgentExecutor, create_tool_calling_agent\n", "from langchain_core.prompts import ChatPromptTemplate\n", "from langchain_core.tools import tool\n", "from langchain_openai import ChatOpenAI\n", "\n", "model = ChatOpenAI(model=\"gpt-4o\")\n", "\n", "\n", "prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\"system\", \"You are a helpful assistant.\"),\n", "        (\"human\", \"{input}\"),\n", "        # Placeholders fill up a **list** of messages\n", "        (\"placeholder\", \"{agent_scratchpad}\"),\n", "    ]\n", ")\n", "\n", "\n", "@tool\n", "def magic_function(input: int) -> int:\n", "    \"\"\"Applies a magic function to an input.\"\"\"\n", "    return input + 2\n", "\n", "\n", "tools = [magic_function]\n", "\n", "agent = create_tool_calling_agent(model, tools, prompt=prompt)\n", "agent_executor = AgentExecutor(agent=agent, tools=tools)\n", "\n", "for step in agent_executor.stream({\"input\": query}):\n", "    print(step)"]}, {"cell_type": "markdown", "id": "46ccbcbf", "metadata": {}, "source": ["### 在LangGraph中", "\n", "在LangGraph中，原生支持通过[stream](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.graph.CompiledGraph.stream)方法或异步的`astream`方法进行处理。"]}, {"cell_type": "code", "execution_count": 11, "id": "076ebc85-f804-4093-a25a-a16334c9898e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_IHTMrjvIHn8gFOX42FstIpr9', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 61, 'total_tokens': 75, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-1a6970da-163a-4e4d-b9b7-7e73b1057f42-0', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_IHTMrjvIHn8gFOX42FstIpr9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 61, 'output_tokens': 14, 'total_tokens': 75, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}}\n", "{'tools': {'messages': [ToolMessage(content='5', name='magic_function', id='51a9d3e4-734d-426f-a5a1-c6597e4efe25', tool_call_id='call_IHTMrjvIHn8gFOX42FstIpr9')]}}\n", "{'agent': {'messages': [AIMessage(content='The value of `magic_function(3)` is 5.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 84, 'total_tokens': 98, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a20a4ee344', 'finish_reason': 'stop', 'logprobs': None}, id='run-73001576-a3dc-4552-8d81-c9ce8aec05b3-0', usage_metadata={'input_tokens': 84, 'output_tokens': 14, 'total_tokens': 98, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}}\n"]}], "source": ["from langgraph.prebuilt import create_react_agent\n", "from langgraph.prebuilt.chat_agent_executor import AgentState\n", "\n", "prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\"system\", \"You are a helpful assistant.\"),\n", "        (\"placeholder\", \"{messages}\"),\n", "    ]\n", ")\n", "\n", "langgraph_agent_executor = create_react_agent(model, tools, prompt=prompt)\n", "\n", "for step in langgraph_agent_executor.stream(\n", "    {\"messages\": [(\"human\", query)]}, stream_mode=\"updates\"\n", "):\n", "    print(step)"]}, {"cell_type": "markdown", "id": "6898ccbc-42b1-4373-954a-2c7b3849fbb0", "metadata": {}, "source": ["## `return_intermediate_steps`", "\n", "### 在LangChain中", "\n", "在AgentExecutor上设置此参数可让用户访问intermediate_steps，该参数将代理操作（例如工具调用）与其结果配对。"]}, {"cell_type": "code", "execution_count": 12, "id": "a2f720f3-c121-4be2-b498-92c16bb44b0a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[(ToolAgentAction(tool='magic_function', tool_input={'input': 3}, log=\"\\nInvoking: `magic_function` with `{'input': 3}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_njTvl2RsVf4q1aMUxoYnJuK1', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7'}, id='run-c9dfe3ab-2db6-4592-851e-89e056aeab32', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_njTvl2RsVf4q1aMUxoYnJuK1', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'magic_function', 'args': '{\"input\":3}', 'id': 'call_njTvl2RsVf4q1aMUxoYnJuK1', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_njTvl2RsVf4q1aMUxoYnJuK1'), 5)]\n"]}], "source": ["agent_executor = AgentExecutor(agent=agent, tools=tools, return_intermediate_steps=True)\n", "result = agent_executor.invoke({\"input\": query})\n", "print(result[\"intermediate_steps\"])"]}, {"cell_type": "markdown", "id": "594f7567-302f-4fa8-85bb-025ac8322162", "metadata": {}, "source": ["### 在LangGraph中", "\n", "默认情况下，LangGraph中的[react代理执行器](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent)会将所有消息附加到中央状态。因此，只需查看完整状态，就能轻松看到任何中间步骤。"]}, {"cell_type": "code", "execution_count": 13, "id": "ef23117a-5ccb-42ce-80c3-ea49a9d3a942", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'messages': [HumanMessage(content='what is the value of magic_function(3)?', additional_kwargs={}, response_metadata={}, id='1abb52c2-4bc2-4d82-bd32-5a24c3976b0f'),\n", "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_XfQD6C7rAalcmicQubkhJVFq', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a20a4ee344', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-34f02786-5b5c-4bb1-bd9e-406c81944a24-0', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_XfQD6C7rAalcmicQubkhJVFq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n", "  ToolMessage(content='5', name='magic_function', id='cbc9fadf-1962-4ed7-b476-348c774652be', tool_call_id='call_XfQD6C7rAalcmicQubkhJVFq'),\n", "  AIMessage(content='The value of `magic_function(3)` is 5.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 78, 'total_tokens': 92, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'stop', 'logprobs': None}, id='run-547e03d2-872d-4008-a38d-b7f739a77df5-0', usage_metadata={'input_tokens': 78, 'output_tokens': 14, 'total_tokens': 92, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}"]}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": ["from langgraph.prebuilt import create_react_agent\n", "\n", "langgraph_agent_executor = create_react_agent(model, tools=tools)\n", "\n", "messages = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n", "\n", "messages"]}, {"cell_type": "markdown", "id": "45b528e5-57e1-450e-8d91-513eab53b543", "metadata": {}, "source": ["## `max_iterations`", "\n", "### 在LangChain中", "\n", "`AgentExecutor` 实现了 `max_iterations` 参数，允许用户在超过指定迭代次数时中止运行。"]}, {"cell_type": "code", "execution_count": 14, "id": "16f189a7-fc78-4cb5-aa16-a94ca06401a6", "metadata": {}, "outputs": [], "source": ["@tool\n", "def magic_function(input: str) -> str:\n", "    \"\"\"Applies a magic function to an input.\"\"\"\n", "    return \"Sorry, there was an error. Please try again.\"\n", "\n", "\n", "tools = [magic_function]"]}, {"cell_type": "code", "execution_count": 15, "id": "c96aefd7-6f6e-4670-aca6-1ac3d4e7871f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n", "\u001b[32;1m\u001b[1;3mLo siento, no puedo decirte directamente el valor de `magic_function(3)`. Si deseas, puedo usar la función mágica para calcularlo. ¿Te gustaría que lo hiciera?\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["{'input': 'what is the value of magic_function(3)?',\n", " 'output': 'Lo siento, no puedo decirte directamente el valor de `magic_function(3)`. Si deseas, puedo usar la función mágica para calcularlo. ¿Te gustaría que lo hiciera?'}"]}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": ["prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\"system\", \"You are a helpful assistant. Respond only in Spanish.\"),\n", "        (\"human\", \"{input}\"),\n", "        # Placeholders fill up a **list** of messages\n", "        (\"placeholder\", \"{agent_scratchpad}\"),\n", "    ]\n", ")\n", "\n", "agent = create_tool_calling_agent(model, tools, prompt)\n", "agent_executor = AgentExecutor(\n", "    agent=agent,\n", "    tools=tools,\n", "    verbose=True,\n", "    max_iterations=3,\n", ")\n", "\n", "agent_executor.invoke({\"input\": query})"]}, {"cell_type": "markdown", "id": "dd3a933f", "metadata": {}, "source": ["### 在LangGraph中", "\n", "在LangGraph中，这通过`recursion_limit`配置参数进行控制。", "\n", "请注意，在 `AgentExecutor` 中，一次“迭代”包含完整的工具调用和执行过程。而在 LangGraph 中，每个步骤都会计入递归限制，因此我们需要乘以二（并加一）才能获得等效结果。", "\n", "如果达到递归限制，LangGraph会抛出一个特定的异常类型，我们可以像处理AgentExecutor一样捕获并管理它。"]}, {"cell_type": "code", "execution_count": 16, "id": "b974a91f-6ae8-4644-83d9-73666258a6db", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["content='what is the value of magic_function(3)?' additional_kwargs={} response_metadata={} id='c2489fe8-e69c-4163-876d-3cce26b28521'\n", "content='' additional_kwargs={'tool_calls': [{'id': 'call_OyNTcO6SDAvZcBlIEknPRrTR', 'function': {'arguments': '{\"input\":\"3\"}', 'name': 'magic_function'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-b65504bb-fa23-4f8a-8d6c-7edb6d16e7ff-0' tool_calls=[{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_OyNTcO6SDAvZcBlIEknPRrTR', 'type': 'tool_call'}] usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n", "content='Sorry, there was an error. Please try again.' name='magic_function' id='f00e0bff-54fe-4726-a1a7-127a59d8f7ed' tool_call_id='call_OyNTcO6SDAvZcBlIEknPRrTR'\n", "content=\"It seems there was an error when trying to compute the value of the magic function with input 3. Let's try again.\" additional_kwargs={'tool_calls': [{'id': 'call_Q020rQoJh4cnh8WglIMnDm4z', 'function': {'arguments': '{\"input\":\"3\"}', 'name': 'magic_function'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 88, 'total_tokens': 128, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-556d8cb2-b47a-4826-b17d-b520982c2475-0' tool_calls=[{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_Q020rQoJh4cnh8WglIMnDm4z', 'type': 'tool_call'}] usage_metadata={'input_tokens': 88, 'output_tokens': 40, 'total_tokens': 128, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n", "content='Sorry, there was an error. Please try again.' name='magic_function' id='777212cd-8381-44db-9762-3f81951ea73e' tool_call_id='call_Q020rQoJh4cnh8WglIMnDm4z'\n", "content=\"It seems there is a persistent issue in computing the value of the magic function with the input 3. Unfortunately, I can't provide the value at this time. If you have any other questions or need further assistance, feel free to ask!\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 150, 'total_tokens': 199, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'stop', 'logprobs': None} id='run-92ec0b90-bc8e-4851-9139-f1d976145ab7-0' usage_metadata={'input_tokens': 150, 'output_tokens': 49, 'total_tokens': 199, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"]}], "source": ["from langgraph.errors import GraphRecursionError\n", "from langgraph.prebuilt import create_react_agent\n", "\n", "RECURSION_LIMIT = 2 * 3 + 1\n", "\n", "langgraph_agent_executor = create_react_agent(model, tools=tools)\n", "\n", "try:\n", "    for chunk in langgraph_agent_executor.stream(\n", "        {\"messages\": [(\"human\", query)]},\n", "        {\"recursion_limit\": RECURSION_LIMIT},\n", "        stream_mode=\"values\",\n", "    ):\n", "        print(chunk[\"messages\"][-1])\n", "except GraphRecursionError:\n", "    print({\"input\": query, \"output\": \"Agent stopped due to max iterations.\"})"]}, {"cell_type": "markdown", "id": "3a527158-ada5-4774-a98b-8272c6b6b2c0", "metadata": {}, "source": ["## `max_execution_time`", "\n", "### 在LangChain中", "\n", "`AgentExecutor` 实现了 `max_execution_time` 参数，允许用户在总运行时间超出限制时中止执行。"]}, {"cell_type": "code", "execution_count": 18, "id": "4b8498fc-a7af-4164-a401-d8714f082306", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n", "\u001b[32;1m\u001b[1;3mLo siento, no tengo la capacidad de evaluar directamente una función llamada \"magic_function\" con el valor 3. Sin embargo, si me proporcionas más detalles sobre qué hace la función o cómo está definida, podría intentar ayudarte a comprender su comportamiento o resolverlo de otra manera.\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["{'input': 'what is the value of magic_function(3)?',\n", " 'output': 'Lo siento, no tengo la capacidad de evaluar directamente una función llamada \"magic_function\" con el valor 3. Sin embargo, si me proporcionas más detalles sobre qué hace la función o cómo está definida, podría intentar ayudarte a comprender su comportamiento o resolverlo de otra manera.'}"]}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}], "source": ["import time\n", "\n", "\n", "@tool\n", "def magic_function(input: str) -> str:\n", "    \"\"\"Applies a magic function to an input.\"\"\"\n", "    time.sleep(2.5)\n", "    return \"Sorry, there was an error. Please try again.\"\n", "\n", "\n", "tools = [magic_function]\n", "\n", "agent = create_tool_calling_agent(model, tools, prompt)\n", "agent_executor = AgentExecutor(\n", "    agent=agent,\n", "    tools=tools,\n", "    max_execution_time=2,\n", "    verbose=True,\n", ")\n", "\n", "agent_executor.invoke({\"input\": query})"]}, {"cell_type": "markdown", "id": "d02eb025", "metadata": {}, "source": ["### 在LangGraph中", "\n", "通过LangGraph的反应代理，您可以在两个层面上控制超时设置。", "\n", "你可以设置 `step_timeout` 来限制每个**步骤**的执行时间："]}, {"cell_type": "code", "execution_count": 19, "id": "b1d8883d-f5c4-444b-b15e-09827f1b9c57", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_UuxSgpGaqzX84sNlKzCVOiRO', 'function': {'arguments': '{\"input\":\"3\"}', 'name': 'magic_function'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-24c94cbd-2962-48cf-a447-af888eb6ef86-0', tool_calls=[{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_UuxSgpGaqzX84sNlKzCVOiRO', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}}\n", "------\n", "{'input': 'what is the value of magic_function(3)?', 'output': 'Agent stopped due to a step timeout.'}\n"]}], "source": ["from langgraph.prebuilt import create_react_agent\n", "\n", "langgraph_agent_executor = create_react_agent(model, tools=tools)\n", "# Set the max timeout for each step here\n", "langgraph_agent_executor.step_timeout = 2\n", "\n", "try:\n", "    for chunk in langgraph_agent_executor.stream({\"messages\": [(\"human\", query)]}):\n", "        print(chunk)\n", "        print(\"------\")\n", "except TimeoutError:\n", "    print({\"input\": query, \"output\": \"Agent stopped due to a step timeout.\"})"]}, {"cell_type": "markdown", "id": "32a9db70", "metadata": {}, "source": ["另一种为整个运行过程设置单一最大超时的方法是直接使用 Python 标准库 [asyncio](https://docs.python.org/3/library/asyncio.html)。"]}, {"cell_type": "code", "execution_count": 20, "id": "f8d5bd03-6e7e-484b-a543-c8c0ab160b69", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_km17xvoY7wJ5yNnXhb5V9D3I', 'function': {'arguments': '{\"input\":\"3\"}', 'name': 'magic_function'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_45c6de4934', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b44a04e5-9b68-4020-be36-98de1593eefc-0', tool_calls=[{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_km17xvoY7wJ5yNnXhb5V9D3I', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}}\n", "------\n", "Task Cancelled.\n"]}], "source": ["import asyncio\n", "\n", "from langgraph.prebuilt import create_react_agent\n", "\n", "langgraph_agent_executor = create_react_agent(model, tools=tools)\n", "\n", "\n", "async def stream(langgraph_agent_executor, inputs):\n", "    async for chunk in langgraph_agent_executor.astream(\n", "        {\"messages\": [(\"human\", query)]}\n", "    ):\n", "        print(chunk)\n", "        print(\"------\")\n", "\n", "\n", "try:\n", "    task = asyncio.create_task(\n", "        stream(langgraph_agent_executor, {\"messages\": [(\"human\", query)]})\n", "    )\n", "    await asyncio.wait_for(task, timeout=3)\n", "except asyncio.TimeoutError:\n", "    print(\"Task Cancelled.\")"]}, {"cell_type": "markdown", "id": "4884ac87", "metadata": {}, "source": ["## `early_stopping_method`", "\n", "### 在LangChain中", "\n", "通过LangChain的[AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter)，您可以配置[early_stopping_method](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.early_stopping_method)来选择两种停止方式：直接返回字符串\"Agent stopped due to iteration limit or time limit.\"（即`\"force\"`模式），或者最后一次提示LLM生成响应（即`\"generate\"`模式）。"]}, {"cell_type": "code", "execution_count": 21, "id": "3f6e2cf2", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Output with early_stopping_method='force':\n", "Agent stopped due to max iterations.\n"]}], "source": ["from langchain.agents import AgentExecutor, create_tool_calling_agent\n", "from langchain_core.prompts import ChatPromptTemplate\n", "from langchain_core.tools import tool\n", "from langchain_openai import ChatOpenAI\n", "\n", "model = ChatOpenAI(model=\"gpt-4o\")\n", "\n", "\n", "prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\"system\", \"You are a helpful assistant.\"),\n", "        (\"human\", \"{input}\"),\n", "        # Placeholders fill up a **list** of messages\n", "        (\"placeholder\", \"{agent_scratchpad}\"),\n", "    ]\n", ")\n", "\n", "\n", "@tool\n", "def magic_function(input: int) -> int:\n", "    \"\"\"Applies a magic function to an input.\"\"\"\n", "    return \"Sorry there was an error, please try again.\"\n", "\n", "\n", "tools = [magic_function]\n", "\n", "agent = create_tool_calling_agent(model, tools, prompt=prompt)\n", "agent_executor = AgentExecutor(\n", "    agent=agent, tools=tools, early_stopping_method=\"force\", max_iterations=1\n", ")\n", "\n", "result = agent_executor.invoke({\"input\": query})\n", "print(\"Output with early_stopping_method='force':\")\n", "print(result[\"output\"])"]}, {"cell_type": "markdown", "id": "706e05c4", "metadata": {}, "source": ["### 在LangGraph中", "\n", "在LangGraph中，由于可以访问完整状态，您可以在智能体外部显式处理响应行为。"]}, {"cell_type": "code", "execution_count": 22, "id": "73cabbc4", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["content='what is the value of magic_function(3)?' additional_kwargs={} response_metadata={} id='81fd2e50-1e6a-4871-87aa-b7c1225913a4'\n", "content='' additional_kwargs={'tool_calls': [{'id': 'call_aaEzj3aO1RTnB0uoc9rYUIhi', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-476bc4b1-b7bf-4607-a31c-ddf09dc814c5-0' tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_aaEzj3aO1RTnB0uoc9rYUIhi', 'type': 'tool_call'}] usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n", "content='Sorry there was an error, please try again.' name='magic_function' id='dcbe7e3e-0ed4-467d-a729-2f45916ff44f' tool_call_id='call_aaEzj3aO1RTnB0uoc9rYUIhi'\n", "content=\"It seems there was an error when trying to compute the value of `magic_function(3)`. Let's try that again.\" additional_kwargs={'tool_calls': [{'id': 'call_jr4R8uJn2pdXF5GZC2Dg3YWS', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 87, 'total_tokens': 127, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-d94b8932-6e9e-4ab1-99f7-7dca89887ffe-0' tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_jr4R8uJn2pdXF5GZC2Dg3YWS', 'type': 'tool_call'}] usage_metadata={'input_tokens': 87, 'output_tokens': 40, 'total_tokens': 127, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n", "{'input': 'what is the value of magic_function(3)?', 'output': 'Agent stopped due to max iterations.'}\n"]}], "source": ["from langgraph.errors import GraphRecursionError\n", "from langgraph.prebuilt import create_react_agent\n", "\n", "RECURSION_LIMIT = 2 * 1 + 1\n", "\n", "langgraph_agent_executor = create_react_agent(model, tools=tools)\n", "\n", "try:\n", "    for chunk in langgraph_agent_executor.stream(\n", "        {\"messages\": [(\"human\", query)]},\n", "        {\"recursion_limit\": RECURSION_LIMIT},\n", "        stream_mode=\"values\",\n", "    ):\n", "        print(chunk[\"messages\"][-1])\n", "except GraphRecursionError:\n", "    print({\"input\": query, \"output\": \"Agent stopped due to max iterations.\"})"]}, {"cell_type": "markdown", "id": "017fe20e", "metadata": {}, "source": ["## `trim_intermediate_steps`", "\n", "### 在LangChain中", "\n", "通过 LangChain 的 [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor)，您可以使用 [trim_intermediate_steps](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.trim_intermediate_steps) 来精简长时间运行代理的中间步骤，该参数可以是整数（表示代理应保留最后 N 步）或自定义函数。", "\n", "例如，我们可以对值进行修剪，使代理仅看到最近的中间步骤。"]}, {"cell_type": "code", "execution_count": 23, "id": "b94bb169", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Call number: 1\n", "Call number: 2\n", "Call number: 3\n", "Call number: 4\n", "Call number: 5\n", "Call number: 6\n", "Call number: 7\n", "Call number: 8\n", "Call number: 9\n", "Call number: 10\n", "Call number: 11\n", "Call number: 12\n", "Call number: 13\n", "Call number: 14\n"]}, {"name": "stderr", "output_type": "stream", "text": ["Stopping agent prematurely due to triggering stop condition\n"]}, {"name": "stdout", "output_type": "stream", "text": ["Call number: 15\n"]}], "source": ["from langchain.agents import AgentExecutor, create_tool_calling_agent\n", "from langchain_core.prompts import ChatPromptTemplate\n", "from langchain_core.tools import tool\n", "from langchain_openai import ChatOpenAI\n", "\n", "model = ChatOpenAI(model=\"gpt-4o\")\n", "\n", "\n", "prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\"system\", \"You are a helpful assistant.\"),\n", "        (\"human\", \"{input}\"),\n", "        # Placeholders fill up a **list** of messages\n", "        (\"placeholder\", \"{agent_scratchpad}\"),\n", "    ]\n", ")\n", "\n", "\n", "magic_step_num = 1\n", "\n", "\n", "@tool\n", "def magic_function(input: int) -> int:\n", "    \"\"\"Applies a magic function to an input.\"\"\"\n", "    global magic_step_num\n", "    print(f\"Call number: {magic_step_num}\")\n", "    magic_step_num += 1\n", "    return input + magic_step_num\n", "\n", "\n", "tools = [magic_function]\n", "\n", "agent = create_tool_calling_agent(model, tools, prompt=prompt)\n", "\n", "\n", "def trim_steps(steps: list):\n", "    # Let's give the agent amnesia\n", "    return []\n", "\n", "\n", "agent_executor = AgentExecutor(\n", "    agent=agent, tools=tools, trim_intermediate_steps=trim_steps\n", ")\n", "\n", "\n", "query = \"Call the magic function 4 times in sequence with the value 3. You cannot call it multiple times at once.\"\n", "\n", "for step in agent_executor.stream({\"input\": query}):\n", "    pass"]}, {"cell_type": "markdown", "id": "3d450c5a", "metadata": {}, "source": ["### 在LangGraph中", "\n", "我们可以像之前传入[提示模板](#prompt-templates)时一样，直接使用[`prompt`](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent)。"]}, {"cell_type": "code", "execution_count": 24, "id": "b309ba9a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Call number: 1\n", "Call number: 2\n", "Call number: 3\n", "Call number: 4\n", "Call number: 5\n", "Call number: 6\n", "Call number: 7\n", "Call number: 8\n", "Call number: 9\n", "Call number: 10\n", "Call number: 11\n", "Call number: 12\n", "Stopping agent prematurely due to triggering stop condition\n"]}], "source": ["from langgraph.errors import GraphRecursionError\n", "from langgraph.prebuilt import create_react_agent\n", "from langgraph.prebuilt.chat_agent_executor import AgentState\n", "\n", "magic_step_num = 1\n", "\n", "\n", "@tool\n", "def magic_function(input: int) -> int:\n", "    \"\"\"Applies a magic function to an input.\"\"\"\n", "    global magic_step_num\n", "    print(f\"Call number: {magic_step_num}\")\n", "    magic_step_num += 1\n", "    return input + magic_step_num\n", "\n", "\n", "tools = [magic_function]\n", "\n", "\n", "def _modify_state_messages(state: AgentState):\n", "    # Give the agent amnesia, only keeping the original user query\n", "    return [(\"system\", \"You are a helpful assistant\"), state[\"messages\"][0]]\n", "\n", "\n", "langgraph_agent_executor = create_react_agent(\n", "    model, tools, prompt=_modify_state_messages\n", ")\n", "\n", "try:\n", "    for step in langgraph_agent_executor.stream(\n", "        {\"messages\": [(\"human\", query)]}, stream_mode=\"updates\"\n", "    ):\n", "        pass\n", "except GraphRecursionError as e:\n", "    print(\"Stopping agent prematurely due to triggering stop condition\")"]}, {"cell_type": "markdown", "id": "41377eb8", "metadata": {}, "source": ["## 后续步骤", "\n", "你现在已经学会了如何将你的LangChain代理执行器迁移到LangGraph。", "\n", "接下来，请查看其他 [LangGraph 使用指南](https://langchain-ai.github.io/langgraph/how-tos/)。"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.4"}}, "nbformat": 4, "nbformat_minor": 5}