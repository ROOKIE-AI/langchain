{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# 如何传递回调构造函数", "\n", ":::info 前提条件", "\n", "本指南假定您熟悉以下概念：", "\n", "- [回调函数](/docs/concepts/callbacks)", "- [自定义回调处理程序](/docs/how_to/custom_callbacks)", "\n", ":::", "\n", "大多数LangChain模块允许您直接将`callbacks`传递到构造函数（即初始化器）中。在这种情况下，回调仅会针对该实例（以及任何嵌套运行）被调用。", "\n", ":::警告", "构造函数回调的作用域仅限于定义它们的对象。它们**不会**被对象的子级继承。这可能会导致令人困惑的行为。", "通常最好将回调函数作为运行时参数传递。", ":::", "\n", "这是一个示例："]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["# | output: false\n", "# | echo: false\n", "\n", "%pip install -qU langchain langchain_anthropic\n", "\n", "import getpass\n", "import os\n", "\n", "os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass()"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Chat model started\n", "Chat model ended, response: generations=[[ChatGeneration(text='1 + 2 = 3', message=AIMessage(content='1 + 2 = 3', response_metadata={'id': 'msg_01CdKsRmeS9WRb8BWnHDEHm7', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 16, 'output_tokens': 13}}, id='run-2d7fdf2a-7405-4e17-97c0-67e6b2a65305-0'))]] llm_output={'id': 'msg_01CdKsRmeS9WRb8BWnHDEHm7', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 16, 'output_tokens': 13}} run=None\n"]}, {"data": {"text/plain": ["AIMessage(content='1 + 2 = 3', response_metadata={'id': 'msg_01CdKsRmeS9WRb8BWnHDEHm7', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 16, 'output_tokens': 13}}, id='run-2d7fdf2a-7405-4e17-97c0-67e6b2a65305-0')"]}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}], "source": ["from typing import Any, Dict, List\n", "\n", "from langchain_anthropic import ChatAnthropic\n", "from langchain_core.callbacks import BaseCallbackHandler\n", "from langchain_core.messages import BaseMessage\n", "from langchain_core.outputs import LLMResult\n", "from langchain_core.prompts import ChatPromptTemplate\n", "\n", "\n", "class LoggingHandler(BaseCallbackHandler):\n", "    def on_chat_model_start(\n", "        self, serialized: Dict[str, Any], messages: List[List[BaseMessage]], **kwargs\n", "    ) -> None:\n", "        print(\"Chat model started\")\n", "\n", "    def on_llm_end(self, response: LLMResult, **kwargs) -> None:\n", "        print(f\"Chat model ended, response: {response}\")\n", "\n", "    def on_chain_start(\n", "        self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs\n", "    ) -> None:\n", "        print(f\"Chain {serialized.get('name')} started\")\n", "\n", "    def on_chain_end(self, outputs: Dict[str, Any], **kwargs) -> None:\n", "        print(f\"Chain ended, outputs: {outputs}\")\n", "\n", "\n", "callbacks = [LoggingHandler()]\n", "llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\", callbacks=callbacks)\n", "prompt = ChatPromptTemplate.from_template(\"What is 1 + {number}?\")\n", "\n", "chain = prompt | llm\n", "\n", "chain.invoke({\"number\": \"2\"})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["你可以看到我们只看到了来自聊天模型运行的事件——没有来自提示或更广泛链的链事件。", "\n", "## 后续步骤", "\n", "你现在已经学会了如何将回调函数传入构造函数。", "\n", "接下来，请查阅本节中的其他操作指南，例如如何[在运行时传递回调函数](/docs/how_to/callbacks_runtime)。"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.4"}}, "nbformat": 4, "nbformat_minor": 4}