{"cells": [{"cell_type": "markdown", "id": "80f15d95-00d8-4c38-a291-07ff2233b4fd", "metadata": {}, "source": ["# å¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰è¾“å‡ºè§£æå™¨", "\n", "åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæ‚¨å¯èƒ½éœ€è¦å®ç°ä¸€ä¸ªè‡ªå®šä¹‰çš„[è§£æå™¨](/docs/concepts/output_parsers/)ï¼Œå°†æ¨¡å‹è¾“å‡ºç»“æ„åŒ–å¤„ç†ä¸ºç‰¹å®šæ ¼å¼ã€‚", "\n", "å®ç°è‡ªå®šä¹‰è§£æå™¨æœ‰ä¸¤ç§æ–¹æ³•ï¼š", "\n", "1. åœ¨[LCEL](/docs/concepts/lcel/)ä¸­ä½¿ç”¨`RunnableLambda`æˆ–`RunnableGenerator`â€”â€”æˆ‘ä»¬å¼ºçƒˆæ¨èåœ¨å¤§å¤šæ•°ç”¨ä¾‹ä¸­é‡‡ç”¨è¿™ç§æ–¹å¼", "2. é€šè¿‡ç»§æ‰¿è‡ªæŸä¸ªç”¨äºè¾“å‡ºçš„è§£æåŸºç±»â€”â€”è¿™æ˜¯è¾ƒä¸ºå¤æ‚çš„å®ç°æ–¹å¼", "\n", "ä¸¤ç§æ–¹æ³•ä¹‹é—´çš„å·®å¼‚å¤§å¤šæ˜¯è¡¨é¢ä¸Šçš„ï¼Œä¸»è¦ä½“ç°åœ¨è§¦å‘çš„å›è°ƒå‡½æ•°ä¸åŒï¼ˆä¾‹å¦‚ `on_chain_start` ä¸ `on_parser_start`ï¼‰ï¼Œä»¥åŠå¯è¿è¡Œ lambda å‡½æ•°ä¸è§£æå™¨åœ¨ LangSmith ç­‰è¿½è¸ªå¹³å°ä¸­çš„å¯è§†åŒ–æ–¹å¼ä¸Šã€‚"]}, {"cell_type": "markdown", "id": "c651cc26-28cb-45d1-9969-d88deff8b819", "metadata": {}, "source": ["## å¯è¿è¡Œçš„Lambdaè¡¨è¾¾å¼ä¸ç”Ÿæˆå™¨", "\n", "æ¨èçš„è§£ææ–¹å¼æ˜¯ä½¿ç”¨**å¯è¿è¡Œlambdaè¡¨è¾¾å¼**å’Œ**å¯è¿è¡Œç”Ÿæˆå™¨**ï¼", "\n", "åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ç¼–å†™ä¸€ä¸ªç®€å•çš„è§£æå™¨ï¼Œç”¨äºåè½¬æ¨¡å‹è¾“å‡ºçš„å¤§å°å†™ã€‚", "\n", "ä¾‹å¦‚ï¼Œå¦‚æœæ¨¡å‹è¾“å‡ºï¼š\"å–µ\"ï¼Œè§£æå™¨å°†ç”Ÿæˆ\"må–µ\"ã€‚"]}, {"cell_type": "code", "execution_count": 1, "id": "6cd7cc21-ec51-4e22-82d0-32c4401f5adc", "metadata": {}, "outputs": [{"data": {"text/plain": ["'hELLO!'"]}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": ["from typing import Iterable\n", "\n", "from langchain_anthropic.chat_models import ChatAnthropic\n", "from langchain_core.messages import AIMessage, AIMessageChunk\n", "\n", "model = ChatAnthropic(model_name=\"claude-2.1\")\n", "\n", "\n", "def parse(ai_message: AIMessage) -> str:\n", "    \"\"\"Parse the AI message.\"\"\"\n", "    return ai_message.content.swapcase()\n", "\n", "\n", "chain = model | parse\n", "chain.invoke(\"hello\")"]}, {"cell_type": "markdown", "id": "eed8baf2-f4c2-44c1-b47d-e9f560af6202", "metadata": {}, "source": [":::æç¤º", "\n", "LCEL åœ¨ä½¿ç”¨ `|` è¯­æ³•ç»„åˆæ—¶ï¼Œä¼šè‡ªåŠ¨å°†å‡½æ•° `parse` å‡çº§ä¸º `RunnableLambda(parse)`ã€‚", "\n", "å¦‚æœä½ ä¸å–œæ¬¢è¿™æ ·ï¼Œå¯ä»¥æ‰‹åŠ¨å¯¼å…¥ `RunnableLambda` ç„¶åè¿è¡Œ `parse = RunnableLambda(parse)`ã€‚", "å¥½çš„ï¼Œè¯·æä¾›éœ€è¦ç¿»è¯‘çš„è‹±æ–‡æ–‡æœ¬ï¼Œæˆ‘ä¼šå°†å…¶ç¿»è¯‘æˆä¸­æ–‡å¹¶ä¿æŒåŸæœ‰çš„Markdownæ ¼å¼ã€‚"]}, {"cell_type": "markdown", "id": "896f52ce-91e2-4c7c-bd62-1f901002ade2", "metadata": {}, "source": ["æµåª’ä½“åŠŸèƒ½æ­£å¸¸å—ï¼Ÿ"]}, {"cell_type": "code", "execution_count": 5, "id": "4e35389a-caa5-4c0d-9d95-48648d0b8d4f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["i'M cLAUDE, AN ai ASSISTANT CREATED BY aNTHROPIC TO BE HELPFUL, HARMLESS, AND HONEST.|"]}], "source": ["for chunk in chain.stream(\"tell me about yourself in one sentence\"):\n", "    print(chunk, end=\"|\", flush=True)"]}, {"cell_type": "markdown", "id": "11c486bb-b2d4-461b-8fd8-19b9e0472129", "metadata": {}, "source": ["ä¸ï¼Œå®ƒä¸ä¼šï¼Œå› ä¸ºè§£æå™¨åœ¨è§£æè¾“å‡ºä¹‹å‰ä¼šå…ˆèšåˆè¾“å…¥ã€‚", "\n", "å¦‚æœæˆ‘ä»¬è¦å®ç°ä¸€ä¸ªæµå¼è§£æå™¨ï¼Œå¯ä»¥è®©è§£æå™¨æ¥å—ä¸€ä¸ªå¯è¿­ä»£çš„è¾“å…¥å¯¹è±¡ï¼Œå¹¶é€šè¿‡ç”Ÿæˆå™¨é€æ­¥äº§å‡ºè§£æç»“æœã€‚", "ç»“æœä¸€ç»è·å–å³å‘ˆç°ã€‚"]}, {"cell_type": "code", "execution_count": 11, "id": "930aa59e-82d0-447c-b711-b416d92a08b7", "metadata": {}, "outputs": [], "source": ["from langchain_core.runnables import RunnableGenerator\n", "\n", "\n", "def streaming_parse(chunks: Iterable[AIMessageChunk]) -> Iterable[str]:\n", "    for chunk in chunks:\n", "        yield chunk.content.swapcase()\n", "\n", "\n", "streaming_parse = RunnableGenerator(streaming_parse)"]}, {"cell_type": "markdown", "id": "62192808-c7e1-4b3a-85f4-b7901de7c0b8", "metadata": {}, "source": [":::é‡è¦", "\n", "è¯·å°†æµå¼è§£æå™¨å°è£…åœ¨ `RunnableGenerator` ä¸­ï¼Œå› ä¸ºæˆ‘ä»¬å¯èƒ½ä¼šåœæ­¢é€šè¿‡ `|` è¯­æ³•è‡ªåŠ¨å‡çº§å®ƒã€‚", "å¥½çš„,æˆ‘ä¼šæŒ‰ç…§è¦æ±‚å°†è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡,å¹¶ä¿æŒmarkdownæ ¼å¼ä¸€è‡´ã€‚ä»¥ä¸‹æ˜¯ä¸åŒ…å«```markdownæ ‡è¯†çš„çº¯å†…å®¹ç¿»è¯‘:\n\n:::"]}, {"cell_type": "code", "execution_count": 12, "id": "c054d4da-66f3-4f11-8137-0734bb3de06c", "metadata": {}, "outputs": [{"data": {"text/plain": ["'hELLO!'"]}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": ["chain = model | streaming_parse\n", "chain.invoke(\"hello\")"]}, {"cell_type": "markdown", "id": "1d344ff2-5c93-49a9-af00-03856d2cbfdb", "metadata": {}, "source": ["è®©æˆ‘ä»¬ç¡®è®¤æµåª’ä½“åŠŸèƒ½æ­£å¸¸è¿ä½œï¼"]}, {"cell_type": "code", "execution_count": 13, "id": "26d746ae-9c5a-4cda-a535-33f555e2e04a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["i|'M| cLAUDE|,| AN| ai| ASSISTANT| CREATED| BY| aN|THROP|IC| TO| BE| HELPFUL|,| HARMLESS|,| AND| HONEST|.|"]}], "source": ["for chunk in chain.stream(\"tell me about yourself in one sentence\"):\n", "    print(chunk, end=\"|\", flush=True)"]}, {"cell_type": "markdown", "id": "24067447-8a5a-4d6b-86a3-4b9cc4b4369b", "metadata": {}, "source": ["## ç»§æ‰¿è§£æåŸºç±»"]}, {"cell_type": "markdown", "id": "9713f547-b2e4-48eb-807f-a0f6f6d0e7e0", "metadata": {}, "source": ["å¦ä¸€ç§å®ç°è§£æå™¨çš„æ–¹æ³•æ˜¯æ ¹æ®éœ€æ±‚ç»§æ‰¿ `BaseOutputParser`ã€`BaseGenerationOutputParser` æˆ–å…¶ä»–åŸºç¡€è§£æå™¨ç±»ã€‚", "\n", "é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬**ä¸å»ºè®®**åœ¨å¤§å¤šæ•°åº”ç”¨åœºæ™¯ä¸­é‡‡ç”¨è¿™ç§æ–¹æ³•ï¼Œå› ä¸ºå®ƒä¼šå¯¼è‡´ä»£ç é‡å¢åŠ ï¼Œå´æ— æ³•å¸¦æ¥æ˜¾è‘—çš„æ”¶ç›Šã€‚", "\n", "æœ€ç®€å•çš„è¾“å‡ºè§£æå™¨ç±»å‹ç»§æ‰¿è‡ª `BaseOutputParser` ç±»ï¼Œä¸”å¿…é¡»å®ç°ä»¥ä¸‹æ–¹æ³•ï¼š", "\n", "* `parse`ï¼šæ¥æ”¶æ¨¡å‹çš„å­—ç¬¦ä¸²è¾“å‡ºå¹¶å¯¹å…¶è¿›è¡Œè§£æ", "* ï¼ˆå¯é€‰ï¼‰`_type`ï¼šæ ‡è¯†è§£æå™¨çš„åç§°ã€‚", "\n", "å½“èŠå¤©æ¨¡å‹æˆ–LLMçš„è¾“å‡ºæ ¼å¼é”™è¯¯æ—¶ï¼Œå¯ä»¥æŠ›å‡ºä¸€ä¸ª`OutputParserException`å¼‚å¸¸ï¼Œä»¥è¡¨æ˜ç”±äºè¾“å…¥é”™è¯¯å¯¼è‡´è§£æå¤±è´¥ã€‚ä½¿ç”¨æ­¤å¼‚å¸¸å¯ä»¥è®©è°ƒç”¨è§£æå™¨çš„ä»£ç ä»¥ä¸€è‡´çš„æ–¹å¼å¤„ç†è¿™äº›å¼‚å¸¸ã€‚", "\n", ":::æç¤º è§£æå™¨ä¹Ÿæ˜¯å¯è¿è¡Œå¯¹è±¡ï¼ğŸƒ", "\n", "ç”±äº `BaseOutputParser` å®ç°äº† `Runnable` æ¥å£ï¼Œé€šè¿‡è¿™ç§æ–¹å¼åˆ›å»ºçš„ä»»ä½•è‡ªå®šä¹‰è§£æå™¨éƒ½å°†æˆä¸ºæœ‰æ•ˆçš„ LangChain å¯è¿è¡Œå¯¹è±¡ï¼Œå¹¶è‡ªåŠ¨è·å¾—å¼‚æ­¥æ”¯æŒã€æ‰¹å¤„ç†æ¥å£ã€æ—¥å¿—è®°å½•æ”¯æŒç­‰ç‰¹æ€§ã€‚", ":::"]}, {"cell_type": "markdown", "id": "1e0f9c59-b5bd-4ed0-a187-ae514c203e80", "metadata": {}, "source": ["### ç®€æ˜“è§£æå™¨"]}, {"cell_type": "markdown", "id": "3a96a846-1296-4d92-8e76-e29e583dee22", "metadata": {}, "source": ["è¿™æ˜¯ä¸€ä¸ªç®€å•çš„è§£æå™¨ï¼Œå¯ä»¥å°†å¸ƒå°”å€¼çš„**å­—ç¬¦ä¸²**è¡¨ç¤ºï¼ˆä¾‹å¦‚ `YES` æˆ– `NO`ï¼‰è§£æå¹¶è½¬æ¢ä¸ºå¯¹åº”çš„ `boolean` ç±»å‹ã€‚"]}, {"cell_type": "code", "execution_count": 1, "id": "733a0c4f-471a-4161-ad3e-804f63053e6f", "metadata": {}, "outputs": [], "source": ["from langchain_core.exceptions import OutputParserException\n", "from langchain_core.output_parsers import BaseOutputParser\n", "\n", "\n", "# The [bool] desribes a parameterization of a generic.\n", "# It's basically indicating what the return type of parse is\n", "# in this case the return type is either True or False\n", "class BooleanOutputParser(BaseOutputParser[bool]):\n", "    \"\"\"Custom boolean parser.\"\"\"\n", "\n", "    true_val: str = \"YES\"\n", "    false_val: str = \"NO\"\n", "\n", "    def parse(self, text: str) -> bool:\n", "        cleaned_text = text.strip().upper()\n", "        if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):\n", "            raise OutputParserException(\n", "                f\"BooleanOutputParser expected output value to either be \"\n", "                f\"{self.true_val} or {self.false_val} (case-insensitive). \"\n", "                f\"Received {cleaned_text}.\"\n", "            )\n", "        return cleaned_text == self.true_val.upper()\n", "\n", "    @property\n", "    def _type(self) -> str:\n", "        return \"boolean_output_parser\""]}, {"cell_type": "code", "execution_count": 2, "id": "101e54f0-12f1-4734-a80d-98e6f62644b2", "metadata": {}, "outputs": [{"data": {"text/plain": ["True"]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["parser = BooleanOutputParser()\n", "parser.invoke(\"YES\")"]}, {"cell_type": "code", "execution_count": 3, "id": "39ed9d84-16a1-4612-a1f7-13269b9f48e8", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Triggered an exception of type: <class 'langchain_core.exceptions.OutputParserException'>\n"]}], "source": ["try:\n", "    parser.invoke(\"MEOW\")\n", "except Exception as e:\n", "    print(f\"Triggered an exception of type: {type(e)}\")"]}, {"cell_type": "markdown", "id": "c27da11a-2c64-4108-9a8a-38008d6041fc", "metadata": {}, "source": ["è®©æˆ‘ä»¬æµ‹è¯•æ”¹å˜å‚æ•°åŒ–"]}, {"cell_type": "code", "execution_count": 4, "id": "2e94c0f4-f6c1-401b-8cee-2572a80846cb", "metadata": {}, "outputs": [{"data": {"text/plain": ["True"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["parser = BooleanOutputParser(true_val=\"OKAY\")\n", "parser.invoke(\"OKAY\")"]}, {"cell_type": "markdown", "id": "dac313d5-20c8-44a9-bfe9-c2b5020172e2", "metadata": {}, "source": ["è®©æˆ‘ä»¬ç¡®è®¤å…¶ä»– LCEL æ–¹æ³•æ˜¯å¦å­˜åœ¨"]}, {"cell_type": "code", "execution_count": 5, "id": "97fb540f-83b2-46fd-a741-b200235f8f9e", "metadata": {}, "outputs": [{"data": {"text/plain": ["[True, False]"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["parser.batch([\"OKAY\", \"NO\"])"]}, {"cell_type": "code", "execution_count": 6, "id": "60cbdb2f-5538-4e74-ba03-53bc1bc4bb2f", "metadata": {}, "outputs": [{"data": {"text/plain": ["[True, False]"]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": ["await parser.abatch([\"OKAY\", \"NO\"])"]}, {"cell_type": "code", "execution_count": 7, "id": "6520dff0-259c-48e4-be69-829fb3275ac2", "metadata": {}, "outputs": [{"data": {"text/plain": ["AIMessage(content='OKAY')"]}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": ["from langchain_anthropic.chat_models import ChatAnthropic\n", "\n", "anthropic = ChatAnthropic(model_name=\"claude-2.1\")\n", "anthropic.invoke(\"say OKAY or NO\")"]}, {"cell_type": "markdown", "id": "12dc079e-c451-496c-953c-cba55ef26de8", "metadata": {}, "source": ["è®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹æˆ‘ä»¬çš„è§£æå™¨æ˜¯å¦æ­£å¸¸å·¥ä½œï¼"]}, {"cell_type": "code", "execution_count": 8, "id": "bb177c14-b1f5-474f-a1c8-5b32ae242259", "metadata": {}, "outputs": [{"data": {"text/plain": ["True"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["chain = anthropic | parser\n", "chain.invoke(\"say OKAY or NO\")"]}, {"cell_type": "markdown", "id": "18f83192-37e8-43f5-ab29-9568b1279f1b", "metadata": {}, "source": [":::note\næ³¨æ„", "è§£æå™¨å¯ä»¥å¤„ç†æ¥è‡ªLLMçš„è¾“å‡ºï¼ˆå­—ç¬¦ä¸²ï¼‰æˆ–æ¥è‡ªèŠå¤©æ¨¡å‹çš„è¾“å‡ºï¼ˆ`AIMessage`ï¼‰ï¼", ":::"]}, {"cell_type": "markdown", "id": "9ed063d3-3159-4f5b-8362-710956fc50bd", "metadata": {}, "source": ["### è§£æåŸå§‹æ¨¡å‹è¾“å‡º", "\n", "æœ‰æ—¶ï¼Œæ¨¡å‹è¾“å‡ºä¸­é™¤äº†åŸå§‹æ–‡æœ¬å¤–ï¼Œè¿˜åŒ…å«é‡è¦çš„é¢å¤–å…ƒæ•°æ®ã€‚å…¶ä¸­ä¸€ä¸ªä¾‹å­æ˜¯å·¥å…·è°ƒç”¨ï¼ˆtool callingï¼‰ï¼Œå…¶ä¸­ä¼ é€’ç»™è¢«è°ƒç”¨å‡½æ•°çš„å‚æ•°ä¼šåœ¨å•ç‹¬çš„å±æ€§ä¸­è¿”å›ã€‚å¦‚æœä½ éœ€è¦è¿™ç§æ›´ç»†ç²’åº¦çš„æ§åˆ¶ï¼Œå¯ä»¥æ”¹ä¸ºç»§æ‰¿ `BaseGenerationOutputParser` ç±»ã€‚", "\n", "è¯¥ç±»éœ€è¦ä¸€ä¸ªå•ç‹¬çš„æ–¹æ³• `parse_result`ã€‚è¯¥æ–¹æ³•æ¥æ”¶åŸå§‹æ¨¡å‹è¾“å‡ºï¼ˆä¾‹å¦‚ `Generation` æˆ– `ChatGeneration` çš„åˆ—è¡¨ï¼‰å¹¶è¿”å›è§£æåçš„è¾“å‡ºã€‚", "\n", "æ”¯æŒ `Generation` å’Œ `ChatGeneration` ä¸¤ç§æ¨¡å¼ï¼Œä½¿å¾—è§£æå™¨èƒ½å¤ŸåŒæ—¶å…¼å®¹å¸¸è§„çš„ LLM å’ŒèŠå¤©æ¨¡å‹ã€‚"]}, {"cell_type": "code", "execution_count": 22, "id": "0fd1f936-e77d-4602-921c-52a37e589e90", "metadata": {}, "outputs": [], "source": ["from typing import List\n", "\n", "from langchain_core.exceptions import OutputParserException\n", "from langchain_core.messages import AIMessage\n", "from langchain_core.output_parsers import BaseGenerationOutputParser\n", "from langchain_core.outputs import ChatGeneration, Generation\n", "\n", "\n", "class StrInvertCase(BaseGenerationOutputParser[str]):\n", "    \"\"\"An example parser that inverts the case of the characters in the message.\n", "\n", "    This is an example parse shown just for demonstration purposes and to keep\n", "    the example as simple as possible.\n", "    \"\"\"\n", "\n", "    def parse_result(self, result: List[Generation], *, partial: bool = False) -> str:\n", "        \"\"\"Parse a list of model Generations into a specific format.\n", "\n", "        Args:\n", "            result: A list of Generations to be parsed. The Generations are assumed\n", "                to be different candidate outputs for a single model input.\n", "                Many parsers assume that only a single generation is passed it in.\n", "                We will assert for that\n", "            partial: Whether to allow partial results. This is used for parsers\n", "                     that support streaming\n", "        \"\"\"\n", "        if len(result) != 1:\n", "            raise NotImplementedError(\n", "                \"This output parser can only be used with a single generation.\"\n", "            )\n", "        generation = result[0]\n", "        if not isinstance(generation, ChatGeneration):\n", "            # Say that this one only works with chat generations\n", "            raise OutputParserException(\n", "                \"This output parser can only be used with a chat generation.\"\n", "            )\n", "        return generation.message.content.swapcase()\n", "\n", "\n", "chain = anthropic | StrInvertCase()"]}, {"cell_type": "markdown", "id": "accab8a3-6b0e-4ad0-89e6-1824ca20c726", "metadata": {}, "source": ["è®©æˆ‘ä»¬æ¥è¯•è¯•æ–°çš„è§£æå™¨ï¼å®ƒåº”è¯¥èƒ½å°†æ¨¡å‹çš„è¾“å‡ºè¿›è¡Œåè½¬ã€‚"]}, {"cell_type": "code", "execution_count": 23, "id": "568fae19-b09c-484f-8775-1c9a60aabdf4", "metadata": {}, "outputs": [{"data": {"text/plain": ["'hELLO! mY NAME IS cLAUDE.'"]}, "execution_count": 23, "metadata": {}, "output_type": "execute_result"}], "source": ["chain.invoke(\"Tell me a short sentence about yourself\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.1"}}, "nbformat": 4, "nbformat_minor": 5}