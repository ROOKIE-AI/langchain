{"cells": [{"cell_type": "raw", "metadata": {}, "source": ["---\n", "sidebar_position: 2\n", "---"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# 如何为聊天机器人添加检索功能", "\n", "[检索](/docs/concepts/retrieval/)是聊天机器人常用的一种技术，通过获取聊天模型训练数据之外的信息来增强其响应能力。本节将介绍如何在聊天机器人中实现检索功能，但值得注意的是，检索是一个非常微妙且深奥的主题——我们建议您进一步探索[文档的其他部分](/docs/how_to#qa-with-rag)，以获取更深入的内容！", "\n", "## 安装设置", "\n", "你需要安装一些软件包，并将你的OpenAI API密钥设置为名为`OPENAI_API_KEY`的环境变量："]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n", "You should consider upgrading via the '/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n", "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"]}, {"data": {"text/plain": ["True"]}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": ["%pip install -qU langchain langchain-openai langchain-chroma beautifulsoup4\n", "\n", "# Set env var OPENAI_API_KEY or load from a .env file:\n", "import dotenv\n", "\n", "dotenv.load_dotenv()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["我们还需要设置一个聊天模型，用于以下示例。"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["from langchain_openai import ChatOpenAI\n", "\n", "chat = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 创建检索器", "\n", "我们将以 [LangSmith 文档](https://docs.smith.langchain.com/overview) 作为源材料，并将内容存储到 [向量数据库](/docs/concepts/vectorstores/) 中供后续检索。请注意，此示例会略过关于解析和存储数据源的一些具体细节——您可以在 [检索系统创建深度文档](/docs/how_to#qa-with-rag) 中查看更多相关内容。", "\n", "让我们使用文档加载器从文档中提取文本："]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["from langchain_community.document_loaders import WebBaseLoader\n", "\n", "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n", "data = loader.load()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["接下来，我们将其分割成更小的片段，以适应大语言模型的上下文窗口容量，并将其存储至向量数据库中："]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["from langchain_text_splitters import RecursiveCharacterTextSplitter\n", "\n", "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n", "all_splits = text_splitter.split_documents(data)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["然后我们将这些文本块嵌入并存储到向量数据库中："]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["from langchain_chroma import Chroma\n", "from langchain_openai import OpenAIEmbeddings\n", "\n", "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["最后，让我们从已初始化的向量存储中创建一个检索器："]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"data": {"text/plain": ["[Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n", " Document(page_content='LangSmith Overview and User Guide | 🦜️🛠️ LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n", " Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n", " Document(page_content=\"does that affect the output?\\u200bSo you notice a bad output, and you go into LangSmith to see what's going on. You find the faulty LLM call and are now looking at the exact input. You want to try changing a word or a phrase to see what happens -- what do you do?We constantly ran into this issue. Initially, we copied the prompt to a playground of sorts. But this got annoying, so we built a playground of our own! When examining an LLM call, you can click the Open in Playground button to access this\", metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'})]"]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": ["# k is the number of chunks to retrieve\n", "retriever = vectorstore.as_retriever(k=4)\n", "\n", "docs = retriever.invoke(\"Can LangSmith help test my LLM applications?\")\n", "\n", "docs"]}, {"cell_type": "markdown", "metadata": {}, "source": ["我们可以看到，调用上述检索器会返回 LangSmith 文档中包含测试信息的部分内容，这些内容可作为聊天机器人在回答问题时的上下文依据。至此，我们已经成功构建了一个能够从 LangSmith 文档中检索相关数据的检索器！", "\n", "## 文档链", "\n", "既然我们已经有了一个能够返回 LangChain 文档的检索器，现在让我们创建一个能够利用这些文档作为上下文来回答问题的链。我们将使用 `create_stuff_documents_chain` 辅助函数将所有输入文档“塞入”提示词中。该函数还会负责将文档格式化为字符串。", "\n", "除了聊天模型外，该函数还期望一个包含`context`变量的提示词模板，以及一个名为`messages`的聊天历史消息占位符。我们将创建如下所示的提示词模板并传入：\n\n（注：根据技术文档的表述习惯，对\"prompt\"采用了\"提示词模板\"的译法以体现其可复用性；保留`context`和`messages`两个变量名的原文格式以符合编程规范；调整了最后半句的语序使其更符合中文表达逻辑）"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["from langchain.chains.combine_documents import create_stuff_documents_chain\n", "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n", "\n", "SYSTEM_TEMPLATE = \"\"\"\n", "Answer the user's questions based on the below context. \n", "If the context doesn't contain any relevant information to the question, don't make something up and just say \"I don't know\":\n", "\n", "<context>\n", "{context}\n", "</context>\n", "\"\"\"\n", "\n", "question_answering_prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\n", "            \"system\",\n", "            SYSTEM_TEMPLATE,\n", "        ),\n", "        MessagesPlaceholder(variable_name=\"messages\"),\n", "    ]\n", ")\n", "\n", "document_chain = create_stuff_documents_chain(chat, question_answering_prompt)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["我们可以直接调用这个 `document_chain` 来回答问题。让我们使用上面检索到的文档和相同的问题：`langsmith 如何帮助进行测试？`"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"data": {"text/plain": ["'Yes, LangSmith can help test and evaluate your LLM applications. It simplifies the initial setup, and you can use it to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.'"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["from langchain_core.messages import HumanMessage\n", "\n", "document_chain.invoke(\n", "    {\n", "        \"context\": docs,\n", "        \"messages\": [\n", "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\")\n", "        ],\n", "    }\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["看起来不错！为了对比，我们可以尝试在没有上下文文档的情况下运行，并比较结果："]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"data": {"text/plain": ["\"I don't know about LangSmith's specific capabilities for testing LLM applications. It's best to reach out to LangSmith directly to inquire about their services and how they can assist with testing your LLM applications.\""]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["document_chain.invoke(\n", "    {\n", "        \"context\": [],\n", "        \"messages\": [\n", "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\")\n", "        ],\n", "    }\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["我们可以看到，LLM 没有返回任何结果。", "\n", "## 检索链", "\n", "让我们将这份文档链与检索器结合起来。以下是其中一种可能的实现方式："]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["from typing import Dict\n", "\n", "from langchain_core.runnables import RunnablePassthrough\n", "\n", "\n", "def parse_retriever_input(params: Dict):\n", "    return params[\"messages\"][-1].content\n", "\n", "\n", "retrieval_chain = RunnablePassthrough.assign(\n", "    context=parse_retriever_input | retriever,\n", ").assign(\n", "    answer=document_chain,\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["给定一个输入消息列表，我们会提取列表中最后一条消息的内容，并将其传递给检索器以获取相关文档。然后，我们将这些文档作为上下文传递给文档链，以生成最终响应。", "\n", "调用此链结合了上述两个步骤："]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"data": {"text/plain": ["{'messages': [HumanMessage(content='Can LangSmith help test my LLM applications?')],\n", " 'context': [Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n", "  Document(page_content='LangSmith Overview and User Guide | 🦜️🛠️ LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n", "  Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n", "  Document(page_content=\"does that affect the output?\\u200bSo you notice a bad output, and you go into LangSmith to see what's going on. You find the faulty LLM call and are now looking at the exact input. You want to try changing a word or a phrase to see what happens -- what do you do?We constantly ran into this issue. Initially, we copied the prompt to a playground of sorts. But this got annoying, so we built a playground of our own! When examining an LLM call, you can click the Open in Playground button to access this\", metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'})],\n", " 'answer': 'Yes, LangSmith can help test and evaluate your LLM applications. It simplifies the initial setup, and you can use it to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.'}"]}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": ["retrieval_chain.invoke(\n", "    {\n", "        \"messages\": [\n", "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\")\n", "        ],\n", "    }\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["看起来不错！", "\n", "## 查询转换", "\n", "我们的检索链能够回答关于LangSmith的问题，但存在一个问题——聊天机器人需要以对话形式与用户交互，因此必须处理后续追问。", "\n", "当前的链式结构难以处理这种情况。试想针对原始问题提出一个后续追问，比如`告诉我更多细节！`。如果我们直接用该查询调用检索器，得到的文档将与LLM应用测试无关："]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"data": {"text/plain": ["[Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n", " Document(page_content='playground. Here, you can modify the prompt and re-run it to observe the resulting changes to the output - as many times as needed!Currently, this feature supports only OpenAI and Anthropic models and works for LLM and Chat Model calls. We plan to extend its functionality to more LLM types, chains, agents, and retrievers in the future.What is the exact sequence of events?\\u200bIn complicated chains and agents, it can often be hard to understand what is going on under the hood. What calls are being', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n", " Document(page_content='however, there is still no complete substitute for human review to get the utmost quality and reliability from your application.', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n", " Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'})]"]}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": ["retriever.invoke(\"Tell me more!\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["这是因为检索器本身不具备状态的概念，只会提取与给定查询最相似的文档。为了解决这个问题，我们可以通过大语言模型将查询转换为不依赖任何外部引用的独立查询。", "\n", "这是一个示例："]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"data": {"text/plain": ["AIMessage(content='\"LangSmith LLM application testing and evaluation\"')"]}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": ["from langchain_core.messages import AIMessage, HumanMessage\n", "\n", "query_transform_prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        MessagesPlaceholder(variable_name=\"messages\"),\n", "        (\n", "            \"user\",\n", "            \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation. Only respond with the query, nothing else.\",\n", "        ),\n", "    ]\n", ")\n", "\n", "query_transformation_chain = query_transform_prompt | chat\n", "\n", "query_transformation_chain.invoke(\n", "    {\n", "        \"messages\": [\n", "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\"),\n", "            AIMessage(\n", "                content=\"Yes, LangSmith can help test and evaluate your LLM applications. It allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs. Additionally, LangSmith can be used to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.\"\n", "            ),\n", "            HumanMessage(content=\"Tell me more!\"),\n", "        ],\n", "    }\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["太棒了！转换后的查询将检索出与LLM应用测试相关的上下文文档。", "\n", "让我们将其添加到检索链中。我们可以按如下方式封装检索器："]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [], "source": ["from langchain_core.output_parsers import StrOutputParser\n", "from langchain_core.runnables import RunnableBranch\n", "\n", "query_transforming_retriever_chain = RunnableBranch(\n", "    (\n", "        lambda x: len(x.get(\"messages\", [])) == 1,\n", "        # If only one message, then we just pass that message's content to retriever\n", "        (lambda x: x[\"messages\"][-1].content) | retriever,\n", "    ),\n", "    # If messages, then we pass inputs to LLM chain to transform the query, then pass to retriever\n", "    query_transform_prompt | chat | StrOutputParser() | retriever,\n", ").with_config(run_name=\"chat_retriever_chain\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["然后，我们可以利用这个查询转换链，使我们的检索链能够更好地处理这类后续问题："]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["SYSTEM_TEMPLATE = \"\"\"\n", "Answer the user's questions based on the below context. \n", "If the context doesn't contain any relevant information to the question, don't make something up and just say \"I don't know\":\n", "\n", "<context>\n", "{context}\n", "</context>\n", "\"\"\"\n", "\n", "question_answering_prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\n", "            \"system\",\n", "            SYSTEM_TEMPLATE,\n", "        ),\n", "        MessagesPlaceholder(variable_name=\"messages\"),\n", "    ]\n", ")\n", "\n", "document_chain = create_stuff_documents_chain(chat, question_answering_prompt)\n", "\n", "conversational_retrieval_chain = RunnablePassthrough.assign(\n", "    context=query_transforming_retriever_chain,\n", ").assign(\n", "    answer=document_chain,\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["太棒了！让我们用与之前相同的输入来调用这个新链："]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [{"data": {"text/plain": ["{'messages': [HumanMessage(content='Can LangSmith help test my LLM applications?')],\n", " 'context': [Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n", "  Document(page_content='LangSmith Overview and User Guide | 🦜️🛠️ LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n", "  Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n", "  Document(page_content=\"does that affect the output?\\u200bSo you notice a bad output, and you go into LangSmith to see what's going on. You find the faulty LLM call and are now looking at the exact input. You want to try changing a word or a phrase to see what happens -- what do you do?We constantly ran into this issue. Initially, we copied the prompt to a playground of sorts. But this got annoying, so we built a playground of our own! When examining an LLM call, you can click the Open in Playground button to access this\", metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'})],\n", " 'answer': 'Yes, LangSmith can help test and evaluate LLM (Language Model) applications. It simplifies the initial setup, and you can use it to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.'}"]}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": ["conversational_retrieval_chain.invoke(\n", "    {\n", "        \"messages\": [\n", "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\"),\n", "        ]\n", "    }\n", ")"]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [{"data": {"text/plain": ["{'messages': [HumanMessage(content='Can LangSmith help test my LLM applications?'),\n", "  AIMessage(content='Yes, LangSmith can help test and evaluate your LLM applications. It allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs. Additionally, LangSmith can be used to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.'),\n", "  HumanMessage(content='Tell me more!')],\n", " 'context': [Document(page_content='LangSmith Overview and User Guide | 🦜️🛠️ LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n", "  Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n", "  Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n", "  Document(page_content='LangSmith makes it easy to manually review and annotate runs through annotation queues.These queues allow you to select any runs based on criteria like model type or automatic evaluation scores, and queue them up for human review. As a reviewer, you can then quickly step through the runs, viewing the input, output, and any existing tags before adding your own feedback.We often use this for a couple of reasons:To assess subjective qualities that automatic evaluators struggle with, like', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'})],\n", " 'answer': 'LangSmith simplifies the initial setup for building reliable LLM applications, but it acknowledges that there is still work needed to bring the performance of prompts, chains, and agents up to the level where they are reliable enough to be used in production. It also provides the capability to manually review and annotate runs through annotation queues, allowing you to select runs based on criteria like model type or automatic evaluation scores for human review. This feature is particularly useful for assessing subjective qualities that automatic evaluators struggle with.'}"]}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": ["conversational_retrieval_chain.invoke(\n", "    {\n", "        \"messages\": [\n", "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\"),\n", "            AIMessage(\n", "                content=\"Yes, LangSmith can help test and evaluate your LLM applications. It allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs. Additionally, LangSmith can be used to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.\"\n", "            ),\n", "            HumanMessage(content=\"Tell me more!\"),\n", "        ],\n", "    }\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["你可以查看[这个LangSmith跟踪记录](https://smith.langchain.com/public/bb329a3b-e92a-4063-ad78-43f720fbb5a2/r)来亲自了解内部查询转换步骤。", "\n", "## 流式传输", "\n", "由于该链是使用LCEL构建的，你可以对其使用熟悉的`.stream()`等方法："]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'messages': [HumanMessage(content='Can LangSmith help test my LLM applications?'), AIMessage(content='Yes, LangSmith can help test and evaluate your LLM applications. It allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs. Additionally, LangSmith can be used to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.'), HumanMessage(content='Tell me more!')]}\n", "{'context': [Document(page_content='LangSmith Overview and User Guide | 🦜️🛠️ LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}), Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}), Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}), Document(page_content='LangSmith makes it easy to manually review and annotate runs through annotation queues.These queues allow you to select any runs based on criteria like model type or automatic evaluation scores, and queue them up for human review. As a reviewer, you can then quickly step through the runs, viewing the input, output, and any existing tags before adding your own feedback.We often use this for a couple of reasons:To assess subjective qualities that automatic evaluators struggle with, like', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'})]}\n", "{'answer': ''}\n", "{'answer': 'Lang'}\n", "{'answer': 'Smith'}\n", "{'answer': ' simpl'}\n", "{'answer': 'ifies'}\n", "{'answer': ' the'}\n", "{'answer': ' initial'}\n", "{'answer': ' setup'}\n", "{'answer': ' for'}\n", "{'answer': ' building'}\n", "{'answer': ' reliable'}\n", "{'answer': ' L'}\n", "{'answer': 'LM'}\n", "{'answer': ' applications'}\n", "{'answer': '.'}\n", "{'answer': ' It'}\n", "{'answer': ' provides'}\n", "{'answer': ' features'}\n", "{'answer': ' for'}\n", "{'answer': ' manually'}\n", "{'answer': ' reviewing'}\n", "{'answer': ' and'}\n", "{'answer': ' annot'}\n", "{'answer': 'ating'}\n", "{'answer': ' runs'}\n", "{'answer': ' through'}\n", "{'answer': ' annotation'}\n", "{'answer': ' queues'}\n", "{'answer': ','}\n", "{'answer': ' allowing'}\n", "{'answer': ' you'}\n", "{'answer': ' to'}\n", "{'answer': ' select'}\n", "{'answer': ' runs'}\n", "{'answer': ' based'}\n", "{'answer': ' on'}\n", "{'answer': ' criteria'}\n", "{'answer': ' like'}\n", "{'answer': ' model'}\n", "{'answer': ' type'}\n", "{'answer': ' or'}\n", "{'answer': ' automatic'}\n", "{'answer': ' evaluation'}\n", "{'answer': ' scores'}\n", "{'answer': ','}\n", "{'answer': ' and'}\n", "{'answer': ' queue'}\n", "{'answer': ' them'}\n", "{'answer': ' up'}\n", "{'answer': ' for'}\n", "{'answer': ' human'}\n", "{'answer': ' review'}\n", "{'answer': '.'}\n", "{'answer': ' As'}\n", "{'answer': ' a'}\n", "{'answer': ' reviewer'}\n", "{'answer': ','}\n", "{'answer': ' you'}\n", "{'answer': ' can'}\n", "{'answer': ' quickly'}\n", "{'answer': ' step'}\n", "{'answer': ' through'}\n", "{'answer': ' the'}\n", "{'answer': ' runs'}\n", "{'answer': ','}\n", "{'answer': ' view'}\n", "{'answer': ' the'}\n", "{'answer': ' input'}\n", "{'answer': ','}\n", "{'answer': ' output'}\n", "{'answer': ','}\n", "{'answer': ' and'}\n", "{'answer': ' any'}\n", "{'answer': ' existing'}\n", "{'answer': ' tags'}\n", "{'answer': ' before'}\n", "{'answer': ' adding'}\n", "{'answer': ' your'}\n", "{'answer': ' own'}\n", "{'answer': ' feedback'}\n", "{'answer': '.'}\n", "{'answer': ' This'}\n", "{'answer': ' can'}\n", "{'answer': ' be'}\n", "{'answer': ' particularly'}\n", "{'answer': ' useful'}\n", "{'answer': ' for'}\n", "{'answer': ' assessing'}\n", "{'answer': ' subjective'}\n", "{'answer': ' qualities'}\n", "{'answer': ' that'}\n", "{'answer': ' automatic'}\n", "{'answer': ' evalu'}\n", "{'answer': 'ators'}\n", "{'answer': ' struggle'}\n", "{'answer': ' with'}\n", "{'answer': '.'}\n", "{'answer': ''}\n"]}], "source": ["stream = conversational_retrieval_chain.stream(\n", "    {\n", "        \"messages\": [\n", "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\"),\n", "            AIMessage(\n", "                content=\"Yes, LangSmith can help test and evaluate your LLM applications. It allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs. Additionally, LangSmith can be used to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.\"\n", "            ),\n", "            HumanMessage(content=\"Tell me more!\"),\n", "        ],\n", "    }\n", ")\n", "\n", "for chunk in stream:\n", "    print(chunk)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 延伸阅读", "\n", "本指南仅浅尝辄止地介绍了检索技术。如需了解更多关于数据摄取、准备及检索最相关数据的不同方法，请查阅相关操作指南[此处](/docs/how_to#document-loaders)。"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.1"}}, "nbformat": 4, "nbformat_minor": 2}