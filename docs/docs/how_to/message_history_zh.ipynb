{"cells": [{"cell_type": "raw", "id": "8165bd4c", "metadata": {"vscode": {"languageId": "raw"}}, "source": ["---\n", "keywords: [memory]\n", "---"]}, {"cell_type": "markdown", "id": "f47033eb", "metadata": {}, "source": ["# 如何添加消息历史记录", "\n", ":::info 前提条件", "\n", "本指南假设您熟悉以下概念：", "- [链式运行](/docs/how_to/sequence/)", "- [提示模板](/docs/concepts/prompt_templates)", "- [聊天消息](/docs/concepts/messages)", "- [LangGraph 持久化](https://langchain-ai.github.io/langgraph/how-tos/persistence/)", "\n", ":::", "\n", ":::note\n注意", "\n", "本指南先前涵盖了 [RunnableWithMessageHistory](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html) 抽象概念。您可以在 [v0.2 版本文档](https://python.langchain.com/v0.2/docs/how_to/message_history/) 中查看该版本的指南。", "\n", "截至 LangChain v0.3 版本发布，我们建议 LangChain 用户利用 [LangGraph 持久化功能](https://langchain-ai.github.io/langgraph/concepts/persistence/) 将 `memory` 集成到新的 LangChain 应用中。", "\n", "如果你的代码已经在使用 `RunnableWithMessageHistory` 或 `BaseChatMessageHistory`，那么你**无需**做任何更改。我们近期没有计划弃用此功能，因为它适用于简单的聊天应用，并且任何使用 `RunnableWithMessageHistory` 的代码将继续按预期工作。", "\n", "请参阅[如何迁移到 LangGraph Memory](/docs/versions/migrating_memory/) 获取更多详情。", ":::", "\n", "在构建聊天机器人时，将对话状态传入和传出链是至关重要的。LangGraph 内置了持久化层，支持将链状态自动保存在内存中，或外部后端（如 SQLite、Postgres 或 Redis）。具体细节可查阅 LangGraph 的[持久化文档](https://langchain-ai.github.io/langgraph/how-tos/persistence/)。", "\n", "在本指南中，我们将演示如何通过将任意LangChain可运行对象封装至一个极简的LangGraph应用中，为其添加持久化功能。这种方法能持久保存消息历史记录及链状态的其他元素，从而简化多轮交互应用的开发流程。同时，该方案支持多线程运行，使得单个应用能够分别与多个用户进行独立交互。", "\n", "## 安装设置", "\n", "让我们初始化一个聊天模型：", "\n", "import ChatModelTabs from \"@theme/ChatModelTabs\";", "\n", "<ChatModelTabs\n", "customVarName=\"llm\"", "/>"]}, {"cell_type": "code", "execution_count": 1, "id": "ca50d084-ae4b-4aea-9eb7-2ebc699df9bc", "metadata": {}, "outputs": [], "source": ["# | output: false\n", "# | echo: false\n", "\n", "# import os\n", "# from getpass import getpass\n", "\n", "# os.environ[\"ANTHROPIC_API_KEY\"] = getpass()\n", "from langchain_anthropic import ChatAnthropic\n", "\n", "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\", temperature=0)"]}, {"cell_type": "markdown", "id": "1f6121bc-2080-4ccc-acf0-f77de4bc951d", "metadata": {}, "source": ["## 示例：消息输入", "\n", "为[聊天模型](/docs/concepts/chat_models)添加记忆功能提供了一个简单的示例。聊天模型接收消息列表作为输入并输出一条消息。LangGraph内置了可用于此目的的`MessagesState`状态管理工具。", "\n", "以下，我们将：", "1. 将图状态定义为一个消息列表；", "2. 向图中添加一个调用聊天模型的单一节点；", "3. 使用内存检查点编译图，以便在运行之间存储消息。", "\n", ":::信息", "\n", "LangGraph 应用程序的输出是其[状态](https://langchain-ai.github.io/langgraph/concepts/low_level/)。这可以是任何 Python 类型，但在本上下文中，它通常是一个与可运行对象模式匹配的 `TypedDict`。", "\n", "好的，请提供需要翻译的英文内容，我会将其转换为标准的中文markdown格式，并保持原有结构一致。"]}, {"cell_type": "code", "execution_count": 2, "id": "f691a73a-a866-4354-9fff-8315605e2b8f", "metadata": {}, "outputs": [], "source": ["from langchain_core.messages import HumanMessage\n", "from langgraph.checkpoint.memory import MemorySaver\n", "from langgraph.graph import START, MessagesState, StateGraph\n", "\n", "# Define a new graph\n", "workflow = StateGraph(state_schema=MessagesState)\n", "\n", "\n", "# Define the function that calls the model\n", "def call_model(state: MessagesState):\n", "    response = llm.invoke(state[\"messages\"])\n", "    # Update message history with response:\n", "    return {\"messages\": response}\n", "\n", "\n", "# Define the (single) node in the graph\n", "workflow.add_edge(START, \"model\")\n", "workflow.add_node(\"model\", call_model)\n", "\n", "# Add memory\n", "memory = MemorySaver()\n", "app = workflow.compile(checkpointer=memory)"]}, {"cell_type": "markdown", "id": "c0b396a8-f81e-4139-b4b2-75adf61d8179", "metadata": {}, "source": ["当我们运行应用程序时，会传入一个包含 `thread_id` 的配置字典。该 ID 用于区分对话线程（例如不同用户之间的会话）。"]}, {"cell_type": "code", "execution_count": 3, "id": "e4309511-2140-4d91-8f5f-ea3661e6d179", "metadata": {}, "outputs": [], "source": ["config = {\"configurable\": {\"thread_id\": \"abc123\"}}"]}, {"cell_type": "markdown", "id": "108c45a2-4971-4120-ba64-9a4305a414bb", "metadata": {}, "source": ["然后我们可以调用该应用程序："]}, {"cell_type": "code", "execution_count": 4, "id": "72a5ff6c-501f-4151-8dd9-f600f70554be", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "It's nice to meet you, Bob! I'm Claude, an AI assistant created by Anthropic. How can I help you today?\n"]}], "source": ["query = \"Hi! I'm Bob.\"\n", "\n", "input_messages = [HumanMessage(query)]\n", "output = app.invoke({\"messages\": input_messages}, config)\n", "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"]}, {"cell_type": "code", "execution_count": 5, "id": "5931fb35-0fac-40e7-8ac6-b14cb4e926cd", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "Your name is Bob, as you introduced yourself at the beginning of our conversation.\n"]}], "source": ["query = \"What's my name?\"\n", "\n", "input_messages = [HumanMessage(query)]\n", "output = app.invoke({\"messages\": input_messages}, config)\n", "output[\"messages\"][-1].pretty_print()"]}, {"cell_type": "markdown", "id": "91de6d12-881d-4d23-a421-f2e3bf829b79", "metadata": {}, "source": ["请注意，不同线程的状态是相互独立的。如果我们向一个带有新 `thread_id` 的线程发出相同的查询，模型会表示它不知道答案："]}, {"cell_type": "code", "execution_count": 6, "id": "6f12c26f-8913-4484-b2c5-b49eda2e6d7d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "I'm afraid I don't actually know your name. As an AI assistant, I don't have personal information about you unless you provide it to me directly.\n"]}], "source": ["query = \"What's my name?\"\n", "config = {\"configurable\": {\"thread_id\": \"abc234\"}}\n", "\n", "input_messages = [HumanMessage(query)]\n", "output = app.invoke({\"messages\": input_messages}, config)\n", "output[\"messages\"][-1].pretty_print()"]}, {"cell_type": "markdown", "id": "6749ea95-3382-4843-bb96-cfececb9e4e5", "metadata": {}, "source": ["## 示例：字典输入", "\n", "LangChain 可运行对象通常通过单个 `dict` 参数中的不同键来接收多个输入。一个常见的例子是包含多个参数的提示模板。", "\n", "此前我们的可运行对象是一个聊天模型，而现在我们将一个提示模板和一个聊天模型串联在一起。"]}, {"cell_type": "code", "execution_count": 7, "id": "6e7a402a-0994-4fc5-a607-fb990a248aa4", "metadata": {}, "outputs": [], "source": ["from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n", "\n", "prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\"system\", \"Answer in {language}.\"),\n", "        MessagesPlaceholder(variable_name=\"messages\"),\n", "    ]\n", ")\n", "\n", "runnable = prompt | llm"]}, {"cell_type": "markdown", "id": "f83107bd-ae61-45e1-a57e-94ab043aad4b", "metadata": {}, "source": ["在此场景中，我们将图状态定义为包含以下参数（除消息历史外）。随后，我们按照与之前相同的方式定义一个单节点图。", "\n", "请注意以下状态：", "- 对 `messages` 列表的更新将追加消息；", "- 对 `language` 字符串的更新将覆盖该字符串。"]}, {"cell_type": "code", "execution_count": 8, "id": "267429ea-be0f-4f80-8daf-c63d881a1436", "metadata": {}, "outputs": [], "source": ["from typing import Sequence\n", "\n", "from langchain_core.messages import BaseMessage\n", "from langgraph.graph.message import add_messages\n", "from typing_extensions import Annotated, TypedDict\n", "\n", "\n", "# highlight-next-line\n", "class State(TypedDict):\n", "    # highlight-next-line\n", "    messages: Annotated[Sequence[BaseMessage], add_messages]\n", "    # highlight-next-line\n", "    language: str\n", "\n", "\n", "workflow = StateGraph(state_schema=State)\n", "\n", "\n", "def call_model(state: State):\n", "    response = runnable.invoke(state)\n", "    # Update message history with response:\n", "    return {\"messages\": [response]}\n", "\n", "\n", "workflow.add_edge(START, \"model\")\n", "workflow.add_node(\"model\", call_model)\n", "\n", "memory = MemorySaver()\n", "app = workflow.compile(checkpointer=memory)"]}, {"cell_type": "code", "execution_count": 9, "id": "f3844fb4-58d7-43c8-b427-6d9f64d7411b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "¡Hola, Bob! Es un placer conocerte.\n"]}], "source": ["config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n", "\n", "input_dict = {\n", "    \"messages\": [HumanMessage(\"Hi, I'm Bob.\")],\n", "    \"language\": \"Spanish\",\n", "}\n", "output = app.invoke(input_dict, config)\n", "output[\"messages\"][-1].pretty_print()"]}, {"cell_type": "markdown", "id": "7df47824-ef18-4a6e-a416-345ec9203f88", "metadata": {}, "source": ["## 管理消息历史记录", "\n", "消息历史记录（以及应用程序状态的其他元素）可通过 `.get_state` 访问："]}, {"cell_type": "code", "execution_count": 10, "id": "1cbd6d82-43c1-4d11-98af-5c3ad9cd9b3b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Language: Spanish\n", "================================\u001b[1m Human Message \u001b[0m=================================\n", "\n", "Hi, I'm Bob.\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "¡Hola, Bob! Es un placer conocerte.\n"]}], "source": ["state = app.get_state(config).values\n", "\n", "print(f'Language: {state[\"language\"]}')\n", "for message in state[\"messages\"]:\n", "    message.pretty_print()"]}, {"cell_type": "markdown", "id": "acfbccda-0bd6-4c4d-ae6e-8118520314e1", "metadata": {}, "source": ["我们也可以通过 `.update_state` 来更新状态。例如，我们可以手动追加一条新消息："]}, {"cell_type": "code", "execution_count": 11, "id": "e98310d7-8ab1-461d-94a7-dd419494ab8d", "metadata": {}, "outputs": [], "source": ["from langchain_core.messages import HumanMessage\n", "\n", "_ = app.update_state(config, {\"messages\": [HumanMessage(\"Test\")]})"]}, {"cell_type": "code", "execution_count": 12, "id": "74ab3691-6f3b-49c5-aad0-2a90fc2a1e6a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Language: Spanish\n", "================================\u001b[1m Human Message \u001b[0m=================================\n", "\n", "Hi, I'm Bob.\n", "==================================\u001b[1m Ai Message \u001b[0m==================================\n", "\n", "¡Hola, Bob! Es un placer conocerte.\n", "================================\u001b[1m Human Message \u001b[0m=================================\n", "\n", "Test\n"]}], "source": ["state = app.get_state(config).values\n", "\n", "print(f'Language: {state[\"language\"]}')\n", "for message in state[\"messages\"]:\n", "    message.pretty_print()"]}, {"cell_type": "markdown", "id": "e4a1ea00-d7ff-4f18-b9ec-9aec5909d027", "metadata": {}, "source": ["有关状态管理的详细信息（包括删除消息），请参阅 LangGraph 文档：", "- [如何删除消息](https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages/)", "- [如何查看和更新历史图状态](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/)"]}, {"cell_type": "code", "execution_count": null, "id": "870c9c5b-c859-4c0e-9cbd-3555e6ed11e4", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.4"}}, "nbformat": 4, "nbformat_minor": 5}