{"cells": [{"cell_type": "markdown", "id": "8cc82b48", "metadata": {}, "source": ["# 如何使用MultiQueryRetriever", "\n", "基于距离的[向量数据库](/docs/concepts/vectorstores/)检索通过将查询[嵌入](/docs/concepts/embedding_models/)（表示）到高维空间中，并根据距离度量找到相似的嵌入文档。然而，检索结果可能会因查询措辞的细微变化，或嵌入未能很好地捕捉数据语义而产生差异。虽然可以通过提示工程/调优手动解决这些问题，但这一过程往往较为繁琐。", "\n", "[MultiQueryRetriever](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.multi_query.MultiQueryRetriever.html) 通过使用大语言模型（LLM）为给定的用户输入查询生成多个不同角度的查询，从而自动化提示调优过程。对于每个生成的查询，它会检索一组相关文档，并取所有查询结果的唯一并集，以获得更广泛的潜在相关文档集合。通过对同一问题生成多视角的查询，`MultiQueryRetriever` 能够缓解基于距离的检索方法的某些局限性，从而得到更丰富的结果集。", "\n", "让我们根据[RAG教程](/docs/tutorials/rag)中Lilian Weng的博文[LLM驱动的自主代理](https://lilianweng.github.io/posts/2023-06-23-agent/)，构建一个向量数据库。"]}, {"cell_type": "code", "execution_count": 1, "id": "994d6c74", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:08:00.190093Z", "iopub.status.busy": "2024-09-10T20:08:00.189665Z", "iopub.status.idle": "2024-09-10T20:08:05.438015Z", "shell.execute_reply": "2024-09-10T20:08:05.437685Z"}}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["USER_AGENT environment variable not set, consider setting it to identify your requests.\n"]}], "source": ["# Build a sample vectorDB\n", "from langchain_chroma import Chroma\n", "from langchain_community.document_loaders import WebBaseLoader\n", "from langchain_openai import OpenAIEmbeddings\n", "from langchain_text_splitters import RecursiveCharacterTextSplitter\n", "\n", "# Load blog post\n", "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n", "data = loader.load()\n", "\n", "# Split\n", "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n", "splits = text_splitter.split_documents(data)\n", "\n", "# VectorDB\n", "embedding = OpenAIEmbeddings()\n", "vectordb = Chroma.from_documents(documents=splits, embedding=embedding)"]}, {"cell_type": "markdown", "id": "cca8f56c", "metadata": {}, "source": ["#### 简单用法", "\n", "指定用于查询生成的LLM，检索器将完成其余工作。"]}, {"cell_type": "code", "execution_count": 2, "id": "edbca101", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:08:05.439930Z", "iopub.status.busy": "2024-09-10T20:08:05.439810Z", "iopub.status.idle": "2024-09-10T20:08:05.553766Z", "shell.execute_reply": "2024-09-10T20:08:05.553520Z"}}, "outputs": [], "source": ["from langchain.retrievers.multi_query import MultiQueryRetriever\n", "from langchain_openai import ChatOpenAI\n", "\n", "question = \"What are the approaches to Task Decomposition?\"\n", "llm = ChatOpenAI(temperature=0)\n", "retriever_from_llm = MultiQueryRetriever.from_llm(\n", "    retriever=vectordb.as_retriever(), llm=llm\n", ")"]}, {"cell_type": "code", "execution_count": 3, "id": "9e6d3b69", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:08:05.555359Z", "iopub.status.busy": "2024-09-10T20:08:05.555262Z", "iopub.status.idle": "2024-09-10T20:08:05.557046Z", "shell.execute_reply": "2024-09-10T20:08:05.556825Z"}}, "outputs": [], "source": ["# Set logging for the queries\n", "import logging\n", "\n", "logging.basicConfig()\n", "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"]}, {"cell_type": "code", "execution_count": 4, "id": "bc93dc2b-9407-48b0-9f9a-338247e7eb69", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:08:05.558176Z", "iopub.status.busy": "2024-09-10T20:08:05.558100Z", "iopub.status.idle": "2024-09-10T20:08:07.250342Z", "shell.execute_reply": "2024-09-10T20:08:07.249711Z"}}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["INFO:langchain.retrievers.multi_query:Generated queries: ['1. How can Task Decomposition be achieved through different methods?', '2. What strategies are commonly used for Task Decomposition?', '3. What are the various ways to break down tasks in Task Decomposition?']\n"]}, {"data": {"text/plain": ["5"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["unique_docs = retriever_from_llm.invoke(question)\n", "len(unique_docs)"]}, {"cell_type": "markdown", "id": "7e170263-facd-4065-bb68-d11fb9123a45", "metadata": {}, "source": ["请注意，由[检索器](/docs/concepts/retrievers/)生成的基础查询会以`INFO`级别记录在日志中。"]}, {"cell_type": "markdown", "id": "c54a282f", "metadata": {}, "source": ["#### 提供您自己的提示", "\n", "在底层实现中，`MultiQueryRetriever` 通过特定的[提示模板](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.multi_query.MultiQueryRetriever.html)生成查询。如需自定义该提示模板：", "\n", "1. 创建一个带有问题输入变量的[PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html);", "2. 实现一个如下所示的[输出解析器](/docs/concepts/output_parsers)，将结果拆分为查询列表。", "\n", "提示词与输出解析器必须共同支持生成查询列表。"]}, {"cell_type": "code", "execution_count": 5, "id": "d9afb0ca", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:08:07.253875Z", "iopub.status.busy": "2024-09-10T20:08:07.253600Z", "iopub.status.idle": "2024-09-10T20:08:07.277848Z", "shell.execute_reply": "2024-09-10T20:08:07.277487Z"}}, "outputs": [], "source": ["from typing import List\n", "\n", "from langchain_core.output_parsers import BaseOutputParser\n", "from langchain_core.prompts import PromptTemplate\n", "from pydantic import BaseModel, Field\n", "\n", "\n", "# Output parser will split the LLM result into a list of queries\n", "class LineListOutputParser(BaseOutputParser[List[str]]):\n", "    \"\"\"Output parser for a list of lines.\"\"\"\n", "\n", "    def parse(self, text: str) -> List[str]:\n", "        lines = text.strip().split(\"\\n\")\n", "        return list(filter(None, lines))  # Remove empty lines\n", "\n", "\n", "output_parser = LineListOutputParser()\n", "\n", "QUERY_PROMPT = PromptTemplate(\n", "    input_variables=[\"question\"],\n", "    template=\"\"\"You are an AI language model assistant. Your task is to generate five \n", "    different versions of the given user question to retrieve relevant documents from a vector \n", "    database. By generating multiple perspectives on the user question, your goal is to help\n", "    the user overcome some of the limitations of the distance-based similarity search. \n", "    Provide these alternative questions separated by newlines.\n", "    Original question: {question}\"\"\",\n", ")\n", "llm = ChatOpenAI(temperature=0)\n", "\n", "# Chain\n", "llm_chain = QUERY_PROMPT | llm | output_parser\n", "\n", "# Other inputs\n", "question = \"What are the approaches to Task Decomposition?\""]}, {"cell_type": "code", "execution_count": 6, "id": "59c75c56-dbd7-4887-b9ba-0b5b21069f51", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:08:07.280001Z", "iopub.status.busy": "2024-09-10T20:08:07.279861Z", "iopub.status.idle": "2024-09-10T20:08:09.579525Z", "shell.execute_reply": "2024-09-10T20:08:09.578837Z"}}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["INFO:langchain.retrievers.multi_query:Generated queries: ['1. Can you provide insights on regression from the course material?', '2. How is regression discussed in the course content?', '3. What information does the course offer regarding regression?', '4. In what way is regression covered in the course?', \"5. What are the course's teachings on regression?\"]\n"]}, {"data": {"text/plain": ["9"]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": ["# Run\n", "retriever = MultiQueryRetriever(\n", "    retriever=vectordb.as_retriever(), llm_chain=llm_chain, parser_key=\"lines\"\n", ")  # \"lines\" is the key (attribute name) of the parsed output\n", "\n", "# Results\n", "unique_docs = retriever.invoke(\"What does the course say about regression?\")\n", "len(unique_docs)"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.9"}}, "nbformat": 4, "nbformat_minor": 5}