{"cells": [{"cell_type": "raw", "id": "3243cb05-8243-421f-99fa-98201abb3094", "metadata": {}, "source": ["---\n", "sidebar_position: 3\n", "---"]}, {"cell_type": "markdown", "id": "14b94240", "metadata": {}, "source": ["# 如何为LLM和聊天模型添加即时工具调用能力", "\n", ":::注意", "\n", "部分模型已针对工具调用进行了微调，并提供了专用的工具调用API。通常来说，这类模型在工具调用方面的表现优于未经微调的模型，因此建议在需要工具调用的场景中使用。更多信息请参阅[如何使用聊天模型调用工具](/docs/how_to/tool_calling)指南。", "\n", ":::", "\n", ":::info 前提条件", "\n", "本指南假定您熟悉以下概念：", "\n", "- [LangChain 工具](/docs/concepts/tools)", "- [函数/工具调用](https://python.langchain.com/docs/concepts/tool_calling)", "- [聊天模型](/docs/concepts/chat_models)", "- [大型语言模型（LLMs）](/docs/concepts/text_llms)", "\n", ":::", "\n", "在本指南中，我们将了解如何为聊天模型添加**临时**工具调用支持。如果您使用的模型本身不支持[工具调用](/docs/how_to/tool_calling)，这是一种替代的调用工具的方法。", "\n", "我们将通过简单地编写一个提示来实现这一点，该提示将引导模型调用适当的工具。以下是逻辑示意图：", "\n", "![链条](../../static/img/tool_chain.svg)"]}, {"cell_type": "markdown", "id": "a0a22cb8-19e7-450a-9d1b-6848d2c81cd1", "metadata": {}, "source": ["## 安装设置", "\n", "我们需要安装以下软件包："]}, {"cell_type": "code", "execution_count": null, "id": "8c556c5e-b785-428b-8e7d-efd34a2a1adb", "metadata": {}, "outputs": [], "source": ["%pip install --upgrade --quiet langchain langchain-community"]}, {"cell_type": "markdown", "id": "897bc01e-cc2b-4400-8a64-db4aa56085d3", "metadata": {}, "source": ["如果你想使用LangSmith，请取消以下行的注释："]}, {"cell_type": "code", "execution_count": 26, "id": "5efb4170-b95b-4d29-8f57-09509f3ba6df", "metadata": {}, "outputs": [], "source": ["import getpass\n", "import os\n", "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n", "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"]}, {"cell_type": "markdown", "id": "7ec6409b-21e5-4d0a-8a46-c4ef0b055dd3", "metadata": {}, "source": ["您可以选择本指南中提供的任何模型。请注意，这些模型大多已[原生支持工具调用功能](/docs/integrations/chat/)，因此对这些模型采用本文所示的提示策略并无意义，您应当遵循[如何使用聊天模型调用工具](/docs/how_to/tool_calling)指南。", "\n", "import ChatModelTabs from \"@theme/ChatModelTabs\";", "\n", "<ChatModelTabs overrideParams={{openai: {model: \"gpt-4\"}}} />\n", "\n", "为了说明这一概念，我们将通过Ollama使用`phi3`模型——该模型**并不**原生支持工具调用功能。如果您也想使用`Ollama`，请按照[这些说明](/docs/integrations/chat/ollama/)操作。"]}, {"cell_type": "code", "execution_count": 24, "id": "424be968-2806-4d1a-a6aa-5499ae20fac5", "metadata": {}, "outputs": [], "source": ["from langchain_community.llms import Ollama\n", "\n", "model = Ollama(model=\"phi3\")"]}, {"cell_type": "markdown", "id": "68946881", "metadata": {}, "source": ["## 创建一个工具", "\n", "首先，我们创建一个`add`（加法）和`multiply`（乘法）工具。有关创建自定义工具的更多信息，请参阅[本指南](/docs/how_to/custom_tools)。"]}, {"cell_type": "code", "execution_count": 4, "id": "4548e6fa-0f9b-4d7a-8fa5-66cec0350e5f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["--\n", "multiply\n", "Multiply two numbers together.\n", "{'x': {'title': 'X', 'type': 'number'}, 'y': {'title': 'Y', 'type': 'number'}}\n", "--\n", "add\n", "Add two numbers.\n", "{'x': {'title': 'X', 'type': 'integer'}, 'y': {'title': 'Y', 'type': 'integer'}}\n"]}], "source": ["from langchain_core.tools import tool\n", "\n", "\n", "@tool\n", "def multiply(x: float, y: float) -> float:\n", "    \"\"\"Multiply two numbers together.\"\"\"\n", "    return x * y\n", "\n", "\n", "@tool\n", "def add(x: int, y: int) -> int:\n", "    \"Add two numbers.\"\n", "    return x + y\n", "\n", "\n", "tools = [multiply, add]\n", "\n", "# Let's inspect the tools\n", "for t in tools:\n", "    print(\"--\")\n", "    print(t.name)\n", "    print(t.description)\n", "    print(t.args)"]}, {"cell_type": "code", "execution_count": 5, "id": "be77e780", "metadata": {}, "outputs": [{"data": {"text/plain": ["20.0"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["multiply.invoke({\"x\": 4, \"y\": 5})"]}, {"cell_type": "markdown", "id": "15dd690e-e54d-4209-91a4-181f69a452ac", "metadata": {}, "source": ["## 创建我们的提示", "\n", "我们需要编写一个提示，明确模型可使用的工具、这些工具的参数以及模型所需的输出格式。在本例中，我们将指示模型输出一个形如 `{\"name\": \"...\", \"arguments\": {...}}` 的 JSON 数据块。"]}, {"cell_type": "code", "execution_count": 6, "id": "2063b564-25ca-4729-a45f-ba4633175b04", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["multiply(x: float, y: float) -> float - Multiply two numbers together.\n", "add(x: int, y: int) -> int - Add two numbers.\n"]}], "source": ["from langchain_core.output_parsers import JsonOutputParser\n", "from langchain_core.prompts import ChatPromptTemplate\n", "from langchain_core.tools import render_text_description\n", "\n", "rendered_tools = render_text_description(tools)\n", "print(rendered_tools)"]}, {"cell_type": "code", "execution_count": 17, "id": "f02f1dce-76e7-4ca9-9bac-5af496131fe1", "metadata": {}, "outputs": [], "source": ["system_prompt = f\"\"\"\\\n", "You are an assistant that has access to the following set of tools. \n", "Here are the names and descriptions for each tool:\n", "\n", "{rendered_tools}\n", "\n", "Given the user input, return the name and input of the tool to use. \n", "Return your response as a JSON blob with 'name' and 'arguments' keys.\n", "\n", "The `arguments` should be a dictionary, with keys corresponding \n", "to the argument names and the values corresponding to the requested values.\n", "\"\"\"\n", "\n", "prompt = ChatPromptTemplate.from_messages(\n", "    [(\"system\", system_prompt), (\"user\", \"{input}\")]\n", ")"]}, {"cell_type": "code", "execution_count": 18, "id": "f8623e03-60eb-4439-b57b-ecbcebc61b58", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{\n", "    \"name\": \"add\",\n", "    \"arguments\": {\n", "        \"x\": 3,\n", "        \"y\": 1132\n", "    }\n", "}\n"]}], "source": ["chain = prompt | model\n", "message = chain.invoke({\"input\": \"what's 3 plus 1132\"})\n", "\n", "# Let's take a look at the output from the model\n", "# if the model is an LLM (not a chat model), the output will be a string.\n", "if isinstance(message, str):\n", "    print(message)\n", "else:  # Otherwise it's a chat model\n", "    print(message.content)"]}, {"cell_type": "markdown", "id": "14df2cd5-b6fa-4b10-892d-e8692c7931e5", "metadata": {}, "source": ["## 添加输出解析器", "\n", "我们将使用 `JsonOutputParser` 来将模型输出解析为 JSON 格式。"]}, {"cell_type": "code", "execution_count": 19, "id": "f129f5bd-127c-4c95-8f34-8f437da7ca8f", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'name': 'multiply', 'arguments': {'x': 13.0, 'y': 4.0}}"]}, "execution_count": 19, "metadata": {}, "output_type": "execute_result"}], "source": ["from langchain_core.output_parsers import JsonOutputParser\n", "\n", "chain = prompt | model | JsonOutputParser()\n", "chain.invoke({\"input\": \"what's thirteen times 4\"})"]}, {"cell_type": "markdown", "id": "e1f08255-f146-4f4a-be43-5c21c1d3ae83", "metadata": {}, "source": [":::重要", "\n", "🎉 太棒了！🎉 我们现在已经指导模型学会如何**请求**调用工具。", "\n", "现在，让我们创建一些逻辑来实际运行这个工具！", "好的，请提供需要翻译的英文文本，我会按照标准Markdown格式将其翻译成中文并保持原有结构。以下为示例格式：\n\n**示例输入（英文）**  \n```markdown\n# Introduction  \nThis is a **sample** text with [a link](https://example.com).  \n- Item 1  \n- Item 2  \n```\n\n**示例输出（中文）**  \n```markdown\n# 简介  \n这是一段**示例**文本，包含[链接](https://example.com)。  \n- 项目1  \n- 项目2  \n```\n\n请直接提供您的英文内容，我将立即开始翻译。"]}, {"cell_type": "markdown", "id": "8e29dd4c-8eb5-457f-92d1-8add076404dc", "metadata": {}, "source": ["## 调用工具", "\n", "既然模型能够请求调用工具，我们需要编写一个能够实际执行调用的函数", "该工具。", "\n", "该函数将根据名称选择适当的工具，并将模型选定的参数传递给它。"]}, {"cell_type": "code", "execution_count": 20, "id": "faee95e0-4095-4310-991f-9e9465c6738e", "metadata": {}, "outputs": [], "source": ["from typing import Any, Dict, Optional, TypedDict\n", "\n", "from langchain_core.runnables import RunnableConfig\n", "\n", "\n", "class ToolCallRequest(TypedDict):\n", "    \"\"\"A typed dict that shows the inputs into the invoke_tool function.\"\"\"\n", "\n", "    name: str\n", "    arguments: Dict[str, Any]\n", "\n", "\n", "def invoke_tool(\n", "    tool_call_request: ToolCallRequest, config: Optional[RunnableConfig] = None\n", "):\n", "    \"\"\"A function that we can use the perform a tool invocation.\n", "\n", "    Args:\n", "        tool_call_request: a dict that contains the keys name and arguments.\n", "            The name must match the name of a tool that exists.\n", "            The arguments are the arguments to that tool.\n", "        config: This is configuration information that LangChain uses that contains\n", "            things like callbacks, metadata, etc.See LCEL documentation about RunnableConfig.\n", "\n", "    Returns:\n", "        output from the requested tool\n", "    \"\"\"\n", "    tool_name_to_tool = {tool.name: tool for tool in tools}\n", "    name = tool_call_request[\"name\"]\n", "    requested_tool = tool_name_to_tool[name]\n", "    return requested_tool.invoke(tool_call_request[\"arguments\"], config=config)"]}, {"cell_type": "markdown", "id": "f4957532-9e0c-47f6-bb62-0fd789ac1d3e", "metadata": {}, "source": ["让我们来测试一下 �！"]}, {"cell_type": "code", "execution_count": 21, "id": "d0ea3b2a-8fb2-4016-83c8-a5d3e78fedbc", "metadata": {}, "outputs": [{"data": {"text/plain": ["15.0"]}, "execution_count": 21, "metadata": {}, "output_type": "execute_result"}], "source": ["invoke_tool({\"name\": \"multiply\", \"arguments\": {\"x\": 3, \"y\": 5}})"]}, {"cell_type": "markdown", "id": "715af6e1-935d-4bc0-a3d2-646ecf8a329b", "metadata": {}, "source": ["## 让我们一起来整合", "\n", "让我们将其整合成一个链条，创建一个具备加法和乘法功能的计算器。"]}, {"cell_type": "code", "execution_count": 22, "id": "0555b384-fde6-4404-86e0-7ea199003d58", "metadata": {}, "outputs": [{"data": {"text/plain": ["53.83784653"]}, "execution_count": 22, "metadata": {}, "output_type": "execute_result"}], "source": ["chain = prompt | model | JsonOutputParser() | invoke_tool\n", "chain.invoke({\"input\": \"what's thirteen times 4.14137281\"})"]}, {"cell_type": "markdown", "id": "b4a9c5aa-f60a-4017-af6f-1ff6e04bfb61", "metadata": {}, "source": ["## 返回工具输入", "\n", "不仅返回工具输出，同时返回工具输入也很有帮助。我们可以通过 `RunnablePassthrough.assign` 轻松实现这一点，将工具输出分配进去。这会将 RunnablePassthrough 组件的输入（假设是一个字典）原样保留，同时添加一个新的键值，而当前输入中的所有内容仍会完整传递："]}, {"cell_type": "code", "execution_count": 23, "id": "45404406-859d-4caa-8b9d-5838162c80a0", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'name': 'multiply',\n", " 'arguments': {'x': 13, 'y': 4.14137281},\n", " 'output': 53.83784653}"]}, "execution_count": 23, "metadata": {}, "output_type": "execute_result"}], "source": ["from langchain_core.runnables import RunnablePassthrough\n", "\n", "chain = (\n", "    prompt | model | JsonOutputParser() | RunnablePassthrough.assign(output=invoke_tool)\n", ")\n", "chain.invoke({\"input\": \"what's thirteen times 4.14137281\"})"]}, {"cell_type": "markdown", "id": "1797fe82-ea35-4cba-834a-1caf9740d184", "metadata": {}, "source": ["## 接下来是什么？", "\n", "本操作指南展示了模型正确输出所有所需工具信息时的“理想路径”。", "\n", "实际上，如果你使用更复杂的工具，就会开始遇到模型产生的错误，特别是那些未针对工具调用进行微调的模型以及能力较弱的模型。", "\n", "你需要准备好添加策略来改进模型的输出；例如，", "\n", "1. 提供少量示例。", "2. 添加错误处理（例如捕获异常并将其反馈给LLM，要求其修正先前的输出）。"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.4"}}, "nbformat": 4, "nbformat_minor": 5}