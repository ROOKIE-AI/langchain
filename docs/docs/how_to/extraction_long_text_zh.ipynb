{"cells": [{"cell_type": "markdown", "id": "9e161a8a-fcf0-4d55-933e-da271ce28d7e", "metadata": {}, "source": ["# 如何处理提取长文本时的问题", "\n", "在处理文件（如PDF）时，你可能会遇到超出语言模型上下文窗口限制的文本。为了处理这些文本，可以考虑以下策略：", "\n", "1. **更换大语言模型** 选择支持更大上下文窗口的不同大语言模型。", "2. **暴力破解** 将文档分块，并从每个块中提取内容。", "3. **RAG** 将文档分块，对分块内容建立索引，仅从看似“相关”的部分分块中提取内容。", "\n", "请记住，这些策略各有不同的权衡取舍，最佳策略很可能取决于你正在设计的应用程序！", "\n", "本指南演示了如何实施策略2和策略3。"]}, {"cell_type": "markdown", "id": "57969139-ad0a-487e-97d8-cb30e2af9742", "metadata": {}, "source": ["## 安装", "\n", "首先，我们将安装本指南所需的依赖项："]}, {"cell_type": "code", "execution_count": 1, "id": "a3b4d838-5be4-4207-8a4a-9ef5624c48f2", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:35:19.850767Z", "iopub.status.busy": "2024-09-10T20:35:19.850427Z", "iopub.status.idle": "2024-09-10T20:35:21.432233Z", "shell.execute_reply": "2024-09-10T20:35:21.431606Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Note: you may need to restart the kernel to use updated packages.\n"]}], "source": ["%pip install -qU langchain-community lxml faiss-cpu langchain-openai"]}, {"cell_type": "markdown", "id": "ac000b03-33fc-414f-8f2c-3850df621a35", "metadata": {}, "source": ["现在我们需要一些示例数据！让我们从维基百科下载一篇关于[汽车的文章](https://en.wikipedia.org/wiki/Car)，并将其加载为LangChain的[文档](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html)。"]}, {"cell_type": "code", "execution_count": 1, "id": "84460db2-36e1-4037-bfa6-2a11883c2ba5", "metadata": {}, "outputs": [], "source": ["import re\n", "\n", "import requests\n", "from langchain_community.document_loaders import BSHTMLLoader\n", "\n", "# Download the content\n", "response = requests.get(\"https://en.wikipedia.org/wiki/Car\")\n", "# Write it to a file\n", "with open(\"car.html\", \"w\", encoding=\"utf-8\") as f:\n", "    f.write(response.text)\n", "# Load it with an HTML parser\n", "loader = BSHTMLLoader(\"car.html\")\n", "document = loader.load()[0]\n", "# Clean up code\n", "# Replace consecutive new lines with a single new line\n", "document.page_content = re.sub(\"\\n\\n+\", \"\\n\", document.page_content)"]}, {"cell_type": "code", "execution_count": 2, "id": "fcb6917b-123d-4630-a0ce-ed8b293d482d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["78865\n"]}], "source": ["print(len(document.page_content))"]}, {"cell_type": "markdown", "id": "af3ffb8d-587a-4370-886a-e56e617bcb9c", "metadata": {}, "source": ["## 定义模式", "\n", "遵循[提取教程](/docs/tutorials/extraction)，我们将使用Pydantic来定义希望提取的信息模式。在本例中，我们将提取包含年份和描述的\"关键发展\"列表（例如重要的历史事件）。", "\n", "请注意，我们还包含了一个`evidence`键，并指示模型逐字提供文章中相关的文本句子。这使得我们能够将提取结果与（模型重构的）原始文档文本进行比较。"]}, {"cell_type": "code", "execution_count": 3, "id": "a3b288ed-87a6-4af0-aac8-20921dc370d4", "metadata": {}, "outputs": [], "source": ["from typing import List, Optional\n", "\n", "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n", "from pydantic import BaseModel, Field\n", "\n", "\n", "class KeyDevelopment(BaseModel):\n", "    \"\"\"Information about a development in the history of cars.\"\"\"\n", "\n", "    year: int = Field(\n", "        ..., description=\"The year when there was an important historic development.\"\n", "    )\n", "    description: str = Field(\n", "        ..., description=\"What happened in this year? What was the development?\"\n", "    )\n", "    evidence: str = Field(\n", "        ...,\n", "        description=\"Repeat in verbatim the sentence(s) from which the year and description information were extracted\",\n", "    )\n", "\n", "\n", "class ExtractionData(BaseModel):\n", "    \"\"\"Extracted information about key developments in the history of cars.\"\"\"\n", "\n", "    key_developments: List[KeyDevelopment]\n", "\n", "\n", "# Define a custom prompt to provide instructions and any additional context.\n", "# 1) You can add examples into the prompt template to improve extraction quality\n", "# 2) Introduce additional parameters to take context into account (e.g., include metadata\n", "#    about the document from which the text was extracted.)\n", "prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\n", "            \"system\",\n", "            \"You are an expert at identifying key historic development in text. \"\n", "            \"Only extract important historic developments. Extract nothing if no important information can be found in the text.\",\n", "        ),\n", "        (\"human\", \"{text}\"),\n", "    ]\n", ")"]}, {"cell_type": "markdown", "id": "3909e22e-8a00-4f3d-bbf2-4762a0558af3", "metadata": {}, "source": ["## 创建一个提取器", "\n", "让我们选择一个LLM。由于我们正在使用工具调用功能，因此需要一个支持工具调用特性的模型。可用的LLM列表请参阅[此表格](/docs/integrations/chat)。", "\n", "import ChatModelTabs from \"@theme/ChatModelTabs\";", "\n", "<ChatModelTabs\n", "customVarName=\"llm\"", "overrideParams={{openai: {model: \"gpt-4o\", kwargs: \"temperature=0\"}}}", "/>"]}, {"cell_type": "code", "execution_count": 4, "id": "109f4f05-d0ff-431d-93d9-8f5aa34979a6", "metadata": {}, "outputs": [], "source": ["# | output: false\n", "# | echo: false\n", "\n", "from langchain_openai import ChatOpenAI\n", "\n", "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"]}, {"cell_type": "code", "execution_count": 5, "id": "aa4ae224-6d3d-4fe2-b210-7db19a9fe580", "metadata": {}, "outputs": [], "source": ["extractor = prompt | llm.with_structured_output(\n", "    schema=ExtractionData,\n", "    include_raw=False,\n", ")"]}, {"cell_type": "markdown", "id": "13aebafb-26b5-42b2-ae8e-9c05cd56e5c5", "metadata": {}, "source": ["## 暴力破解法", "\n", "将文档分割成若干块，确保每块内容都能适配大语言模型的上下文窗口。"]}, {"cell_type": "code", "execution_count": 6, "id": "27b8a373-14b3-45ea-8bf5-9749122ad927", "metadata": {}, "outputs": [], "source": ["from langchain_text_splitters import TokenTextSplitter\n", "\n", "text_splitter = TokenTextSplitter(\n", "    # Controls the size of each chunk\n", "    chunk_size=2000,\n", "    # Controls overlap between chunks\n", "    chunk_overlap=20,\n", ")\n", "\n", "texts = text_splitter.split_text(document.page_content)"]}, {"cell_type": "markdown", "id": "5b43d7e0-3c85-4d97-86c7-e8c984b60b0a", "metadata": {}, "source": ["使用[batch](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html)功能对每个文本块**并行**执行提取操作！", "\n", ":::提示", "你通常可以使用 `.batch()` 来并行化提取操作！`.batch` 在底层使用线程池来帮助你并行化工作负载。", "\n", "如果你的模型通过API公开，这很可能会加快你的提取流程！", "好的,我会按照要求进行翻译,只输出翻译后的中文内容,并保持原有的markdown格式。以下是一个示例:\n\n# 欢迎使用翻译助手\n\n这是一个示例文档,展示如何将英文markdown格式翻译成中文。\n\n## 主要功能\n\n- 保持原有markdown格式\n- 提供准确的中文翻译\n- 自动处理标题、列表等元素\n\n### 注意事项\n\n1. 翻译时会保留所有格式符号\n2. 专业术语会进行准确翻译\n3. 确保语句通顺自然\n\n> 这是引用的内容也会被正确翻译\n\n```python\n# 代码块不会被翻译\nprint(\"Hello World\")\n```\n\n[链接文字](url)也会保持原样\n\n**粗体**和*斜体*等格式都会保留"]}, {"cell_type": "code", "execution_count": 7, "id": "6ba766b5-8d6c-48e6-8d69-f391a66b65d2", "metadata": {}, "outputs": [], "source": ["# Limit just to the first 3 chunks\n", "# so the code can be re-run quickly\n", "first_few = texts[:3]\n", "\n", "extractions = extractor.batch(\n", "    [{\"text\": text} for text in first_few],\n", "    {\"max_concurrency\": 5},  # limit the concurrency by passing max concurrency!\n", ")"]}, {"cell_type": "markdown", "id": "67da8904-e927-406b-a439-2a16f6087ccf", "metadata": {}, "source": ["### 合并结果", "\n", "在从各个数据块中提取数据后，我们需要将提取结果合并在一起。"]}, {"cell_type": "code", "execution_count": 8, "id": "3c118525-97cb-4f07-a5ec-5c053dca6ed2", "metadata": {}, "outputs": [{"data": {"text/plain": ["[KeyDevelopment(year=1769, description='Nicolas-Joseph Cugnot built the first steam-powered road vehicle.', evidence='The French inventor Nicolas-Joseph Cugnot built the first steam-powered road vehicle in 1769, while the Swiss inventor François Isaac de Rivaz designed and constructed the first internal combustion-powered automobile in 1808.'),\n", " KeyDevelopment(year=1808, description='François Isaac de Rivaz designed and constructed the first internal combustion-powered automobile.', evidence='The French inventor Nicolas-Joseph Cugnot built the first steam-powered road vehicle in 1769, while the Swiss inventor François Isaac de Rivaz designed and constructed the first internal combustion-powered automobile in 1808.'),\n", " KeyDevelopment(year=1886, description='Carl Benz invented the modern car, a practical, marketable automobile for everyday use, and patented his Benz Patent-Motorwagen.', evidence='The modern car—a practical, marketable automobile for everyday use—was invented in 1886, when the German inventor Carl Benz patented his Benz Patent-Motorwagen.'),\n", " KeyDevelopment(year=1901, description='The Oldsmobile Curved Dash became the first mass-produced car.', evidence='The 1901 Oldsmobile Curved Dash and the 1908 Ford Model T, both American cars, are widely considered the first mass-produced[3][4] and mass-affordable[5][6][7] cars, respectively.'),\n", " KeyDevelopment(year=1908, description='The Ford Model T became the first mass-affordable car.', evidence='The 1901 Oldsmobile Curved Dash and the 1908 Ford Model T, both American cars, are widely considered the first mass-produced[3][4] and mass-affordable[5][6][7] cars, respectively.'),\n", " KeyDevelopment(year=1885, description='Carl Benz built the original Benz Patent-Motorwagen, the first modern car.', evidence='The original Benz Patent-Motorwagen, the first modern car, built in 1885 and awarded the patent for the concept'),\n", " KeyDevelopment(year=1881, description='Gustave Trouvé demonstrated a three-wheeled car powered by electricity.', evidence='In November 1881, French inventor Gustave Trouvé demonstrated a three-wheeled car powered by electricity at the International Exposition of Electricity.'),\n", " KeyDevelopment(year=1888, description=\"Bertha Benz undertook the first road trip by car to prove the road-worthiness of her husband's invention.\", evidence=\"In August 1888, Bertha Benz, the wife and business partner of Carl Benz, undertook the first road trip by car, to prove the road-worthiness of her husband's invention.\"),\n", " KeyDevelopment(year=1896, description='Benz designed and patented the first internal-combustion flat engine, called boxermotor.', evidence='In 1896, Benz designed and patented the first internal-combustion flat engine, called boxermotor.'),\n", " KeyDevelopment(year=1897, description='The first motor car in central Europe and one of the first factory-made cars in the world was produced by Czech company Nesselsdorfer Wagenbau (later renamed to Tatra), the Präsident automobil.', evidence='The first motor car in central Europe and one of the first factory-made cars in the world, was produced by Czech company Nesselsdorfer Wagenbau (later renamed to Tatra) in 1897, the Präsident automobil.')]"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["key_developments = []\n", "\n", "for extraction in extractions:\n", "    key_developments.extend(extraction.key_developments)\n", "\n", "key_developments[:10]"]}, {"cell_type": "markdown", "id": "48afd4a7-abcd-48b4-8ff1-6ca485f529e3", "metadata": {}, "source": ["## 基于RAG的方法", "\n", "另一个简单的想法是将文本分块处理，但并非从每个块中提取信息，而是专注于最相关的块。", "\n", ":::注意", "可能难以确定哪些数据块是相关的。", "\n", "例如，在我们正在使用的这篇关于`汽车`的文章中，大部分内容都包含了关键的发展信息。因此，通过使用", "**RAG**，我们很可能会丢弃大量相关信息。", "\n", "我们建议您针对具体用例进行实验，以验证此方法是否有效。", ":::", "\n", "要实现基于RAG的方法：", "\n", "1. 将文档分块并建立索引（例如存入向量数据库）；", "2. 在 `extractor` 链前添加一个使用向量数据库的检索步骤。", "\n", "以下是一个基于`FAISS`向量数据库的简单示例："]}, {"cell_type": "code", "execution_count": 9, "id": "aaf37c82-625b-4fa1-8e88-73303f08ac16", "metadata": {}, "outputs": [], "source": ["from langchain_community.vectorstores import FAISS\n", "from langchain_core.documents import Document\n", "from langchain_core.runnables import RunnableLambda\n", "from langchain_openai import OpenAIEmbeddings\n", "from langchain_text_splitters import CharacterTextSplitter\n", "\n", "texts = text_splitter.split_text(document.page_content)\n", "vectorstore = FAISS.from_texts(texts, embedding=OpenAIEmbeddings())\n", "\n", "retriever = vectorstore.as_retriever(\n", "    search_kwargs={\"k\": 1}\n", ")  # Only extract from first document"]}, {"cell_type": "markdown", "id": "013ecad9-f80f-477c-b954-494b46a02a07", "metadata": {}, "source": ["在这种情况下，RAG提取器仅查看顶部文档。"]}, {"cell_type": "code", "execution_count": 10, "id": "47aad00b-7013-4f7f-a1b0-02ef269093bf", "metadata": {}, "outputs": [], "source": ["rag_extractor = {\n", "    \"text\": retriever | (lambda docs: docs[0].page_content)  # fetch content of top doc\n", "} | extractor"]}, {"cell_type": "code", "execution_count": 11, "id": "68f2de01-0cd8-456e-a959-db236189d41b", "metadata": {}, "outputs": [], "source": ["results = rag_extractor.invoke(\"Key developments associated with cars\")"]}, {"cell_type": "code", "execution_count": 13, "id": "1788e2d6-77bb-417f-827c-eb96c035164e", "metadata": {"execution": {"iopub.execute_input": "2024-09-10T20:35:43.200497Z", "iopub.status.busy": "2024-09-10T20:35:43.200037Z", "iopub.status.idle": "2024-09-10T20:35:43.206773Z", "shell.execute_reply": "2024-09-10T20:35:43.205426Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["year=2006 description='Car-sharing services in the US experienced double-digit growth in revenue and membership.' evidence='in the US, some car-sharing services have experienced double-digit growth in revenue and membership growth between 2006 and 2007.'\n", "year=2020 description='56 million cars were manufactured worldwide, with China producing the most.' evidence='In 2020, there were 56 million cars manufactured worldwide, down from 67 million the previous year. The automotive industry in China produces by far the most (20 million in 2020).'\n"]}], "source": ["for key_development in results.key_developments:\n", "    print(key_development)"]}, {"cell_type": "markdown", "id": "cf36e626-cf5d-4324-ba29-9bd602be9b97", "metadata": {}, "source": ["## 常见问题", "\n", "不同方法在成本、速度和准确性方面各有优缺点。", "\n", "注意以下问题：", "\n", "* 分块处理内容意味着，如果信息分散在多个块中，LLM可能无法成功提取信息。", "* 大块文本重叠可能导致相同信息被重复提取，因此请准备好进行去重处理！", "* 大语言模型可能会编造数据。如果在一大段文本中寻找单一事实并采用蛮力方法，最终可能会得到更多虚构的数据。"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.4"}}, "nbformat": 4, "nbformat_minor": 5}