{"cells": [{"cell_type": "raw", "id": "beba2e0e", "metadata": {}, "source": ["---\n", "sidebar_position: 2\n", "---"]}, {"cell_type": "markdown", "id": "bb0735c0", "metadata": {}, "source": ["# å¦‚ä½•åœ¨èŠå¤©æ¨¡å‹ä¸­ä½¿ç”¨å°‘é‡ç¤ºä¾‹", "\n", ":::info å‰ææ¡ä»¶", "\n", "æœ¬æŒ‡å—å‡å®šæ‚¨å·²ç†Ÿæ‚‰ä»¥ä¸‹æ¦‚å¿µï¼š", "- [æç¤ºæ¨¡æ¿](/docs/concepts/prompt_templates)", "- [ç¤ºä¾‹é€‰æ‹©å™¨](/docs/concepts/example_selectors)", "- [èŠå¤©æ¨¡å‹](/docs/concepts/chat_models)", "- [å‘é‡æ•°æ®åº“](/docs/concepts/vectorstores)", "\n", ":::", "\n", "æœ¬æŒ‡å—ä»‹ç»äº†å¦‚ä½•é€šè¿‡ç¤ºä¾‹è¾“å…¥å’Œè¾“å‡ºæ¥å¼•å¯¼èŠå¤©æ¨¡å‹ã€‚ä¸ºæ¨¡å‹æä¾›å°‘é‡æ­¤ç±»ç¤ºä¾‹çš„æ–¹æ³•ç§°ä¸º[å°‘æ ·æœ¬æç¤º](/docs/concepts/few_shot_prompting/)ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹å¼ï¼Œæ—¢èƒ½æŒ‡å¯¼ç”Ÿæˆè¿‡ç¨‹ï¼Œåˆèƒ½åœ¨æŸäº›æƒ…å†µä¸‹æ˜¾è‘—æå‡æ¨¡å‹è¡¨ç°ã€‚", "\n", "å…³äºå¦‚ä½•æœ€å¥½åœ°è¿›è¡Œå°‘æ ·æœ¬æç¤ºï¼ˆfew-shot promptingï¼‰ï¼Œç›®å‰ä¼¼ä¹å°šæœªå½¢æˆåšå®çš„å…±è¯†ï¼Œä¸”æœ€ä¼˜çš„æç¤ºç¼–è¯‘æ–¹å¼å¯èƒ½å› æ¨¡å‹è€Œå¼‚ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æä¾›äº†è¯¸å¦‚ [FewShotChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate.html?highlight=fewshot#langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate) è¿™æ ·çš„å°‘æ ·æœ¬æç¤ºæ¨¡æ¿ä½œä¸ºçµæ´»çš„èµ·ç‚¹ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦å¯¹å…¶è¿›è¡Œä¿®æ”¹æˆ–æ›¿æ¢ã€‚", "\n", "å°æ ·æœ¬æç¤ºæ¨¡æ¿çš„ç›®æ ‡æ˜¯æ ¹æ®è¾“å…¥åŠ¨æ€é€‰æ‹©ç¤ºä¾‹ï¼Œç„¶åå°†è¿™äº›ç¤ºä¾‹æ ¼å¼åŒ–åˆ°æœ€ç»ˆæç¤ºä¸­ä¾›æ¨¡å‹ä½¿ç”¨ã€‚", "\n", "**æ³¨æ„ï¼š** ä»¥ä¸‹ä»£ç ç¤ºä¾‹ä»…é€‚ç”¨äºèŠå¤©æ¨¡å‹ï¼Œå› ä¸º`FewShotChatMessagePromptTemplates`çš„è®¾è®¡ç›®çš„æ˜¯è¾“å‡ºæ ¼å¼åŒ–çš„[èŠå¤©æ¶ˆæ¯](/docs/concepts/messages)ï¼Œè€Œéçº¯å­—ç¬¦ä¸²ã€‚å¦‚éœ€æŸ¥çœ‹é€‚ç”¨äºçº¯å­—ç¬¦ä¸²æ¨¡æ¿ï¼ˆå…¼å®¹è¡¥å…¨æ¨¡å‹LLMï¼‰çš„ç±»ä¼¼å°æ ·æœ¬æç¤ºç¤ºä¾‹ï¼Œè¯·å‚é˜…[å°æ ·æœ¬æç¤ºæ¨¡æ¿](/docs/how_to/few_shot_examples/)æŒ‡å—ã€‚"]}, {"cell_type": "markdown", "id": "d716f2de-cc29-4823-9360-a808c7bfdb86", "metadata": {"tags": []}, "source": ["## å›ºå®šç¤ºä¾‹", "\n", "æœ€åŸºæœ¬çš„ï¼ˆä¹Ÿæ˜¯æœ€å¸¸è§çš„ï¼‰å°‘é‡ç¤ºä¾‹æç¤ºæŠ€æœ¯æ˜¯ä½¿ç”¨å›ºå®šçš„æç¤ºç¤ºä¾‹ã€‚è¿™æ ·ä½ å¯ä»¥é€‰æ‹©ä¸€ä¸ªé“¾ï¼Œå¯¹å…¶è¿›è¡Œè¯„ä¼°ï¼Œå¹¶é¿å…åœ¨ç”Ÿäº§ä¸­æ‹…å¿ƒé¢å¤–çš„å˜åŠ¨éƒ¨åˆ†ã€‚", "\n", "æ¨¡æ¿çš„åŸºæœ¬ç»„æˆéƒ¨åˆ†åŒ…æ‹¬ï¼š", "- `examples`: åŒ…å«åœ¨æœ€ç»ˆæç¤ºä¸­çš„å­—å…¸ç¤ºä¾‹åˆ—è¡¨ã€‚", "- `example_prompt`: é€šè¿‡å…¶ [`format_messages`](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html?highlight=format_messages#langchain_core.prompts.chat.ChatPromptTemplate.format_messages) æ–¹æ³•å°†æ¯ä¸ªç¤ºä¾‹è½¬æ¢ä¸ºä¸€æ¡æˆ–å¤šæ¡æ¶ˆæ¯ã€‚å¸¸è§çš„åšæ³•æ˜¯å°†æ¯ä¸ªç¤ºä¾‹è½¬æ¢ä¸ºä¸€æ¡äººç±»æ¶ˆæ¯å’Œä¸€æ¡AIæ¶ˆæ¯å›å¤ï¼Œæˆ–è€…ä¸€æ¡äººç±»æ¶ˆæ¯åè·Ÿä¸€æ¡å‡½æ•°è°ƒç”¨æ¶ˆæ¯ã€‚", "\n", "ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„æ¼”ç¤ºã€‚é¦–å…ˆï¼Œå®šä¹‰ä½ æƒ³è¦åŒ…å«çš„ç¤ºä¾‹ã€‚è®©æˆ‘ä»¬ç»™è¿™ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ä¸€ä¸ªä¸ç†Ÿæ‚‰çš„æ•°å­¦è¿ç®—ç¬¦ï¼Œç”¨â€œğŸ¦œâ€è¡¨æƒ…ç¬¦å·è¡¨ç¤ºï¼š"]}, {"cell_type": "code", "execution_count": 1, "id": "5b79e400", "metadata": {}, "outputs": [], "source": ["%pip install -qU langchain langchain-openai langchain-chroma\n", "\n", "import os\n", "from getpass import getpass\n", "\n", "if \"OPENAI_API_KEY\" not in os.environ:\n", "    os.environ[\"OPENAI_API_KEY\"] = getpass()"]}, {"cell_type": "markdown", "id": "30856d92", "metadata": {}, "source": ["å¦‚æœæˆ‘ä»¬å°è¯•è¯¢é—®æ¨¡å‹è¿™ä¸ªè¡¨è¾¾å¼çš„ç»“æœæ˜¯ä»€ä¹ˆï¼Œå®ƒå°†ä¼šå¤±è´¥ï¼š"]}, {"cell_type": "code", "execution_count": 4, "id": "174dec5b", "metadata": {}, "outputs": [{"data": {"text/plain": ["AIMessage(content='The expression \"2 ğŸ¦œ 9\" is not a standard mathematical operation or equation. It appears to be a combination of the number 2 and the parrot emoji ğŸ¦œ followed by the number 9. It does not have a specific mathematical meaning.', response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 17, 'total_tokens': 71}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-aad12dda-5c47-4a1e-9949-6fe94e03242a-0', usage_metadata={'input_tokens': 17, 'output_tokens': 54, 'total_tokens': 71})"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["from langchain_openai import ChatOpenAI\n", "\n", "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n", "\n", "model.invoke(\"What is 2 ğŸ¦œ 9?\")"]}, {"cell_type": "markdown", "id": "e6d58385", "metadata": {}, "source": ["ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å¦‚æœç»™å¤§è¯­è¨€æ¨¡å‹æä¾›ä¸€äº›ç¤ºä¾‹ä¼šå‘ç”Ÿä»€ä¹ˆã€‚æˆ‘ä»¬å°†åœ¨ä¸‹é¢å®šä¹‰å‡ ä¸ªä¾‹å­ï¼š"]}, {"cell_type": "code", "execution_count": 5, "id": "0fc5a02a-6249-4e92-95c3-30fff9671e8b", "metadata": {"tags": []}, "outputs": [], "source": ["from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n", "\n", "examples = [\n", "    {\"input\": \"2 ğŸ¦œ 2\", \"output\": \"4\"},\n", "    {\"input\": \"2 ğŸ¦œ 3\", \"output\": \"5\"},\n", "]"]}, {"cell_type": "markdown", "id": "e8710ecc-2aa0-4172-a74c-250f6bc3d9e2", "metadata": {}, "source": ["æ¥ä¸‹æ¥ï¼Œå°†å®ƒä»¬æ•´åˆåˆ°å°‘æ ·æœ¬æç¤ºæ¨¡æ¿ä¸­ã€‚"]}, {"cell_type": "code", "execution_count": 6, "id": "65e72ad1-9060-47d0-91a1-bc130c8b98ac", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[HumanMessage(content='2 ğŸ¦œ 2'), AIMessage(content='4'), HumanMessage(content='2 ğŸ¦œ 3'), AIMessage(content='5')]\n"]}], "source": ["# This is a prompt template used to format each individual example.\n", "example_prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\"human\", \"{input}\"),\n", "        (\"ai\", \"{output}\"),\n", "    ]\n", ")\n", "few_shot_prompt = FewShotChatMessagePromptTemplate(\n", "    example_prompt=example_prompt,\n", "    examples=examples,\n", ")\n", "\n", "print(few_shot_prompt.invoke({}).to_messages())"]}, {"cell_type": "markdown", "id": "5490bd59-b28f-46a4-bbdf-0191802dd3c5", "metadata": {}, "source": ["æœ€åï¼Œæˆ‘ä»¬æŒ‰ç…§å¦‚ä¸‹æ–¹å¼ç»„è£…æœ€ç»ˆæç¤ºï¼Œç›´æ¥å°†`few_shot_prompt`ä¼ å…¥`from_messages`å·¥å‚æ–¹æ³•ï¼Œå¹¶ä¸æ¨¡å‹ä¸€èµ·ä½¿ç”¨ï¼š"]}, {"cell_type": "code", "execution_count": 7, "id": "9f86d6d9-50de-41b6-b6c7-0f9980cc0187", "metadata": {"tags": []}, "outputs": [], "source": ["final_prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\"system\", \"You are a wondrous wizard of math.\"),\n", "        few_shot_prompt,\n", "        (\"human\", \"{input}\"),\n", "    ]\n", ")"]}, {"cell_type": "markdown", "id": "dd8029c5", "metadata": {}, "source": ["ç°åœ¨è®©æˆ‘ä»¬å‘æ¨¡å‹æå‡ºåˆå§‹é—®é¢˜ï¼Œçœ‹çœ‹å®ƒçš„è¡¨ç°å¦‚ä½•ï¼š"]}, {"cell_type": "code", "execution_count": 8, "id": "97d443b1-6fae-4b36-bede-3ff7306288a3", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": ["AIMessage(content='11', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 60, 'total_tokens': 61}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5ec4e051-262f-408e-ad00-3f2ebeb561c3-0', usage_metadata={'input_tokens': 60, 'output_tokens': 1, 'total_tokens': 61})"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["from langchain_openai import ChatOpenAI\n", "\n", "chain = final_prompt | model\n", "\n", "chain.invoke({\"input\": \"What is 2 ğŸ¦œ 9?\"})"]}, {"cell_type": "markdown", "id": "70ab7114-f07f-46be-8874-3705a25aba5f", "metadata": {}, "source": ["æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ¨¡å‹ç°åœ¨å·²ç»ä»ç»™å®šçš„å°‘é‡ç¤ºä¾‹ä¸­æ¨æ–­å‡ºé¹¦é¹‰è¡¨æƒ…ç¬¦å·ä»£è¡¨åŠ æ³•ï¼", "\n", "## åŠ¨æ€å°‘æ ·æœ¬æç¤º", "\n", "æœ‰æ—¶ä½ å¯èƒ½å¸Œæœ›æ ¹æ®è¾“å…¥ä»æ•´ä½“é›†åˆä¸­ä»…é€‰æ‹©å°‘é‡ç¤ºä¾‹è¿›è¡Œå±•ç¤ºã€‚ä¸ºæ­¤ï¼Œä½ å¯ä»¥å°†ä¼ å…¥`FewShotChatMessagePromptTemplate`çš„`examples`æ›¿æ¢ä¸º`example_selector`ã€‚å…¶ä½™ç»„ä»¶ä¸ä¸Šè¿°ä¿æŒä¸€è‡´ï¼æˆ‘ä»¬çš„åŠ¨æ€å°‘é‡ç¤ºä¾‹æç¤ºæ¨¡æ¿å°†å¦‚ä¸‹æ‰€ç¤ºï¼š", "\n", "- `example_selector`: è´Ÿè´£ä¸ºç»™å®šè¾“å…¥é€‰æ‹©å°‘æ ·æœ¬ç¤ºä¾‹ï¼ˆä»¥åŠè¿”å›é¡ºåºï¼‰ã€‚è¿™äº›é€‰æ‹©å™¨å®ç°äº† [BaseExampleSelector](https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.base.BaseExampleSelector.html?highlight=baseexampleselector#langchain_core.example_selectors.base.BaseExampleSelector) æ¥å£ã€‚ä¸€ä¸ªå¸¸è§ç¤ºä¾‹æ˜¯åŸºäºå‘é‡å­˜å‚¨çš„ [SemanticSimilarityExampleSelector](https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector.html?highlight=semanticsimilarityexampleselector#langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector)", "- `example_prompt`: é€šè¿‡å…¶ [`format_messages`](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html?highlight=chatprompttemplate#langchain_core.prompts.chat.ChatPromptTemplate.format_messages) æ–¹æ³•å°†æ¯ä¸ªç¤ºä¾‹è½¬æ¢ä¸º1æ¡æˆ–å¤šæ¡æ¶ˆæ¯ã€‚å¸¸è§çš„åšæ³•æ˜¯å°†æ¯ä¸ªç¤ºä¾‹è½¬æ¢ä¸ºä¸€æ¡äººç±»æ¶ˆæ¯å’Œä¸€æ¡AIæ¶ˆæ¯å›å¤ï¼Œæˆ–è€…ä¸€æ¡äººç±»æ¶ˆæ¯åè·Ÿä¸€æ¡å‡½æ•°è°ƒç”¨æ¶ˆæ¯ã€‚", "\n", "è¿™äº›å¯ä»¥å†æ¬¡ä¸å…¶ä»–æ¶ˆæ¯å’ŒèŠå¤©æ¨¡æ¿ç»„åˆï¼Œä»¥æ„å»ºæ‚¨çš„æœ€ç»ˆæç¤ºã€‚", "\n", "è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç¤ºä¾‹æ¥äº†è§£ `SemanticSimilarityExampleSelector` çš„å·¥ä½œåŸç†ã€‚ç”±äºè¯¥å®ç°ä½¿ç”¨å‘é‡å­˜å‚¨ï¼ˆvectorstoreï¼‰åŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§æ¥é€‰æ‹©ç¤ºä¾‹ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦å¡«å……è¯¥å­˜å‚¨ã€‚è¿™é‡Œçš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼Œæˆ‘ä»¬å¸Œæœ›æœç´¢å¹¶è¿”å›ä¸æ–‡æœ¬è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹ï¼Œå› æ­¤æˆ‘ä»¬ä¼šå¯¹æç¤ºç¤ºä¾‹çš„ `values` è¿›è¡ŒåµŒå…¥ï¼ˆembeddingï¼‰ï¼Œè€Œä¸æ˜¯è€ƒè™‘é”®ï¼ˆkeysï¼‰ï¼š"]}, {"cell_type": "code", "execution_count": 9, "id": "ad66f06a-66fd-4fcc-8166-5d0e3c801e57", "metadata": {"tags": []}, "outputs": [], "source": ["from langchain_chroma import Chroma\n", "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n", "from langchain_openai import OpenAIEmbeddings\n", "\n", "examples = [\n", "    {\"input\": \"2 ğŸ¦œ 2\", \"output\": \"4\"},\n", "    {\"input\": \"2 ğŸ¦œ 3\", \"output\": \"5\"},\n", "    {\"input\": \"2 ğŸ¦œ 4\", \"output\": \"6\"},\n", "    {\"input\": \"What did the cow say to the moon?\", \"output\": \"nothing at all\"},\n", "    {\n", "        \"input\": \"Write me a poem about the moon\",\n", "        \"output\": \"One for the moon, and one for me, who are we to talk about the moon?\",\n", "    },\n", "]\n", "\n", "to_vectorize = [\" \".join(example.values()) for example in examples]\n", "embeddings = OpenAIEmbeddings()\n", "vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)"]}, {"cell_type": "markdown", "id": "2f7e384a-2031-432b-951c-7ea8cf9262f1", "metadata": {}, "source": ["### åˆ›å»º `example_selector`", "\n", "åˆ›å»ºå¥½å‘é‡å­˜å‚¨åï¼Œæˆ‘ä»¬å°±å¯ä»¥æ„å»º `example_selector` äº†ã€‚è¿™é‡Œæˆ‘ä»¬å°†å•ç‹¬è°ƒç”¨å®ƒï¼Œå¹¶è®¾ç½® `k` å‚æ•°å€¼ï¼Œä½¿å…¶ä»…è·å–ä¸è¾“å…¥æœ€æ¥è¿‘çš„ä¸¤ä¸ªç¤ºä¾‹ã€‚"]}, {"cell_type": "code", "execution_count": 10, "id": "7790303a-f722-452e-8921-b14bdf20bdff", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": ["[{'input': 'What did the cow say to the moon?', 'output': 'nothing at all'},\n", " {'input': '2 ğŸ¦œ 4', 'output': '6'}]"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["example_selector = SemanticSimilarityExampleSelector(\n", "    vectorstore=vectorstore,\n", "    k=2,\n", ")\n", "\n", "# The prompt template will load examples by passing the input do the `select_examples` method\n", "example_selector.select_examples({\"input\": \"horse\"})"]}, {"cell_type": "markdown", "id": "cc77c40f-3f58-40a2-b757-a2a2ea43f24a", "metadata": {}, "source": ["### åˆ›å»ºæç¤ºæ¨¡æ¿", "\n", "æˆ‘ä»¬ç°åœ¨ç»„è£…æç¤ºæ¨¡æ¿ï¼Œä½¿ç”¨ä¸Šé¢åˆ›å»ºçš„ `example_selector`ã€‚"]}, {"cell_type": "code", "execution_count": 11, "id": "253c255e-41d7-45f6-9d88-c7a0ced4b1bd", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[HumanMessage(content='2 ğŸ¦œ 3'), AIMessage(content='5'), HumanMessage(content='2 ğŸ¦œ 4'), AIMessage(content='6')]\n"]}], "source": ["from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n", "\n", "# Define the few-shot prompt.\n", "few_shot_prompt = FewShotChatMessagePromptTemplate(\n", "    # The input variables select the values to pass to the example_selector\n", "    input_variables=[\"input\"],\n", "    example_selector=example_selector,\n", "    # Define how each example will be formatted.\n", "    # In this case, each example will become 2 messages:\n", "    # 1 human, and 1 AI\n", "    example_prompt=ChatPromptTemplate.from_messages(\n", "        [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n", "    ),\n", ")\n", "\n", "print(few_shot_prompt.invoke(input=\"What's 3 ğŸ¦œ 3?\").to_messages())"]}, {"cell_type": "markdown", "id": "339cae7d-0eb0-44a6-852f-0267c5ff72b3", "metadata": {}, "source": ["æˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªå°‘é‡ç¤ºä¾‹çš„èŠå¤©æ¶ˆæ¯æç¤ºæ¨¡æ¿ä¼ å…¥å¦ä¸€ä¸ªèŠå¤©æç¤ºæ¨¡æ¿ä¸­ï¼š"]}, {"cell_type": "code", "execution_count": 12, "id": "e731cb45-f0ea-422c-be37-42af2a6cb2c4", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["messages=[HumanMessage(content='2 ğŸ¦œ 3'), AIMessage(content='5'), HumanMessage(content='2 ğŸ¦œ 4'), AIMessage(content='6')]\n"]}], "source": ["final_prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\"system\", \"You are a wondrous wizard of math.\"),\n", "        few_shot_prompt,\n", "        (\"human\", \"{input}\"),\n", "    ]\n", ")\n", "\n", "print(few_shot_prompt.invoke(input=\"What's 3 ğŸ¦œ 3?\"))"]}, {"cell_type": "markdown", "id": "2408ea69-1880-4ef5-a0fa-ffa8d2026aa9", "metadata": {}, "source": ["### ä¸èŠå¤©æ¨¡å‹ä¸€èµ·ä½¿ç”¨", "\n", "æœ€åï¼Œä½ å¯ä»¥å°†ä½ çš„æ¨¡å‹è¿æ¥åˆ°å°‘æ ·æœ¬æç¤ºä¸Šã€‚"]}, {"cell_type": "code", "execution_count": 13, "id": "0568cbc6-5354-47f1-ab4d-dfcc616cf583", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": ["AIMessage(content='6', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 60, 'total_tokens': 61}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d1863e5e-17cd-4e9d-bf7a-b9f118747a65-0', usage_metadata={'input_tokens': 60, 'output_tokens': 1, 'total_tokens': 61})"]}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": ["chain = final_prompt | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n", "\n", "chain.invoke({\"input\": \"What's 3 ğŸ¦œ 3?\"})"]}, {"cell_type": "markdown", "id": "c87fad3c", "metadata": {}, "source": ["## åç»­æ­¥éª¤", "\n", "ä½ ç°åœ¨å·²ç»å­¦ä¼šäº†å¦‚ä½•åœ¨èŠå¤©æç¤ºä¸­æ·»åŠ å°‘é‡ç¤ºä¾‹ã€‚", "\n", "æ¥ä¸‹æ¥ï¼Œè¯·æŸ¥é˜…æœ¬èŠ‚ä¸­å…³äºæç¤ºæ¨¡æ¿çš„å…¶ä»–æ“ä½œæŒ‡å—ï¼Œç›¸å…³çš„[æ–‡æœ¬è¡¥å…¨æ¨¡å‹å°‘æ ·æœ¬å­¦ä¹ æ“ä½œæŒ‡å—](/docs/how_to/few_shot_examples)ï¼Œæˆ–å…¶ä»–[ç¤ºä¾‹é€‰æ‹©å™¨æ“ä½œæŒ‡å—](/docs/how_to/example_selectors/)ã€‚"]}, {"cell_type": "code", "execution_count": null, "id": "46e26b53", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.5"}}, "nbformat": 4, "nbformat_minor": 5}