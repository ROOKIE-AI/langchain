{"cells": [{"cell_type": "raw", "id": "beba2e0e", "metadata": {}, "source": ["---\n", "sidebar_position: 2\n", "---"]}, {"cell_type": "markdown", "id": "bb0735c0", "metadata": {}, "source": ["# 如何在聊天模型中使用少量示例", "\n", ":::info 前提条件", "\n", "本指南假定您已熟悉以下概念：", "- [提示模板](/docs/concepts/prompt_templates)", "- [示例选择器](/docs/concepts/example_selectors)", "- [聊天模型](/docs/concepts/chat_models)", "- [向量数据库](/docs/concepts/vectorstores)", "\n", ":::", "\n", "本指南介绍了如何通过示例输入和输出来引导聊天模型。为模型提供少量此类示例的方法称为[少样本提示](/docs/concepts/few_shot_prompting/)，这是一种简单而有效的方式，既能指导生成过程，又能在某些情况下显著提升模型表现。", "\n", "关于如何最好地进行少样本提示（few-shot prompting），目前似乎尚未形成坚实的共识，且最优的提示编译方式可能因模型而异。因此，我们提供了诸如 [FewShotChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate.html?highlight=fewshot#langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate) 这样的少样本提示模板作为灵活的起点，您可以根据需要对其进行修改或替换。", "\n", "小样本提示模板的目标是根据输入动态选择示例，然后将这些示例格式化到最终提示中供模型使用。", "\n", "**注意：** 以下代码示例仅适用于聊天模型，因为`FewShotChatMessagePromptTemplates`的设计目的是输出格式化的[聊天消息](/docs/concepts/messages)，而非纯字符串。如需查看适用于纯字符串模板（兼容补全模型LLM）的类似小样本提示示例，请参阅[小样本提示模板](/docs/how_to/few_shot_examples/)指南。"]}, {"cell_type": "markdown", "id": "d716f2de-cc29-4823-9360-a808c7bfdb86", "metadata": {"tags": []}, "source": ["## 固定示例", "\n", "最基本的（也是最常见的）少量示例提示技术是使用固定的提示示例。这样你可以选择一个链，对其进行评估，并避免在生产中担心额外的变动部分。", "\n", "模板的基本组成部分包括：", "- `examples`: 包含在最终提示中的字典示例列表。", "- `example_prompt`: 通过其 [`format_messages`](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html?highlight=format_messages#langchain_core.prompts.chat.ChatPromptTemplate.format_messages) 方法将每个示例转换为一条或多条消息。常见的做法是将每个示例转换为一条人类消息和一条AI消息回复，或者一条人类消息后跟一条函数调用消息。", "\n", "以下是一个简单的演示。首先，定义你想要包含的示例。让我们给这个大型语言模型一个不熟悉的数学运算符，用“🦜”表情符号表示："]}, {"cell_type": "code", "execution_count": 1, "id": "5b79e400", "metadata": {}, "outputs": [], "source": ["%pip install -qU langchain langchain-openai langchain-chroma\n", "\n", "import os\n", "from getpass import getpass\n", "\n", "if \"OPENAI_API_KEY\" not in os.environ:\n", "    os.environ[\"OPENAI_API_KEY\"] = getpass()"]}, {"cell_type": "markdown", "id": "30856d92", "metadata": {}, "source": ["如果我们尝试询问模型这个表达式的结果是什么，它将会失败："]}, {"cell_type": "code", "execution_count": 4, "id": "174dec5b", "metadata": {}, "outputs": [{"data": {"text/plain": ["AIMessage(content='The expression \"2 🦜 9\" is not a standard mathematical operation or equation. It appears to be a combination of the number 2 and the parrot emoji 🦜 followed by the number 9. It does not have a specific mathematical meaning.', response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 17, 'total_tokens': 71}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-aad12dda-5c47-4a1e-9949-6fe94e03242a-0', usage_metadata={'input_tokens': 17, 'output_tokens': 54, 'total_tokens': 71})"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["from langchain_openai import ChatOpenAI\n", "\n", "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n", "\n", "model.invoke(\"What is 2 🦜 9?\")"]}, {"cell_type": "markdown", "id": "e6d58385", "metadata": {}, "source": ["现在让我们看看如果给大语言模型提供一些示例会发生什么。我们将在下面定义几个例子："]}, {"cell_type": "code", "execution_count": 5, "id": "0fc5a02a-6249-4e92-95c3-30fff9671e8b", "metadata": {"tags": []}, "outputs": [], "source": ["from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n", "\n", "examples = [\n", "    {\"input\": \"2 🦜 2\", \"output\": \"4\"},\n", "    {\"input\": \"2 🦜 3\", \"output\": \"5\"},\n", "]"]}, {"cell_type": "markdown", "id": "e8710ecc-2aa0-4172-a74c-250f6bc3d9e2", "metadata": {}, "source": ["接下来，将它们整合到少样本提示模板中。"]}, {"cell_type": "code", "execution_count": 6, "id": "65e72ad1-9060-47d0-91a1-bc130c8b98ac", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[HumanMessage(content='2 🦜 2'), AIMessage(content='4'), HumanMessage(content='2 🦜 3'), AIMessage(content='5')]\n"]}], "source": ["# This is a prompt template used to format each individual example.\n", "example_prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\"human\", \"{input}\"),\n", "        (\"ai\", \"{output}\"),\n", "    ]\n", ")\n", "few_shot_prompt = FewShotChatMessagePromptTemplate(\n", "    example_prompt=example_prompt,\n", "    examples=examples,\n", ")\n", "\n", "print(few_shot_prompt.invoke({}).to_messages())"]}, {"cell_type": "markdown", "id": "5490bd59-b28f-46a4-bbdf-0191802dd3c5", "metadata": {}, "source": ["最后，我们按照如下方式组装最终提示，直接将`few_shot_prompt`传入`from_messages`工厂方法，并与模型一起使用："]}, {"cell_type": "code", "execution_count": 7, "id": "9f86d6d9-50de-41b6-b6c7-0f9980cc0187", "metadata": {"tags": []}, "outputs": [], "source": ["final_prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\"system\", \"You are a wondrous wizard of math.\"),\n", "        few_shot_prompt,\n", "        (\"human\", \"{input}\"),\n", "    ]\n", ")"]}, {"cell_type": "markdown", "id": "dd8029c5", "metadata": {}, "source": ["现在让我们向模型提出初始问题，看看它的表现如何："]}, {"cell_type": "code", "execution_count": 8, "id": "97d443b1-6fae-4b36-bede-3ff7306288a3", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": ["AIMessage(content='11', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 60, 'total_tokens': 61}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5ec4e051-262f-408e-ad00-3f2ebeb561c3-0', usage_metadata={'input_tokens': 60, 'output_tokens': 1, 'total_tokens': 61})"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["from langchain_openai import ChatOpenAI\n", "\n", "chain = final_prompt | model\n", "\n", "chain.invoke({\"input\": \"What is 2 🦜 9?\"})"]}, {"cell_type": "markdown", "id": "70ab7114-f07f-46be-8874-3705a25aba5f", "metadata": {}, "source": ["我们可以看到，模型现在已经从给定的少量示例中推断出鹦鹉表情符号代表加法！", "\n", "## 动态少样本提示", "\n", "有时你可能希望根据输入从整体集合中仅选择少量示例进行展示。为此，你可以将传入`FewShotChatMessagePromptTemplate`的`examples`替换为`example_selector`。其余组件与上述保持一致！我们的动态少量示例提示模板将如下所示：", "\n", "- `example_selector`: 负责为给定输入选择少样本示例（以及返回顺序）。这些选择器实现了 [BaseExampleSelector](https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.base.BaseExampleSelector.html?highlight=baseexampleselector#langchain_core.example_selectors.base.BaseExampleSelector) 接口。一个常见示例是基于向量存储的 [SemanticSimilarityExampleSelector](https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector.html?highlight=semanticsimilarityexampleselector#langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector)", "- `example_prompt`: 通过其 [`format_messages`](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html?highlight=chatprompttemplate#langchain_core.prompts.chat.ChatPromptTemplate.format_messages) 方法将每个示例转换为1条或多条消息。常见的做法是将每个示例转换为一条人类消息和一条AI消息回复，或者一条人类消息后跟一条函数调用消息。", "\n", "这些可以再次与其他消息和聊天模板组合，以构建您的最终提示。", "\n", "让我们通过一个示例来了解 `SemanticSimilarityExampleSelector` 的工作原理。由于该实现使用向量存储（vectorstore）基于语义相似性来选择示例，我们首先需要填充该存储。这里的核心思想是，我们希望搜索并返回与文本输入最相似的示例，因此我们会对提示示例的 `values` 进行嵌入（embedding），而不是考虑键（keys）："]}, {"cell_type": "code", "execution_count": 9, "id": "ad66f06a-66fd-4fcc-8166-5d0e3c801e57", "metadata": {"tags": []}, "outputs": [], "source": ["from langchain_chroma import Chroma\n", "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n", "from langchain_openai import OpenAIEmbeddings\n", "\n", "examples = [\n", "    {\"input\": \"2 🦜 2\", \"output\": \"4\"},\n", "    {\"input\": \"2 🦜 3\", \"output\": \"5\"},\n", "    {\"input\": \"2 🦜 4\", \"output\": \"6\"},\n", "    {\"input\": \"What did the cow say to the moon?\", \"output\": \"nothing at all\"},\n", "    {\n", "        \"input\": \"Write me a poem about the moon\",\n", "        \"output\": \"One for the moon, and one for me, who are we to talk about the moon?\",\n", "    },\n", "]\n", "\n", "to_vectorize = [\" \".join(example.values()) for example in examples]\n", "embeddings = OpenAIEmbeddings()\n", "vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)"]}, {"cell_type": "markdown", "id": "2f7e384a-2031-432b-951c-7ea8cf9262f1", "metadata": {}, "source": ["### 创建 `example_selector`", "\n", "创建好向量存储后，我们就可以构建 `example_selector` 了。这里我们将单独调用它，并设置 `k` 参数值，使其仅获取与输入最接近的两个示例。"]}, {"cell_type": "code", "execution_count": 10, "id": "7790303a-f722-452e-8921-b14bdf20bdff", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": ["[{'input': 'What did the cow say to the moon?', 'output': 'nothing at all'},\n", " {'input': '2 🦜 4', 'output': '6'}]"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["example_selector = SemanticSimilarityExampleSelector(\n", "    vectorstore=vectorstore,\n", "    k=2,\n", ")\n", "\n", "# The prompt template will load examples by passing the input do the `select_examples` method\n", "example_selector.select_examples({\"input\": \"horse\"})"]}, {"cell_type": "markdown", "id": "cc77c40f-3f58-40a2-b757-a2a2ea43f24a", "metadata": {}, "source": ["### 创建提示模板", "\n", "我们现在组装提示模板，使用上面创建的 `example_selector`。"]}, {"cell_type": "code", "execution_count": 11, "id": "253c255e-41d7-45f6-9d88-c7a0ced4b1bd", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[HumanMessage(content='2 🦜 3'), AIMessage(content='5'), HumanMessage(content='2 🦜 4'), AIMessage(content='6')]\n"]}], "source": ["from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n", "\n", "# Define the few-shot prompt.\n", "few_shot_prompt = FewShotChatMessagePromptTemplate(\n", "    # The input variables select the values to pass to the example_selector\n", "    input_variables=[\"input\"],\n", "    example_selector=example_selector,\n", "    # Define how each example will be formatted.\n", "    # In this case, each example will become 2 messages:\n", "    # 1 human, and 1 AI\n", "    example_prompt=ChatPromptTemplate.from_messages(\n", "        [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n", "    ),\n", ")\n", "\n", "print(few_shot_prompt.invoke(input=\"What's 3 🦜 3?\").to_messages())"]}, {"cell_type": "markdown", "id": "339cae7d-0eb0-44a6-852f-0267c5ff72b3", "metadata": {}, "source": ["我们可以将这个少量示例的聊天消息提示模板传入另一个聊天提示模板中："]}, {"cell_type": "code", "execution_count": 12, "id": "e731cb45-f0ea-422c-be37-42af2a6cb2c4", "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["messages=[HumanMessage(content='2 🦜 3'), AIMessage(content='5'), HumanMessage(content='2 🦜 4'), AIMessage(content='6')]\n"]}], "source": ["final_prompt = ChatPromptTemplate.from_messages(\n", "    [\n", "        (\"system\", \"You are a wondrous wizard of math.\"),\n", "        few_shot_prompt,\n", "        (\"human\", \"{input}\"),\n", "    ]\n", ")\n", "\n", "print(few_shot_prompt.invoke(input=\"What's 3 🦜 3?\"))"]}, {"cell_type": "markdown", "id": "2408ea69-1880-4ef5-a0fa-ffa8d2026aa9", "metadata": {}, "source": ["### 与聊天模型一起使用", "\n", "最后，你可以将你的模型连接到少样本提示上。"]}, {"cell_type": "code", "execution_count": 13, "id": "0568cbc6-5354-47f1-ab4d-dfcc616cf583", "metadata": {"tags": []}, "outputs": [{"data": {"text/plain": ["AIMessage(content='6', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 60, 'total_tokens': 61}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d1863e5e-17cd-4e9d-bf7a-b9f118747a65-0', usage_metadata={'input_tokens': 60, 'output_tokens': 1, 'total_tokens': 61})"]}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": ["chain = final_prompt | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n", "\n", "chain.invoke({\"input\": \"What's 3 🦜 3?\"})"]}, {"cell_type": "markdown", "id": "c87fad3c", "metadata": {}, "source": ["## 后续步骤", "\n", "你现在已经学会了如何在聊天提示中添加少量示例。", "\n", "接下来，请查阅本节中关于提示模板的其他操作指南，相关的[文本补全模型少样本学习操作指南](/docs/how_to/few_shot_examples)，或其他[示例选择器操作指南](/docs/how_to/example_selectors/)。"]}, {"cell_type": "code", "execution_count": null, "id": "46e26b53", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.5"}}, "nbformat": 4, "nbformat_minor": 5}